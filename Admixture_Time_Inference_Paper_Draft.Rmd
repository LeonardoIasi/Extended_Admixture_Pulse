---
title: "The dating of the Human-Neandertal introgression event estimated from present-day human genomes is compatible with a multitude of admixture durations"
#title: "The Human-Neandertal admixture time estimated from present-day human genomes is compatible with a multitude of durations"
#title: "Neandertal-Human admixture duration not detectable using introgressed segments from modern human genomes due to uncertainties in the recombination map"
author: Leonardo Nicola Martin Iasi (Max Planck Institute for Evolutionary Anthropology,
  MPI EVA), Dr. Benjamin Marco Peter (MPI EVA, benjamin_peter@eva.mpg.de)
date: "`r Sys.Date()`"
output:
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
    fig_caption: yes
    citation_package: natbib
#    template: ATE_modified.tex
#  html_document:
#    code_folding: hide
#    toc: yes
#    toc_depth: 4
#    toc_float:
#      collapsed: no
#    citation_package: natbib
#  md_document:
#    toc: yes
#    variant: markdown_github
#    citation_package: natbib
#  word_document:
#    toc: yes
#    toc_depth: '4'
#    citation_package: natbib
#  github_document:
#    toc: yes
#    citation_package: natbib
header-includes:
- \usepackage{setspace}
- \doublespacing
- \usepackage[none]{hyphenat}
- \usepackage{amsfonts}
- \usepackage{amssymb}
- \usepackage{graphicx}
- \usepackage{float}
- \usepackage{xcolor}
- \floatplacement{figure}{H}

#csl: References/chicago-author-date.csl
bibliography: References/MyLibraryATE.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
#Make code wrap text so it doesn't go off the page when Knitting to PDF
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

<style>
body {
text-align: justify}
</style>


\section{Abstract}\label{abstract}

\section{Introduction}\label{introduction}

Admixture, i.e. gene flow between populations, is a major evolutionary force that shapes genetic diversity and allows the exchange of beneficial variants. Genomic studies have shown that admixture is prevalent across species (\cite{Salazar_Hybrid_speciation_2010, rieseberg_hybridization_2007,kronforst_multilocus_2006,kolbe_multiple_2007}) and facilitates adaptation (\cite{harrison_hybridization_2014,hedrick_adaptive_2013, shaw_genes_2011,payseur_using_2010}).

The advent of wide-spread full-genome sequencing methods makes it easier to detect admixture events
between populations (\cite{sousa_understanding_2013}). In humans, the sequencing of
the Neandertal genome (\cite{green_draft_2010}) revealed that all humans outside Africa carry low proportions of Neandertal ancestry
(\cite{green_draft_2010,prufer_complete_2013,vernot_resurrecting_2014,fu_early_2015,fu_genome_2014,sankararaman_genomic_2014,prufer_high-coverage_2017}). In addition, the  Denisovan genome (\cite{reich_genetic_2010})
showed low proportions of Denisovan ancestry being widespread in Oceania and to a smaller extent in East-Asia
(\cite{reich_genetic_2010,meyer_high-coverage_2012,sankararaman_combined_2016,vernot_excavating_2016,malaspinas_genomic_2016}).
This genetic evidence for the direct contact and interbreeding of modern humans with other hominin populations can also help resolving the timing and duration of contact by genetically dating the admixture.
Moreover, additional to archaeological records of Neandertals, the admixture can hint to the time of their disappearance assumed to be at the end of the Mousterian around 41,030â€“39,260 calibrated years before present (yBP) (\cite{higham_timing_2014}), based on archaeological data. 
Together, genetically dated admixture events can be a clue of the debated question of contact with and extinction of these hominin populations.

\subsection{Admixture on the genomic level and basic idea how to date
it}\label{admixture-on-the-genomic-level-and-basic-idea-how-to-date-it}

On the genomic level, admixture introduces  divergent chromosomes
into the admixed population. Over time, meiotic recombination
progressively breaks these chromosomes down into introgressed segments, whose size decreases with time (\cite{falush_inference_2003}). 
Assuming that recombination events are
independent from each other, the length of these segments  is roughly inversely proportional to  the number of
generations since admixture
(\cite{moorjani_history_2011,pool_inference_2009,gravel_population_2012,liang_lengths_2014}).
Hence, using this 'recombination clock', the length distribution of introgressed chromosomal segments
 can be used to inferred the time since the
admixture event 
(\cite{moorjani_history_2011,pugach_dating_2011,sankararaman_date_2012,loh_inferring_2013,sankararaman_combined_2016,pugach_gateway_2018,jacobs_multiple_2019,hellenthal_genetic_2014}).


\subsection{The two approaches and their application to find archaic admixture dates}\label{the-two-approaches-and-their-application-to-find-archaic-admixture-dates}

The first step in dating admixture events from genetic data is estimating the length distribution of admixture segments.  There are two main approaches for this; a first approach is to use patterns of linkage along a chromosome to estimate the length distribution, without explicitly inferring the genomic location of these segments. In contrast, a second set of methods first aims to identify all admixture segments over a certain length, and then use these segments for inference. 
(\cite{chimusa_dating_2018}) (Figure \ref{fig:fig1} A).

The first approach uses the admixture-induced linkage disequilibrium
(ALD) decay. Variants on introgressed archaic segments are
expected to be in high linkage disequilibrium to each other at the time
of admixture
(\cite{chakraborty_admixture_1988,stephens_mapping_1994,wall_detecting_2000}). The extent of linkage between introgressed variants decreases over generations as genetic distance increases. Hence, in case of a recent
admixture event a few tens of generations ago, ALD stretches  over long genetic distances
(\cite{patterson_methods_2004}) and is therefore easily distinguishable
from short range LD due to other processes (\cite{moorjani_history_2011}). For ancient
admixture events however, ALD is quite similar to the genomic background. To circumvent this issue for dating the Neandertal-human admixture time, an ascertainment scheme was used to calculate LD only for markers that are nearly differentially fixed between the two taxa. In this case, the presence of apparent Neandertal alleles in close-range LD is a signature of a locally introgressed locus
(\cite{sankararaman_date_2012}). Typically, estimation of admixture time proceeds by fitting a decay curve of pairwise LD as a function of
genetic distance, using an exponential distribution whose parameters are informative for the time of the admixture pulse
(\cite{moorjani_history_2011,loh_inferring_2013}). Using this approach Sankararaman et al. dated the Neandertal-human admixture time to
be  between 37,000--86,000 ya (years ago) (\cite{sankararaman_date_2012}). Later,
this date was refined to 40,510--54,454 ya (95\% CI) using a different
ascertainment scheme combined with a different genetic map
(\cite{moorjani_genetic_2016}). A date was also obtained from an ancient
genome to be 50,000 - 60,000 ya by adding the time since the admixture obtained from the
ancient individual, by the decay of pairwise covariance between
introgressed SNPs, to the specimens radiocarbon date
(\cite{fu_genome_2014}).

A higher amount of Neandertal admixture segments in present-day East-Asians was identified by using the second set of approaches. To explain the higher amount of Neandertal ancestry in these populations a second admixture event was suggested at the same time as the admixture between Neandertals and
all non-Africans (\cite{kim_selection_2015,vernot_complex_2015}).  The identification of segments is largely independent from the later dating, and can be done using a variety of methods.(\cite{racimo_signatures_2017,seguin_orlando_paleogenomics_2014,vernot_excavating_2016,sankararaman_combined_2016,skov_detecting_2018}. The length distribution of the obtained fragments is then used to estimate the time of the admixture pulse, typically using an exponential model.

The Denisovan human
admixture time point was dated to lie in the interval between 44,000--54,000 ya using the ALD
approach on modern day genomes (\cite{sankararaman_combined_2016}).

Direct identification of archaic segments in genomes from present day Southeast-Asians revealed a proportion of previously unknown Denisovan ancestry private to these populations. The segments from this ancestry are more diverged from the high-coverage Denisovan genome then previously found ones. This suggests an additional admixture event from a different population of Denisovans (\cite{browning_analysis_2018}).
Comparing the mean length of the formerly known and newly identified Denisovan segments did, however, not reveal
significant differences, suggesting a lack of power to distinguish the
two events by time (\cite{browning_analysis_2018,jacobs_multiple_2019}).
Analysing genomes from Papuan individuals revealed two time separated
admixture events with Denisovans, one in line with previous estimates at
45.7 kya (95\% CI 31.9-60.7 kya) and one exclusive to Papuans dated to
be around 29.8 kya (95\% CI 14.4-50.4 kya)
(\cite{jacobs_multiple_2019}).

Here, we are manly interested in the gene flow model these studies used and its implication.

The most widely used model is one where gene flow is constant through time (\cite{nielsen_distinguishing_2001,hey_multilocus_2004}), which does not have a time component. However, for dating admixture, it is generally assumed that gene flow
happens over a very short time period, in a single \textit{admixture pulse} (\cite{moorjani_history_2011}), usually modelled as a single generation
of gene flow. While convenient for inference, one cannot use this approach to distinguish an extend period of gene flow from an admixture pulse (\cite{pickrell_toward_2014}). 
Here, we are chiefly interested in gene flow between Neandertals and modern humans, which was previously modeled assuming a one-generation pulse of admixture. Dating this gene flow event accurately would inform several questions of  great importance, but not always the same aspect of the gene flow is the one of primary interest. For example, if we are interested in dating the out-of-Africa migration of our ancestors, the start of the gene flow between Neandertals and modern humans is of primary interest, as this establishes modern humans and Neandertals in sympatry, likely outside of Africa.
In contrast, the date of the most recent gene flow between Neandertals and modern humans may be informative for dating the extinction of Neandertals. Under an admixture pulse model, which assumes that these two times coincide, hypotheses about the impact of modern human colonization of Eurasia on Neandertal extinction cannot be evaluated.

Thus, our goal here is to examine when an admixture pulse can be rejected for more general models of continuous gene flow.  Using a continuous model, we are interested in establishing the start and end of admixture between Neandertals and modern humans, not just the mean admixture time. This is a difficult problem, as it requires deconvoluting an exponential mixture, which is notoriously hard . Thus, we also need to carefully evaluate the potential technical and biological factors that may introduce additional biases (\cite{pool_inference_2009,gravel_population_2012,liang_lengths_2014}).
For this purpose, we explore these factors influencing the inferred length of admixture pulses, to gauge their relative importance.



\subsection{Assumptions on the data}\label{assumptions-on-the-data}

In general the model assumes that introgressed segments are rare and inbreeding is not significant (\cite{pool_inference_2009}). The segments act neutral (\cite{shchur_distribution_2019}) and the recombination clock is constant over time and populations (\cite{gravel_population_2012}). We will adopt these assumptions. Instead we focus on the one-generation pulse and technical assumptions. It is usually assumed that the demography is known or its effects negligible, the recombination map known or recombination is constant. Beside that is is assumed that the ascertainment scheme sufficiently represent the variation in the true introgressing archaic population.

Violations of these assumptions are known to influence the mean time
estimates. Hence, the effect of assuming a one-generation pulse has to
be contrasted with other influencing factors, for both a scenario of
pulse-like and multi-generation long admixture. 


\subsection{complex migration models}

To relax the one-generation pulse assumption we have to generalize the admixture model.
The simplest generalization of the admixture pulse model to more complex scenarios is to assume a model with two or more pulses. In such a case,  each segment will have entered in one of the pulses, and the resulting admixture tracts will be a discrete mixture of the constituent distributions (\cite{pickrell_ancient_2014}), weighted by the relative migration rates. Zhou et al. 2017 (\cite{zhou_modeling_2017}) showed that this model, in principle, can be used for continuous mixtures as well, using a polynomial function as a mixture density. However, they found that even for relatively short admixture events, the large number of parameters led to an underestimate of admixture duration \cite{zhou_inference_2017}, and the beginning and end of admixture were not well inferred.
(\cite{zhou_modeling_2017,zhou_inference_2017}). 

Here we use a simpler model of continuous admixture with just two parameters, and one less than the two-pulse model of Pickrell et al. 2014 (\cite{pickrell_ancient_2014}). One parameter reflects the mean admixture time, and the other the duration of the admixture event; letting this parameter go to zero thus recovers the (nested) pulse model. 
This model is particularly simple if we assume that migration rate over time is Gamma distributed, in which case the distribution of admixture segment lengths has a closed form.

\subsection{What we want to do}\label{what-we-want-to-do}
In our  study, we first examine the  effect of long
continuous admixture on the admixture time estimates (assuming a pulse-like admixture) in comparison to
the effects of the aforementioned model assumptions. Second, we define
the expectation of the resulting segment length distribution for
continuous Gamma distributed admixture being Lomax distributed, holding
a parameter for the duration of admixture. This expectation works for
both methods to infer the segments length, either directly or by using
the ALD decay. Using this model, we investigate under which scenarios
the parameters of the Lomax-distribution can be accurately estimated and
for which parameters we can distinguish a pulse-like admixture event
from a continuous event. We show that in many cases pulses cannot be
distinguished from more continuous admixture events, and so current
methods are unsuitable to definitively answer when the contact between
Neandertals and modern humans ended.

```{r message=FALSE, echo=F,warning=FALSE}
suppressPackageStartupMessages({
  library(VGAM)
  library(tidyverse)
  library(ggplot2)
  library(reshape)
  library(viridis)
  library(ggpubr)
  library(dplyr)
  library(rethinking)
  library(kableExtra)
  library(DEoptim)
  library(png)
  library("MASS")
  library(bbmle)
  library(DPQ)
})

Results_Table <- function(Table_Path) {
  header_for_Result=c("A","m","c","RSS_Expo","error","Scenario","GF_Start","GF_Stop","Ascertained","min_dist","Gene_Flow_Model")
  Raw_results <-  read.table(Table_Path, header = F,col.names = header_for_Result)
  Raw_results$mean.t.GF <- rowMeans(Raw_results[c('GF_Start', 'GF_Stop')], na.rm=TRUE)
  Raw_results$length.t.GF <- Raw_results$GF_Stop - Raw_results$GF_Start
  Raw_results$GF[Raw_results$length.t.GF== 1]="0_Pulse"
  Raw_results$GF[Raw_results$length.t.GF > 1]="Continous"
  Raw_results$Ascertainment[Raw_results$Ascertained== 0]="0_LES"
  Raw_results$Ascertainment[Raw_results$Ascertained == 1]="HES"
  Raw_results$min_dist <- as.factor(Raw_results$min_dist)
  Raw_results$GF[Raw_results$Gene_Flow_Model== "GF_Model_I"]="0_Pulse"
  return(Raw_results)
}

cbPalette <- c( "#56B4E9", "#E69F00", "#009E73", "#F0E442", "#0072B2", "#D55E00")
cbPalette_viridis <- viridis(6,option = "D")

Get_Data_Table <- function(Data,mean_Gamma=F){
  xx=as.data.frame(table(round(Data$m,digits = 0), paste(Data$GF,Data$mean.t.GF, sep="_"),Data$mean.t.GF,Data$GF,Data$mean.t.GF,Data$length.t.GF))
  xx=subset(xx,Freq>0)
  xx=xx[order(xx$Var3),]
  return(xx)
}

Get_gamma_mean <- function(start_GF,stop_GF){
    EX= (stop_GF - start_GF)/2 + start_GF
    VarX= ((stop_GF - start_GF)/4)**2
    b= EX/VarX
    a=EX*b
    a=a+1
    mean_gamma= a/b
    return(round(mean_gamma))
}

Get_points <- function(input,lval,hval,log){
  # Read input file
  data <- read.table(input, header = F)
  
  
  # set dist and wcorr
  col=2
  dist <- data[,1]
  wcorr <- data[,col]
  ndist <- length(dist)  ## number of rows in dataset
  lval=lval
  hval=hval
  
  # check x lower value and y lower value
  data.sub <- data
  if ((lval > dist[1]) || (hval < dist[ndist])) {
    data.sub <- subset(data, ((dist <= hval) & (dist >= lval)))
  } 
  dist <- data.sub[,1]		# updated x values
  wcorr <- data.sub[,col]		# updated y values
  if(log==T){
    xx <- cbind(dist,log(wcorr))
    xx <- xx[complete.cases(xx),]
    wcorr <- xx[,2]
    wcorr <-c(wcorr,rep(NA,length(data.sub[,1])-length(wcorr)))
    dist <- xx[,1]
    dist <-c(dist,rep(NA,length(data.sub[,1])-length(dist)))
  }
  result_table <- data.frame(dist,wcorr)
  return(result_table)
}

Figure_1_C_1 <- function(input,log,Colour_P){
  
  Pulse <- Get_points(input[1],lval=0.05,hval=0.6,log)
  Continous <- Get_points(input[2],lval=0.05,hval=0.6,log)
  P_C_Data <- data.frame(Pulse,Continous)
  P_C_Data <- P_C_Data[P_C_Data$wcorr > -13,]
  
  Px <-  ggplot(data=P_C_Data,aes(y=wcorr,x=dist))+
    geom_point(aes(x=dist,y=wcorr),color=Colour_P[1],pch=4)+
    geom_point(aes(x=dist.1,y=wcorr.1),color=Colour_P[6],pch=18)+
    labs(y = "log weighted LD")+
    labs(x = "Genetic Distance in cM")
  #coord_cartesian(ylim = c(-13,-8),xlim=c(0,0.4),expand = 0)
  
  return(Px)
  
}

Figure_All_Real_Data <- function(input,log,GF_length,Colour_P){
  
  Real_Data <- c()
  for(i in input){
    xx <-Get_points(i,lval=0.05,hval=0.5,log)
    Real_Data <- c(Real_Data,xx)
  }
  Real_Data <- as.data.frame(Real_Data)
  Real_Data_names <- c()
  for(i in GF_length){
    Real_Data_names <- c(Real_Data_names,c('Genetic_Distance',i))
  }
  colnames(Real_Data) <- Real_Data_names
  Real_Data.melted <- melt(Real_Data, id = c("Genetic_Distance"))
  
  Px <-  ggplot(data =Real_Data.melted, aes(x = Genetic_Distance, y = value,color=variable)) +
    geom_point(pch=18)+
    coord_cartesian(ylim = c(-8,-14),expand = 0,xlim = c(0,0.5))+
    #geom_vline(xintercept=Split_time,linetype=3,color='black')+
    scale_color_manual(values = Colour_P)+
    labs(x = "Genetic distance")+
    labs(y = "log weighted LD")+
    labs(color="Admixture Duration")
  return(Px)
  
}

Figure_1_C_2 <- function(Timespan_GF_Models,time_l,Split_time,Mean_Time,Colour_P,max_y,max_x){
  
  n_GF_Models=length(Timespan_GF_Models)
  time=seq(1,time_l,1)
  
  Gamma_fun <- function(GF_Length,time_l,Split_time,Mean_Time){
    time=seq(1,time_l,1)
    EX= Mean_Time
    VarX= (GF_Length/4)**2
    b= EX/VarX
    a=EX*b
    
    GF_gamma <- dgamma(x=time,shape = a,scale = 1/b)
    GF_gamma[GF_gamma < 1e-6] = 0
    GF_gamma <- GF_gamma[1:Split_time]
    m2 <- c()
    for (i in GF_gamma){
      x <- i*(0.03/sum(GF_gamma))
      m2 <- c(m2,x)
    }
    m2 <- c(m2,rep(0,time_l-Split_time))
    cutoff_in_Percent=(sum(m2[2550:5001])/0.03)*100
    
    GF <- c(m2)
    return(GF)
  }
  GF <- c(seq(1,time_l,1))
  for(i in 1:n_GF_Models){
    Timespan <- Timespan_GF_Models[i]
    GF_x <- Gamma_fun(Timespan,time_l,Split_time,Mean_Time)
    GF <- cbind(GF,GF_x)
  }
  GF <- as.data.frame(GF)
  colnames(GF) <- c('Time',Timespan_GF_Models)
  GF.melted <- melt(GF, id = "Time")
  Px <-  ggplot(data =GF.melted, aes(x = Time, y = value,color=variable)) +
    geom_line(show.legend = F)+
    coord_cartesian(ylim = c(0,max(GF[max_y])),xlim = c(0,max_x),expand = 0)+
    geom_vline(xintercept=Split_time,linetype=3,color='black')+
    scale_color_manual(values = Colour_P)+
    labs(x = "Time in Generations")+
    labs(y = "Migration Rate")+
    labs(color="Admixture Duration")
  return(Px)
}

Theoratical_Lomax <- function(Timespan_GF_Models,max_Genetic_distance,Split_time,Mean_Time,Intercept,Colour_P){
  n_GF_Models=length(Timespan_GF_Models)
  
  Lomax_fun <- function(GF_Length,max_Genetic_distance,Split_time,Mean_Time,Intercept,log=T){
    Genetic_length=seq(0.01,max_Genetic_distance,0.01)
    EX= Mean_Time
    VarX= (GF_Length/4)**2
    b= EX/VarX
    a=EX*b
    Theta=b
    k=a+1
    Lomax_normal <- function(dist,k,theta,A) A*(1 + ((dist/100) /  theta))^-(k)
    Lomax_log <- function(dist,k,theta,A) -k* log(1 + ((dist/100) /  theta)) + log(A)
    if(log==T){
      ALD <-  Lomax_log(dist=Genetic_length,k = k ,theta = Theta, A=Intercept)
    }
    else{
      ALD <-  Lomax_normal(dist=Genetic_length,k = k ,theta = Theta, A=Intercept)
    }
    Lomax_Result <- cbind(Genetic_length,ALD,k,Theta)
    return(Lomax_Result)
  }
  Lomax_Result <- c()
  for(i in Timespan_GF_Models){
    xx=Lomax_fun(i,max_Genetic_distance,Split_time,Mean_Time,Intercept,log=T)
    Lomax_Result <- cbind(Lomax_Result,xx)
  }
  Lomax_Result <- as.data.frame(Lomax_Result)
  colnames_Lomax_Result <- c()
  for(time in Timespan_GF_Models){
    colnames_Lomax_Result <- c(colnames_Lomax_Result,c('Genetic_Distance',time,'k','Theta'))
  }
  colnames(Lomax_Result) <- colnames_Lomax_Result
  Lomax_Result.melted <- melt(Lomax_Result, id = c("Genetic_Distance",'k','Theta'))
  Px <-  ggplot(data =Lomax_Result.melted, aes(x = Genetic_Distance, y = value,color=variable)) +
    geom_line()+
    #coord_cartesian(ylim = c(0,max(ALD$'2')),expand = 0)+
    coord_cartesian(ylim = c(-8,-14),expand = 0,xlim = c(0,0.5))+
    #geom_vline(xintercept=Split_time,linetype=3,color='black')+
    scale_color_manual(values = Colour_P)+
    labs(x = "Genetic distance (cM)")+
    labs(y = "log weighted LD")+
    labs(color="Admixture Duration")
  return(Px)
}


######################## GG PLotting ###########################

## ggplot Figure 1 A
Plot_Fig_1_A <- function(Data,Colour_P){
  Px <-  ggplot(Data,aes(x=Var4,y=as.numeric(as.character(Var1)),colour=factor(Var4)))+
    geom_point(aes(size = Freq),show.legend = F)+
    geom_boxplot()+
    facet_grid(~as.factor(Var3),switch = "x")+
    geom_hline( aes(yintercept = as.numeric(as.character(Data$Var3)) ))+
    labs(x = "True Admixture Time")+
    labs(y = "Estimated Admixture Time")+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    coord_cartesian(ylim = c(0,2500), expand = 0)+
    scale_color_manual("Gene Flow Model",
                       values = c(Colour_P[1],Colour_P[6]),
                       labels = c("Pulse","Continuous"))
  return(Px)
  
}


### Figure 1 ggplot ###
Plot_Fig_1_B <- function(Data,Colour_P){
  Px <-  ggplot(Data,aes(x=Var7,y=as.numeric(as.character(Var1)),colour=factor(Var6)))+
    geom_point(aes(size = Freq),show.legend = F)+
    geom_boxplot()+
    facet_grid(~as.factor(Var6),switch = "x")+
    geom_hline( aes(yintercept = 1500 ))+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    labs(x = "Admixture Duration")+
    labs(y = "Estimated Admixture Time")+
    scale_color_manual("Admixture Duration",
                       values = Colour_P  
                       
    )
  return(Px)
  
}

```


```{r fig1,message=FALSE, echo=FALSE,warning=FALSE,fig1.pos="H",fig.width=9,fig.height=3,fig.cap="\\label{fig:fig1} A) Chromosomal sections with introgressed segments (grey). Introgressed variants (green circles) are in high LD compared to the background (stars). The ALD approach estimates linkage between the introgressed variants, wheres the haplotype  approach tries to estimate the segment directly. B) Migration rate per #generation modeled using a Gamma distribution for different gene flow length, dotted line indicates maximum time of gene flow. C) The #expected LD decay modeled as a Lomax distribution for the different length."}


t_d=c(1,100,200,400,800,1000,1500,2000,2500)
cbPalette_viridis <- viridis(length(t_d),option = "D")

P_Gamma <- Figure_1_C_2(c(t_d),3000,2550,1500,Colour_P = cbPalette_viridis,3,3100)

P_Lomax <-Theoratical_Lomax(c(t_d),0.5,2550,1500,0.0004,Colour_P = cbPalette_viridis)

Intro_graphic <- readPNG(source = "New_Intro_fig_2.png",native = F)

im_A <- ggplot() + 
    background_image(Intro_graphic) +
    theme_bw()+
    theme(plot.margin = margin(t=0, l=0, r=0, b=0, unit = "cm"),
    panel.border = element_blank())
ggsave(file="GG_New_Intro_fig.png", width=6, height=8, dpi=300)

im_AA <- cowplot::ggdraw() +
  cowplot::draw_image("GG_New_Intro_fig.png")

ggarrange(im_AA,P_Gamma,P_Lomax,
          labels = c("A","B", "C"),
          ncol = 3, nrow = 1,common.legend = T,legend = 'bottom')



```


\section{Methods}\label{methods}

We conducted various simulations to assess the effect of continuous
admixture compared to a pulse under ideal circumstances. We changed
recombination and demographic parameters to simulate more realistic
models. We compared the effect of these parameters together with
analysis parameters to the effect of continuous admixture on the
estimates. After assessing these effects we evaluate the possible
parameter range for using a Lomax distribution to fit the ALD decay,
enabling to obtain a duration of continuous admixture. We used both admixture models on real data. We fitted several admixture scenarios with different durations to ALD data from the 1000 Genomes Project with 3 high coverage Neandertals and to directly inferred Neandertal fragments using data from Skov \& Coll Maci\`{a} et al. 2020 \cite{skov_nature_2020}.

\subsection{Simulations}\label{simulations}

We used the msprime coalescent simulator
(\cite{kelleher_efficient_2016}) for simulations with sample sizes
chosen to reflect presently available data. For ALD simulations we simulate 176 diploid
African individuals and 170 diploid non-Africans, corresponding to the
number of Yoruba (YRI) and Central Europeans from Utah (CEU)
sequences in the 1000 Genomes project data
(\cite{the_1000_genomes_project_consortium_global_2015}). Since three
high coverage Neandertal sequences are available
(\cite{prufer_complete_2013,prufer_high-coverage_2017,mafessoni_high_coverage_2020}) we choose to
simulate three diploid genomes. For each individual we simulated 20
chromosomes with a length of 150 Mb each. The mutation rate was set for
all simulations to \(2*10^{-8}\) per base per generation. The
recombination rate was set to \(1*10^{-8}\) per base pair per generation
unless specified otherwise. The demographic parameters are based on
previous studies dating Neandertal admixture
(\cite{sankararaman_date_2012,fu_genome_2014,moorjani_genetic_2016}). In
the ``simple'' model (Supplement Figure \ref{fig:figS1} A), the effective
population size is assumed constant at Ne=10000 for all populations, the
split time between modern humans and Neandertals is 10000 generations
ago and the split between Africans and non-Africans is 2550
generations ago. The migration rate from Neandertals into non-Africans
was set to zero before the split from Africans, to ensure no Neandertal
ancestry in Africans. Each simulation was repeated 100 times. We used a simplified version of the demographic model described in Skov et al. 2018 \cite{skov_detecting_2018} for the direct inference of admixture segments (Supplement Figure\ref{fig:figS1} C). Here we simulate 100 haploid non-Africans with a starting effective population size of 3899. The mutation rate and recombination rate are  \(1.2*10^{-8}\) per base per generation. Number of chromosomes, length of the chromosome and all split times are the same as in the simple demographic ALD simulations. We sampled 500 haploid Africans as outgroup individuals.

\subsubsection{Gene Flow}\label{gene flow}

In the admixture pulse model, gene flow is a one generation long pulse,
resulting in an exponentially distributed admixture-induced linkage
disequilibrium (ALD) decay curve (Eq. \ref{eq:1}), with $\lambda$ as
the rate parameter of the exponential distribution holding the  time since the admixture event $t$ with $l$ ,here being either the genetic
distance \(d\) between two SNPs or the genetic length of an admixture segment,

\begin{equation}
\begin{split}
\label{eq:1}
L_i &\sim exp(\lambda) \\
\mathbb{E}[l] &= \frac{1}{\lambda} = \frac{1}{t}
\end{split}
\end{equation}

Continuous gene flow $m$ over time with the random variable $t \in \{t_1,t_2,...,t_n\}$ was modeled as a gamma distribution (Eq.
\ref{eq:2})

\begin{equation}
\label{eq:2}
m_i \sim \Gamma(k,\theta)
\end{equation}

Where k is the shape and \(\theta\) the scale parameter. The parameter
values are chosen such that the mean length of the
exponentially distributed ALD decay or segment length curve resulting from the one
generation admixture pulse, is equal to the mean length as a result of continuous migration with the same total amount of
migrants, modeled using a Lomax distribution with shape being $k+1$ and the scale $\frac{1}{\theta}$ (Eq. \ref{eq:3})

\begin{equation}
\begin{split}
\label{eq:3}
L_i &\sim Lomax(k+1,\frac{1}{\theta}) \\
\mathbb{E}[l] &= \frac{1}{\lambda} = \frac{1}{k\theta}
\end{split}
\end{equation}

\begin{equation}
\label{eq:4}
t_{m}=\mathbb{E}[m] = k \theta
\end{equation}

\begin{equation*}
\nonumber
where \qquad k=t_m \, \frac{1}{\theta} \qquad and \qquad \theta=\frac{1}{t_{m}Var[m]}
\end{equation*}

Equation (Eq. \ref{eq:4}) shows the relationships between the
distribution parameters such that the resulting decay mean length are
equal. Here \(l\) is in generations. $t_{m}$ is the mean time of admixture equal to the mean of the Gamma distribution ($\mathbb{E}[m]$) and $Var[m]=(\frac{t_d}{4})^2$ its variance with $t_d$ as the duration of admixture in generations.

\subsubsection{Recombination map}\label{recombination map}

Uncertainties in the recombination map were previously shown to bias
admixture time estimates. To investigate the effect of more realistic
recombination rate variation we simulated samples using a recombination map. For ALD simulations we
either used the African-American-Map (\cite{hinch_landscape_2011} or
the HapMap phase 3 (\cite{HapMapConsortium_second_2007}) for simulations
under a variable recombination rate, for simplicity, we used the same
recombination map (150 Mb of chromosome 1, excluding the first 10 Mb)
for all simulated chromosomes. The mean recombination rate was
calculated from the 150 Mb map (\(1.017 \, \frac{cM}{Mb}\) AAMap and
\(0.992 \, \frac{cM}{Mb}\) HapMap). To emulate uncertainties in the
genetic map we either: used the mean recombination rate from the
respective map to calculate the genetic distance from the physical
distance for each SNP, used the other map to assign distances
(e.g.~AAMap used for the msprime simulation and HapMap used to assign
genetic distances) or used the same map for simulation and assigning
genetic distances. For simulating the Icelandic fragment we used 150 Mb of chromosome 1 from the deCODE map \cite{kong_fine-scale_2010} \(0.914 \, \frac{cM}{Mb}\).

\subsubsection{Complex demography}\label{inferred demography}

Demography such as population size changes are known to influence LD
patterns and can create false admixture signals. To test the impact of
demographic history on admixture time estimates, we simulate a more
realistic and complex demographic history with substructure in the ancestral human population and additional gene flow between Africans and non-Africans after the Neandertal admixture (Figure \ref{fig:figS1}. The 
effective population
sizes are based on estimates from Neandertal and present-day human
genomes. MSMC estimates from YRI as representatives for Africans and CEU
for non-Africans from Schiffles \& Durbin 2014
(\cite{schiffels_inferring_2014}) were used together with PSMC
(\cite{li_inference_2011}) inferred demographic model for Neandertals
based on the Vindija33.19 high-coverage genome
(\cite{prufer_high-coverage_2017}). In order to use the effective
population size estimates at a given time point for modern humans from
Schiffels \& Durbin 2014 (Figure 4 Excel Table) for our simulations, we
first transformed the time points given in years back to generations by
using 30 years for one generation, as assumed in the original study.
Second, since the original estimates are based on a different mutation
rates (\(1.25*10^{-8} \frac{bp}{gen}\)), we corrected all estimates for
the mutation rate used in the simulations
(\(2*10^{-8} \frac{bp}{gen}\)). The split times between Neandertals and
modern humans was kept the
same as in the simple simulations (10000 generations ago). In the complex model we simulated substructure in Africa starting from 3550 till the final split at 2550 generations ago with a per generation migration rate between the two subpopulations of 0.001. The population size of the ancestor of Neandertals and
humans before the split was set to 18296 (taken from the MSMC results). To simulate branch shortening
caused by the extinction of Neandertals, Neandertals were sampled 750
generations before the Africans and non-Africans. We simulated an additional admixture event between African and non-African populations with a total migration rate of 0.01 starting from 200 till 50 generations ago.

\subsection{1000 Genomes Data}\label{1000 Genomes Data}

We used the 1000 Genomes phase 3 data together with the Altai, Vindija and Chagyrskaya high coverage Neandertals.  We filtered for all unrelated individuals from the YRI as representatives of unadmixed Africans and all CEU as admixed Europeans. We only considered biallelic sites. The sites were polarized relative to the Chimpanzee base (panTro4). We used the CEU specific fine-scale recombination map (\cite{spence_inference_2019}) to convert the physical distance between sites into genetic distance. 

\subsection{Neandertal segments in Icelanders}\label{1000 Genomes Data}

We used the identified archaic segments from Skov \& Coll Maci\`{a} et al. 2020. The segments are pre-filtered using a posterior probability cutoff of 0.9 for identified archaic segments. We filtered the data set for archaic segments identified as Neandertal (Altai and Vindija). We used the DeCode genetic map to convert the physical segment length in bp to genetic length in cM. We used a lower and upper cutoff of 0.05 - 1.2 cM for the length of segments

\subsection{Admixture time estimates}\label{admixture time estimates}

\subsubsection{Ascertainment scheme}\label{asceteinment scheme}

Ascertainment schemes are used to select certain variable positions of
interest in a genome. Ascertainment schemes can be used to enrich for
Neandertal informative sites in the test population to remove noise and
amplify the ALD signal (\cite{sankararaman_date_2012}). Two
ascertainment schemes were tested to enrich for Neandertal informative
sites, which were used previously
(\cite{sankararaman_date_2012,fu_genome_2014}). The lower-enrichment
ascertainment scheme filters for SNPs fixed for the ancestral state in
Africans and polymorphic in Neandertals. The higher-enrichment
ascertainment scheme restricts the analysis on SNPs fixed for the
ancestral state in Africans, polymorphic in Neandertals and polymorphic
in non-Africans.

\subsubsection{ALD calculation and curve fitting}\label{ALD calculation and curve fitting}

The pairwise weighted LD between the ascertained SNPs a certain genetic
distance \(d\) apart was calculated using ALDER
(\cite{loh_inferring_2013}). A minimal genetic distance \(d_0\) between
SNPs is set either to 0.02 cM and 0.05 cM. This minimal distance cutoff
removes extreme short range LD likely confounded by non-ALD,
facilitating the fitting procedure. To obtain the mean time estimates
the data is fitted with an exponential distribution (one generation pulse model) shown in equation
\ref{eq:5}, using a non-linear least-square optimization algorithm
implemented in R (\cite{R_Core_Team_2019}). Where \emph{A} is the
intercept, $t_m$ the mean time since the admixture event in generations,
\emph{d} the genetic distance in cM and \emph{c} is a constant modeling
background LD. The model was fitted following Moorjani et al 2016
(\cite{moorjani_genetic_2016}). The duration of continuous admixture is
modeled using the Lomax fit shown in Eq. \ref{eq:6}. We used the
notation from Kozubowski et al. 2008 (\cite{Kozubowski_Testing_2008}). Holding $\frac{1}{\theta} = \frac{t_m}{k}$.
The starting value of $t_m$  is taken from the exponential fit to ensure
convergence of the model.


\begin{equation}
\label{eq:5}
ALD \sim\ A\,e^{-t_m \:d}+c
\end{equation}

\begin{equation}
\label{eq:6}
ALD \sim\ A\,\left( \frac{1}{1 + \frac{1}{k}t_m \:d}\right) ^k+c
\end{equation}

\subsubsection{Fitting of directly inferred segments length distribution}\label{Fitting of directly inferred segments length distribution}

We fitted the density of the length of directly inferred introgressed segments either to the exponential (Eq. \ref{eq:7}) or lomax (Eq. \ref{eq:8}) probability density function. We set a lower and upper length cutoff, to account for non uniform detection capability of the Skov et al. 2018 model across different length of introgressed segments. To correct our parameter estimate from the respective pdf we divided it by the interval between the lower and upper cutoff of the pdf. 

\begin{equation}
\label{eq:7}
Pr(l_{lower}<=L=<l_{upper}) \sim \frac{exp(l,\lambda)}{exp(L>=l_{lower},\lambda)-exp(L<=l_{upper},\lambda)}
\end{equation}

\begin{equation}
\label{eq:8}
Pr(l_{lower}<=L=<l_{upper}) \sim \frac{lomax(l,k+1,\frac{1}\theta)}{lomax(L>=l_{lower},k+1,\frac{1}\theta)-lomax(L<=l_{upper},k+1,\frac{1}\theta)}
\end{equation}

\subsection{Modeling parameter effect sizes}\label{modeling prameter effect sizes}

To model and compare parameter effect sizes we simulated 100
replications for each combination of potentially influencing
parameters: ascertainment scheme ($A_i$ = LES/HES), minimal genetic distance
($M_i$ = \(d_{0}=0.02\,cM\)/\(d_{0}=0.05\,cM\)), demography ($D_i$ = simple/complex),
recombination rate ($R_i$ = constant/variable), gene flow model
($G_i$ = pulse/continuous). Results of simulations where the nls-optimization to
fit the ALD decay curve did not converge were removed (11 out of 3200).
We used a Generalized Linear Model (GLM)  to estimate the effect
size of the different parameters (Eq.
\ref{eq:8}). The difference between the estimated
admixture time and the true admixture time, the error in the estimate,
was standardized using the true time as the mean. The standardized error in this model is the response to the parameters as model
predictors. We choose the Normal distribution as the likelihood function being the maximum entropy distribution in our case. The mean of the Normal distribution is then described by a fixed effect size model of the predictors (factors) coded as indicator variables. We obtained the posterior probability using a Hamiltonian Monte Carlo MCMC algorithm. The Markov chains converged to the target distribution (Rhat = 1) and efficiently sampled from the posterior (Supplement Table \ref{tab:tableS1}).  

\begin{equation}\label{eq:8}
\begin{split}
E_i &\sim Normal(\mu_i,\sigma) \\
\mu_i &= \alpha + \beta_aA_i + \beta_mM_i + \beta_dD_i + \beta_rR_i + \beta_gG_i \\
\alpha &\sim Normal(0,2) \\
\beta_a,\beta_m,\beta_d,\beta_r,\beta_g &\sim Normal(0,2) \\
\sigma &\sim Exponential(1)
\end{split}
\end{equation}


\section{Results}\label{results}

\subsection{Introduction to result}\label{introduction to result}

We used coalescent simulations of Neandertal admixture into non-African humans to investigate multi-generation continuous admixture, using a Gamma distribution describing the per generation migration rate. Focusing on the ALD approach, the ALDER program was used to infer the decay of LD between ascertained sites informative for Neandertal introgression in non-Africans. The ascertained ALD was fitted with an exponential distribution assuming a one-generation admixture pulse.  We simulated this scenario using different conditions of recombination and demography as well as deploying different ascertainment schemes and LD cutoffs. A Generalized Linear Model (GLM) was used to compare all these factors with the effect of multi-generation continuous admixture on the pulse assumption. To get the duration of the admixture we introduce a new fitting approach deploying the LOMAX distribution. We test this new fitting with the most inferential factors from the previous analysis on simulated and real data using the ALD and the direct inference of introgressed segment approaches.

\subsection{Theoretical framework for continuous admixture}\label{theoretical framework for continuous admixture}

First we want to establish the model of continuous admixture and an
expectation of the segment length distribution under this model in an
ideal-case from perfect data. For this purpose, we assume that the
lengths of introgressed segments are perfectly known. In this case, under
some models, the distribution of introgressed segment lengths \(L_i\) can
be written as

\begin{equation}
L_i \sim exp(t)
\end{equation}

where $t$ is the time when the fragment entered the population. The mean fragment length will vary  depending on the model assumptions and
recombination rate \(r\) (\citep{liang_lengths_2014}). E.g under the SMC,
\(L_i = t(1-m)r\), and under the SMC' allowing for back coalescence,
\(L_i = 2N(1-m)(1-exp^{-t/2N})r\). For Neandertal admixture where
\(m\), the admixture fraction, is typically low, the exponential
assumption is satisfied (\cite{liang_lengths_2014}). For scenarios where
the length of admixture tracts is not exponential, e.g. because
admixture is recent or very old, our results do not apply.

It is widely assumed that Neandertal ancestry entered the modern human
population over a very short period (one-generation admixture pulse). As an alternative model describing multi-generation admixture, we need to
consider \(t\) not as a single point in time, but as a random variable
itself that follows a mixture distribution \(\mathcal{D}_t\). The most
widely studied is a small number of discrete ``pulses'' of admixture, in
which case \(\mathcal{D}_t\) is categorical. Here, we instead assume a
continuous multi-generation admixture \(\mathcal{D}_t\); more precisely we assume \(\mathcal{D}_t\)
follows a \(\Gamma(k, \theta)\)-distribution. This has a number of
advantages:

\begin{itemize}
    \item We just need two parameter $k$ and $\theta$, that can be interpreted as the duration of gene flow, instead of the minimal of two additional parameters required for the pulse model.
    \item The segment length distribution $L_i$ follows a Lomax-distribution, i.e. has the analytical density $Pr(L=l) = \frac{1}{\theta k-1} (1+l\frac{1}{\theta})^{-(k-1)}$
    \item The mean segment-length is  $\frac{1}{k \theta}$ for all $k > 0$, and undefined otherwise. 
    \item As $k$ approaches infinity, we recover the exponential distribution. Thus, if segment length are directly inferred, one can use a likelihood-ratio test to distinguish continuous from discrete gene flow. As the special case of exponentially lies on the boundary of the parameter space, the test-statistic does not follow a $\chi^2$-distribution (\cite{Kozubowski_Testing_2008}). Model selection using a LRT is however not possible when segment length are indirectly inferred by ALD.
\end{itemize}

Using this model we i) examining the effect of continuous admixture on
the admixture time estimates calculated using the exponential model
assuming a pulse like admixture. ii) comparing this effect to the
effects by demography, recombination rate and analysis parameters used
for the indirect inference of admixture segment length using ALD, namely
the ascertainment scheme and the minimal distance between SNPs. iii) are
interested under which conditions the parameters of the
Lomax-distribution can be estimated accurately for a scenario of
Neandertal admixture and if it is possible to distinguish a pulse-like
admixture event (resulting in exponentially-distributed ALD)
from a continuous event (resulting in Lomax-distributed ALD).




\subsection{The effect of continuous admixture on the admixture time estimates}\label{the effect of continuous admixture on the admixture time estimates}


```{r message=FALSE, echo=FALSE,warning=FALSE}

# New Data
Figure_1_A_Data <- Results_Table("Fig_1_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_1_A_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0.txt")
Figure_1_A_Data <- Figure_1_A_Data[Figure_1_A_Data$error=="no_error",]
Figure_1_B_Data <- Results_Table("Fig_1_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_1_B_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0.txt")


Fig_A_1 <- Get_Data_Table(Figure_1_A_Data)
Fig_A_1$Var1 <- as.numeric(as.character(Fig_A_1$Var1))
Fig_A_1$Var3 <- round(as.numeric(as.character(Fig_A_1$Var3)))
Fig_A_1_Means <- aggregate(Fig_A_1[,c(1,3)],list(Fig_A_1$Var2), mean)
Fig_A_1_Means_diff <- data.frame(sqrt((Fig_A_1_Means$Var1-Fig_A_1_Means$Var3)^2)/Fig_A_1_Means$Var3)
Fig_A_1_Means_diff_pulse <- round(range(Fig_A_1_Means_diff[1:5,]*100))
Fig_A_1_Means_diff_continuous <- round(range(Fig_A_1_Means_diff[6:10,]*100))
```

To asses the effect of estimating admixture time assuming a one-generation pulse when the real gene flow is actually continuous over multiple generations,
we compared the deviation from the true mean time of admixture for simulations under a one-generation pulse with the one of multi-generation continuous gene flow with the same mean time. We took the scenario of Neandertal admixture into non-Africans simulated using coalescent simulations.
The total amount of gene flow \(m\) from Neandertals into non-Africans
in the two models is equal. Gene flow is modeled using a Gamma
distribution (Eq. \ref{eq:2}) holding the migration rate per generation
for different length of continuous gene flow (Figure \ref{fig:fig1} B).
The shape and scale parameter of the Gamma distribution are chosen such
that the resulting weighted LD decay curves as functions of genetic
distance share the same mean for a pulse (Eq. \ref{eq:1}) and a
continuous admixture (Eq. \ref{eq:3}). Sites informative for Neandertal
introgression into non-Africans where enriched using the
Lower-Enrichment Ascertainment scheme (LES) filtering for SNPs ancestral in
all Africans and polymorphic in Neandertals. The pairwise weighted LD
between the ascertained SNPs was computed using the ALDER program with a minimal distance between the SNPs of 0.05 cM.
Figure \ref{fig:fig1} C shows the expected log weighted LD for different
length of continuous admixture ranging from a one generation pulse to
1500 generations.



First, we compared estimates for different mean admixture times ranging from 250 generations ago to 2000 generations ago. We either used a pulse-like gene flow model where the gene flow is only one generation long or a continuous gene flow model for the simulations. The duration of gene flow under the continuous model is 50\% of the mean time (if the mean time is 250 generations ago gene flow ranges from 325 to 175 generations ago). Assuming only a one generation pulse to estimate the mean time, revealed only minor deviations between the two scenarios and the true
admixture time of  `r Fig_A_1_Means_diff_pulse[1]`% to `r Fig_A_1_Means_diff_pulse[2]`% for the pulse and `r Fig_A_1_Means_diff_continuous[1]`% to `r Fig_A_1_Means_diff_continuous[2]`% for the continuous (Figure \ref{fig:fig2} A). 

To
further investigate the effect of pulse and continuous gene flow on the
admixture time estimates, we compared different durations of continuous
admixture with a fixed mean time of admixture of 1500
generations ago, displayed in Figure \ref{fig:fig2} B. Estimates between
pulse and continuous admixture start to deviate for 800 generations of
continuous admixture, with increasingly lower estimates for simulations
under continuous admixture compared to simulations under a pulse scenario per increase of admixture duration. This bias is likely caused
by the differences in LD between sites entered in the tails of the gamma
distribution. LD between sites arising from early admixture events,
simulated by the right tail of the gamma distribution, is not detected
anymore, while LD between sites from late admixture is still present,
biasing the estimate towards younger dates. However, deviations in
estimates between the two scenarios of \textasciitilde{}100 generations
in the most extreme case are moderate compared to the mean admixture
time of 1500 generations.

In conclusion, the differences in mean time estimates between a pulse and a continuous admixture assuming a one-generation pulse are moderate, even for very long continuous admixture scenarios. This makes point estimates for mean admixture time compatible with long continuous admixture.

```{r fig2,message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=8,fig.height=8,fig.cap="\\label{fig:fig2} A) Comparison of mean admixture time estimates between pulse and continuous gene flow for different admixture times. The length of continuous gene flow corresponds to 50 % of the mean admixture time, black line indicates true mean admixture time. B) Comparison of mean admixture time estimates for simulations with a mean time of admixture of 1500 generations ago, at a varying length of gene flow. Boxplot created from 100 simulation replicates, respectively."}
### Plot in one window

P1_1 <- Plot_Fig_1_A(Fig_A_1,Colour_P = cbPalette_viridis)

Fig_B_1 <- Get_Data_Table(Figure_1_B_Data)
Fig_B_1$Var7 <- rep('xx',length(Fig_B_1$Var1))
P1_2 <- Plot_Fig_1_B(Fig_B_1,Colour_P = cbPalette_viridis)

ggarrange(P1_1,P1_2,
          labels = c("A","B"),
          ncol = 2, nrow = 2,common.legend = F,legend = 'bottom', align = "h")
```


\subsection{Comparing effect sizes}\label{comparing effect sizes}


```{r message=FALSE, echo=FALSE,warning=FALSE, cache=T}

##### GLM for the bais on the admixture dates #####


### Read in data ###

Simple_D_Sim_1 <- Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_A-GF_Model_IV-min_dist_Fit-0.02-ascertainment-0.txt")
Simple_D_Sim_1$Gamma_mean <- Get_gamma_mean(Simple_D_Sim_1$GF_Start,Simple_D_Sim_1$GF_Stop)
Simple_D_Sim_1$Demography <- "0_Simple"
Simple_D_Sim_1$Recomb.rate <- "0_constant"
Simple_D_Sim_1$Sim_id <- ifelse(Simple_D_Sim_1$Ascertained==0,"Simple_D_Sim_LES_0","Simple_D_Sim_HES_0")

Simple_D_Sim_2 <- Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_A-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0.txt")
Simple_D_Sim_2$Gamma_mean <- Get_gamma_mean(Simple_D_Sim_2$GF_Start,Simple_D_Sim_2$GF_Stop)
Simple_D_Sim_2$Demography <- "0_Simple"
Simple_D_Sim_2$Recomb.rate <- "0_constant"
Simple_D_Sim_2$Sim_id <- ifelse(Simple_D_Sim_2$Ascertained==0,"Simple_D_Sim_LES_1","Simple_D_Sim_HES_1")

Inferred_D_Sim_1 <- Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_B_complex-GF_Model_IV-min_dist_Fit-0.02-ascertainment-0.txt")
Inferred_D_Sim_1$Gamma_mean <- Get_gamma_mean(Inferred_D_Sim_1$GF_Start,Inferred_D_Sim_1$GF_Stop)
Inferred_D_Sim_1$Demography <- "Inferred"
Inferred_D_Sim_1$Recomb.rate <- "0_constant"
Inferred_D_Sim_1$Sim_id <- ifelse(Inferred_D_Sim_1$Ascertained==0,"Inferred_D_Sim_LES_0","Inferred_D_Sim_HES_0")

Inferred_D_Sim_2 <- Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_B_complex-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0.txt")
Inferred_D_Sim_2$Gamma_mean <- Get_gamma_mean(Inferred_D_Sim_2$GF_Start,Inferred_D_Sim_2$GF_Stop)
Inferred_D_Sim_2$Demography <- "Inferred"
Inferred_D_Sim_2$Recomb.rate <- "0_constant"
Inferred_D_Sim_2$Sim_id <- ifelse(Inferred_D_Sim_2$Ascertained==0,"Inferred_D_Sim_LES_1","Inferred_D_Sim_HES_1")

Recom_Sim_1_1 <- Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_C_corrected-GF_Model_IV-min_dist_Fit-0.02-ascertainment-0_comp.txt")
Recom_Sim_1_2 <- Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_C_corrected-GF_Model_IV-min_dist_Fit-0.02-ascertainment-1_comp.txt")
Recom_Sim_1 <- rbind(Recom_Sim_1_1,Recom_Sim_1_2)
rm(Recom_Sim_1_1,Recom_Sim_1_2)
Recom_Sim_1$Gamma_mean <- round(Recom_Sim_1$mean.t.GF)
Recom_Sim_1$Demography <- "0_Simple"
Recom_Sim_1$Recomb.rate <- "variable"
Recom_Sim_1$m <- Recom_Sim_1$m
Recom_Sim_1$Sim_id <- ifelse(Recom_Sim_1$Ascertained==0,"Recom_D_Sim_LES_0","Recom_D_Sim_HES_0")

Recom_Sim_2_1 <- Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_C_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0_comp.txt")
Recom_Sim_2_2 <- Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_C_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-1_comp.txt")
Recom_Sim_2 <- rbind(Recom_Sim_2_1,Recom_Sim_2_2)
rm(Recom_Sim_2_1,Recom_Sim_2_2)
Recom_Sim_2$Gamma_mean <- round(Recom_Sim_2$mean.t.GF)
Recom_Sim_2$Demography <- "0_Simple"
Recom_Sim_2$Recomb.rate <- "variable"
Recom_Sim_2$m <- Recom_Sim_2$m
Recom_Sim_2$Sim_id <- ifelse(Recom_Sim_2$Ascertained==0,"Recom_D_Sim_LES_0","Recom_D_Sim_HES_0")

Recom_Sim_and_Inf_1_1 <-  Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_D_Complex_corrected-GF_Model_IV-min_dist_Fit-0.02-ascertainment-0_comp.txt")
Recom_Sim_and_Inf_1_2 <-  Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_D_Complex_corrected-GF_Model_IV-min_dist_Fit-0.02-ascertainment-1_comp.txt")
Recom_Sim_and_Inf_1 <- rbind(Recom_Sim_and_Inf_1_1,Recom_Sim_and_Inf_1_2)
rm(Recom_Sim_and_Inf_1_1,Recom_Sim_and_Inf_1_2)
Recom_Sim_and_Inf_1$Gamma_mean <- round(Recom_Sim_and_Inf_1$mean.t.GF)
Recom_Sim_and_Inf_1$Demography <- "Inferred"
Recom_Sim_and_Inf_1$Recomb.rate <- "variable"
Recom_Sim_and_Inf_1$m <- Recom_Sim_and_Inf_1$m
Recom_Sim_and_Inf_1$Sim_id <- ifelse(Recom_Sim_and_Inf_1$Ascertained==0,"Recom_Sim_and_Inf_LES_0","Recom_Sim_and_Inf_HES_0")

Recom_Sim_and_Inf_2_1 <-  Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_D_Complex_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0_comp.txt")
Recom_Sim_and_Inf_2_2 <-  Results_Table("Fig_2_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_2_D_Complex_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-1_comp.txt")
Recom_Sim_and_Inf_2 <- rbind(Recom_Sim_and_Inf_2_1,Recom_Sim_and_Inf_2_2)
rm(Recom_Sim_and_Inf_2_1,Recom_Sim_and_Inf_2_2)
Recom_Sim_and_Inf_2$Gamma_mean <- round(Recom_Sim_and_Inf_2$mean.t.GF)
Recom_Sim_and_Inf_2$Demography <- "Inferred"
Recom_Sim_and_Inf_2$Recomb.rate <- "variable"
Recom_Sim_and_Inf_2$m <- Recom_Sim_and_Inf_2$m
Recom_Sim_and_Inf_2$Sim_id <- ifelse(Recom_Sim_and_Inf_2$Ascertained==0,"Recom_Sim_and_Inf_LES_0","Recom_Sim_and_Inf_HES_0")

# first build model only with Simple and Inferred demography
#xdata <- rbind(Simple_D_Sim_1,Simple_D_Sim_2,Inferred_D_Sim_1,Inferred_D_Sim_2)

######## model with response beeing the difference between the estimated Admixture time and the true one #####
# full model with Ascertainement, min dist, Demographi and recombination rate as predictore but no interactions
xdata.M.3 <- rbind(Simple_D_Sim_1,Simple_D_Sim_2,Recom_Sim_1,Recom_Sim_2,Inferred_D_Sim_1,Inferred_D_Sim_2,Recom_Sim_and_Inf_1,Recom_Sim_and_Inf_2)
rm(Simple_D_Sim_1,Simple_D_Sim_2,Recom_Sim_1,Recom_Sim_2,Inferred_D_Sim_1,Inferred_D_Sim_2,Recom_Sim_and_Inf_1,Recom_Sim_and_Inf_2)
xdata.M.3$TID <- ifelse(xdata.M.3$GF=='0_Pulse',paste(xdata.M.3$Sim_id,'P',sep = '_'),paste(xdata.M.3$Sim_id,'C',sep = '_')) 


#xdata.M.3$Diff <- xdata.M.3$m - xdata.M.3$mean.t.GF
xdata.M.3$Diff <- xdata.M.3$m - xdata.M.3$Gamma_mean
# remove all estimates where nls reported an error
xdata.M.3_no_error <- xdata.M.3[xdata.M.3$error=="no_error",]
xdata.M.3_no_error$Sim_id_int <- as.integer(as.factor(xdata.M.3_no_error$TID))

xdata.M.3_no_error$Diff_s <- (xdata.M.3_no_error$m - xdata.M.3_no_error$Gamma_mean)/sd(xdata.M.3_no_error$m)



Bdata_index_s_2 <- list(
  E = (xdata.M.3_no_error$Diff_s),
  Id = xdata.M.3_no_error$Sim_id_int,
  A = ifelse(xdata.M.3_no_error$Ascertained==0,0,1),
  MD = ifelse(xdata.M.3_no_error$min_dist=="0.05",0,1),
  D = ifelse(xdata.M.3_no_error$Demography=="0_Simple",0,1),
  R = ifelse(xdata.M.3_no_error$Recomb.rate=="0_constant",0,1),
  GF = ifelse(xdata.M.3_no_error$GF=="0_Pulse",0,1)
)



Effect_size_fixed_s_2 <- ulam(
  alist(
    E ~ dnorm(mu,sigma),
    mu <- a + bA*A + bm*MD + bD*D + bR*R + bG*GF ,
    a ~ dnorm( 0 , 2 ),
    c(bA,bm,bD,bR,bG) ~ dnorm( 0 , 2 ),
    sigma ~ dexp(1)
  ), data=Bdata_index_s_2, chains=4 , cores=4 , log_lik = T)

```

```{r eval=FALSE,message=FALSE, echo=FALSE,warning=FALSE, cache=T}
# Alternative models


Bdata_index_s_2 <- list(
  E = (xdata.M.3_no_error$Diff_s),
  Id = xdata.M.3_no_error$Sim_id_int,
  A = ifelse(xdata.M.3_no_error$Ascertained==0,0,1),
  MD = ifelse(xdata.M.3_no_error$min_dist=="0.05",0,1),
  D = ifelse(xdata.M.3_no_error$Demography=="0_Simple",0,1),
  R = ifelse(xdata.M.3_no_error$Recomb.rate=="0_constant",0,1),
  GF = ifelse(xdata.M.3_no_error$GF=="0_Pulse",0,1)
)

Effect_size_fixed_s <- ulam(
  alist(
    E ~ dnorm(mu,sigma),
    mu <- a + bA*A + bm*MD + bD*D + bR*R + bG*GF ,
    a ~ dnorm( 0 , 2 ),
    c(bA,bm,bD,bR,bG) ~ dnorm( 0 , 2 ),
    sigma ~ dexp(1)
  ), data=Bdata_index_s_2, chains=4 , cores=4 , log_lik = T)

Effect_size_fixed_id_s <- ulam(
  alist(
    E ~ dnorm(mu,sigma),
    mu <- a[Id] + bA*A + bm*MD + bD*D + bR*R + bG*GF ,
    a[Id] ~ dnorm( 0 , 2 ),
    c(bA,bm,bD,bR,bG) ~ dnorm( 0 , 2 ),
    sigma ~ dexp(1)
  ), data=Bdata_index_s_2, chains=4 , cores=4,iter=4000, log_lik = T)

Effect_size_varying_intercepts_s <- ulam(
  alist(
    E ~ dnorm(mu,sigma),
    mu <- a[Id] + bA*A + bm*MD + bD*D + bR*R + bG*GF ,
    a[Id] ~ dnorm( a_bar , sigma_a ),
    c(bA,bm,bD,bR,bG) ~ dnorm( 0 , 2 ),
    a_bar ~ dnorm(0,1),
    sigma_a ~ dexp(1),
    sigma ~ dexp(1)
  ), data=Bdata_index_s_2, chains=4 , cores=4 , log_lik = T)


Effect_size_fixed_with_all_pairwise_interactions <- ulam(
  alist(
    E ~ dnorm(mu,sigma),
    mu <- a + bA*A + bm*MD + bD*D + bR*R + bG*GF + bmd*MD*D + bma*MD*A + bmr*MD*R + bmg*MD*GF + brd*R*D + bra*R*A + brg*R*GF + bad*A*D + 
      bag*A*GF + bdg*D*GF ,
    a ~ dnorm( 0 , 2 ),
    c(bA,bm,bD,bR,bG,bmd,bma,bmr,bmg,brd,bra,brg,bad,bag,bdg) ~ dnorm( 0 , 2 ),
    sigma ~ dexp(1)
  ), data=Bdata_index_s_2, chains=4 , cores=4 ,log_lik = T)


compare(Effect_size_fixed_s,Effect_size_fixed_id_s,Effect_size_varying_intercepts_s,Effect_size_fixed_with_all_pairwise_interactions)
#Effect_size_fixed_id seems to make th best out of sample predictions however it splits it and we are more interrested in the overall effects
traceplot(Effect_size_fixed_id)
```

```{r message=FALSE, echo=FALSE,warning=FALSE, cache=T}
B_model_result <- precis(Effect_size_fixed_s_2,prob = 0.95)
```


Having established that the duration of continuous admixture under ideal
circumstances is only marginally influential on admixture time
estimates, we want to compare its effect to more realistic simulation scenarios. Two common assumptions, namely knowing the recombination pattern and knowing the demographic history, were implicitly used in the previous simulations.
Previous studies reported that violations of these assumptions can have an effect on the admixture time estimates.
Hence, we used the African-American genetic map and a more complex demography with substructure in the ancestral human population and additional gene flow between Africans and non-Africans after the Neadertal admixture ended (Supp. Fig. \ref{fig:figS1}), for simulations under more realistic parameters. The genetic distance was assigned using the average recombination rate of the African-American genetic map.
Furthermore, we altered the used scheme for ascertainment of SNPs for admixture informative sites. We compared the LES where only
positions in the admixed population are considered where both source
populations are diverged from each other, to an even stricter scheme. The Higher-Enrichment Scheme (HES) requiring additional
to the LES non-Africans to be polymorphic at a SNP. Additionally, we altered the minimal distance between pairs of SNPs for which the LD is calculated from 0.05 cM to 0.02 cM.


We simulated every combination of these parameter sets resulting in 32
different sets with 100 replications each (Supp. Fig. \ref{fig:figS2}).
A GLM was applied to estimate effect sizes of the four predictors being
ascertainment scheme, minimal distance, demography and recombination on
the bias of admixture estimates (Supplement Table \ref{tab:tableS1}).
Figure \ref{fig:fig3} shows the comparison of the standardized
difference between true and estimated time between the previously used
model (ascertainment = LES, \(d_{0} = 0.05 cM\), demography = simple and
recombination = constant) further refereed to as the standard model and
a model with one of the four parameter changed, respectively. The previously observed overestimation of the standard model was estimated to be `r round(B_model_result$mean[1],2)` (`r round(B_model_result[1,3],2)` - `r round(B_model_result[1,4],2)` 95 % CI)  standard deviation from the true admixture time.

Every parameter change results in lower estimates compared to the standard model, with the biggest difference between a constant and a varying recombination (`r round(B_model_result[3,3],2)` - `r round(B_model_result[3,4],2)` 95 % CI) and the smallest differences between a pulse and continuous gene flow model (`r round(B_model_result[2,3],2)` - `r round(B_model_result[2,4],2)` 95 % CI). Most accurate estimates are achieved using the LES
ascertainment scheme in combination with a minimal distance of 0.05 cM. Additionally, the bias introduced by the demography seems to depend on the used
ascertainment scheme, since only under the HES a difference between the
simple and complex demography is evident (Supp. Fig. \ref{fig:figS2}). 

Overall the bias introduced by the ascertainment, minimal distance cutoff,
demography and admixture model are 10 \% or less of the true mean
admixture time. The major uncertainties in the admixture time estimate arise from assuming a constant recombination rate. The admixture time estimates for a pulse or a multi-generation admixture are simillarly effected by the other modeling parameters.



```{r fig3,message=FALSE, echo=FALSE,warning=FALSE,fig3.pos="H",fig.width=9,fig.height=6,fig.cap="\\label{fig:fig3} Comparison between the effect sizes of the estimated parameters on the standardized difference between true and estimated admixture time"}

post_effect_size_model <- extract.samples(Effect_size_fixed_s_2,n = 1e5)
Post_effect_size_est=data.frame(mean=c(
mean(post_effect_size_model$a),
mean(post_effect_size_model$a + post_effect_size_model$bG),
mean(post_effect_size_model$a + post_effect_size_model$bR),
mean(post_effect_size_model$a + post_effect_size_model$bD),
mean(post_effect_size_model$a + post_effect_size_model$bm),
mean(post_effect_size_model$a + post_effect_size_model$bA)),
HPDI_lower=c(
HPDI(post_effect_size_model$a,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bG,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bR,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bD,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bm,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bA,0.95)[1]),
HPDI_upper=c(
HPDI(post_effect_size_model$a,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bG,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bR,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bD,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bm,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bA,0.95)[2])
#,row.names = c("Standart Model","Continuous GF","Varying recombination","Complex Demography","d0 = 0.02","HES")
)


ggplot(Post_effect_size_est,aes(x=row.names(Post_effect_size_est),y=as.numeric(as.character(mean))))+
      geom_point(aes(size=1.5,col=c(cbPalette_viridis[1],cbPalette_viridis[6],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1])),show.legend = F)+
    geom_errorbar(aes(ymin=HPDI_lower,ymax=HPDI_upper,pos=as.numeric(row.names(Post_effect_size_est))),col="black",width=0.2)+
  geom_hline(yintercept = 0,linetype=2,aes(colour='grey'))+
  labs(x = "")+
  labs(y = "Standardized difference between true and estimated time")+
  theme(plot.title = element_text(hjust = 0.5,size = 12))+
  scale_x_discrete(labels= c("Standart Model","Continuous GF","Varying recombination","Complex Demography","d0 = 0.02","HES")
                    )+
  scale_color_manual("Gene Flow Model",
                     values = c(cbPalette_viridis[1],cbPalette_viridis[6],
                                cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1]),
                     label=c("Pulse","Continuous"))

```

\subsection{Estimating the Lomax-parameters under different conditions}\label{estimating the Lomax-parameters under different conditions}

```{r message=FALSE, echo=FALSE,warning=FALSE}
#### New Figure for Paper using recent sampling (50 gen): constant RR, RM no correction, RM diff RM correction, RM correction same RM ####

cbPalette_viridis <- viridis(6,option = "D")

Filter_Result_Table <- function(Result.Table){
  Result.Table=read.table(Result.Table,header=F,sep = " ")
  Result.names <- c('A.exp', 's.exp', 'c.exp', 'RSS_Expo','AIC_Expo', 'A.lomax', 's.lomax', 'w.lomax','c.lomax', 'RSS_Lomax','AIC_Lomax', 'F_Test','Scenario.name','GF.Start','GF.End','AS','minDist','GF.Model')
  colnames(Result.Table) <- Result.names
  #Result.Table <- Result.Table[(1/Result.Table$s.exp)>0,]
  #Result.Table <- Result.Table[(1/Result.Table$s.exp)<5000,]
  #Result.Table <- Result.Table[Result.Table$RSS_Lomax<1e-2,]
  return(Result.Table)
}

#### True values
True_params <- function(Result.Table){
  True_params_Calc <- function(True_GF_length,True_mean_GF){
    EX= True_mean_GF
    GF_Len <-True_GF_length
    VarX= ((GF_Len)/4)**2
    b= EX/VarX
    a=EX*b
    a=a
    True_W=1/a
    True_S=b/(1/True_W)
    xx=c(True_W,True_S)
    return(xx)
  }
  True.params <- c()
  for (i in 1:length(Result.Table$F_Test)) {
    xx=True_params_Calc(Result.Table$True_GF_length[i],Result.Table$True_mean_GF[i])
    True.params <- rbind(True.params,xx)
  }
  True.params <- as.data.frame(True.params)
  return(True.params)
}

Result.Table.fn <- function(Result.Table.path,Sampling.time.from.GF.End,name){
  Result.Table <- Filter_Result_Table(Result.Table.path)
  Result.Table$Name <- name
  Result.Table$Sample_Time <- Sampling.time.from.GF.End
  Result.Table$True_GF_length <- Result.Table$GF.End-Result.Table$GF.Start
  Result.Table$True_mean_GF <- ((Result.Table$GF.End+Result.Table$GF.Start)/2)-(Result.Table$GF.Start-Result.Table$Sample_Time)
  Result.Table$mean_GF_exp <- 1/Result.Table$s.exp
  Result.Table$mean_GF_lomax_s <- 1/Result.Table$s.lomax
  Result.Table.comparison <- True_params(Result.Table)
  Result.Table$True_W <- Result.Table.comparison$V1
  Result.Table$True_S <- Result.Table.comparison$V2
  Result.Table.comparison$length_GF <- (sqrt(Result.Table$mean_GF_lomax_s/(((1/Result.Table$w.lomax))*Result.Table$s.lomax)))*4
  Result.Table$length_GF <- Result.Table.comparison$length_GF
  
  return(Result.Table)
}

Plot_sampling_50_gen_t_GF <- function(ggdata_t.GF,cbPalette_viridis,Ptitle){
  ggplot(ggdata_t.GF,aes(x=variable,y=as.numeric(as.character(value)),colour=factor(Name)))+
    geom_boxplot(show.legend = T)+
    facet_grid(~as.factor(True_GF_length),switch = "x")+
    geom_hline( aes(yintercept = True_mean_GF ))+
    ggtitle(Ptitle) +
    labs(x = "Admixture Duration")+
    labs(y = "Estimated Admixture Time")+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    coord_cartesian(ylim = c(0,1500), expand = 0)+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[2],cbPalette_viridis[3],cbPalette_viridis[4]),
                       labels = c("Constant Recombination","HapMap AAMap corrected","HapMap HapMap corrected","HapMap not corrected"))
  
}

Plot_sampling_50_gen_GF_Length <- function(ggdata_l.GF,cbPalette_viridis,Ptitle){
  ggplot(ggdata_l.GF,aes(x=variable,y=as.numeric(as.character(value)),colour=factor(Name)))+
    geom_boxplot(show.legend = F)+
    facet_grid(~as.factor(True_GF_length),switch = "x")+
    geom_hline( aes(yintercept = True_GF_length ))+
    ggtitle(Ptitle) +
    labs(x = "Admixture Duration")+
    labs(y = "Estimated Admixture Duration")+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    coord_cartesian(ylim = c(0,4000), expand = 0)+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[2],cbPalette_viridis[3],cbPalette_viridis[4]),
                       labels = c("Constant Recombination","HapMap AAMap corrected","HapMap HapMap corrected","HapMap not corrected"))
}

Plot_sampling_varying_gen_t_GF <- function(ggdata_t.GF_varying,cbPalette_viridis,Ptitle){
  ggplot(ggdata_t.GF_varying,aes(x=variable,y=as.numeric(as.character(value)),colour=factor(Name)))+
    geom_boxplot()+
    facet_grid(~as.factor(Sample_Time),switch = "x")+
    geom_hline( aes(yintercept = True_mean_GF ))+
    ggtitle(Ptitle) + 
    labs(x = "Generations Sampled After End of Admixture")+
    labs(y = "Estimated Admixture Time")+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    coord_cartesian(ylim = c(0,2000), expand = 0)+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[2],cbPalette_viridis[3],cbPalette_viridis[4]),
                       labels = c("Constant Recombination","HapMap AAMap corrected","HapMap HapMap corrected","HapMap not corrected"))
  
}

Plot_sampling_varying_gen_GF_Length <- function(ggdata_l.GF_varying,cbPalette_viridis, Ptitle){
  ggplot(ggdata_l.GF_varying,aes(x=variable,y=as.numeric(as.character(value)),colour=factor(Name)))+
    #geom_point(aes(size = Freq),show.legend = F)+
    geom_boxplot(show.legend = F)+
    facet_grid(~as.factor(Sample_Time),switch = "x")+
    geom_hline( aes(yintercept = True_GF_length ))+
    ggtitle(Ptitle) +
    labs(x = "Generations Sampled After End of Admixture")+
    labs(y = "Estimated Admixture Duration")+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    coord_cartesian(ylim = c(0,4000), expand = 0)+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[2],cbPalette_viridis[3],cbPalette_viridis[4]),
                       labels = c("Constant Recombination","HapMap AAMap corrected","HapMap HapMap corrected","HapMap not corrected"))
}

Result.Table.path_Recent_50 <-'Fig_3_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Close_to_GF_End_Recent_GF_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-No_correction.txt'
Result.Table.path_Recent_50_Recomb_Map_no_correction <-'Fig_3_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Close_to_GF_End_Recent_GF_Recomn_Map_Hap_Map_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-No_correction.txt'
Result.Table.path_Recent_50_Recomb_Map_AAMap_correction <-'Fig_3_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Close_to_GF_End_Recent_GF_Recomn_Map_Hap_Map_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-AAMap_correction.txt'
Result.Table.path_Recent_50_Recomb_Map_HapMap_Recomb_HapMap_correction <-'Fig_3_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Close_to_GF_End_Recent_GF_Recomn_Map_Hap_Map_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-HapMap_correction.txt'

Result.Table.path_Recent_Varying <-'Fig_3_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Variyng_Time_of_Recent_sampling_GF_l_fixed_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-No_correction.txt'
Result.Table.path_Recent_Varying_Recomb_Map_no_correction <-'Fig_3_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Variyng_Time_of_Recent_sampling_GF_l_fixed_Recomn_Map_Hap_Map_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-No_correction.txt'
Result.Table.path_Recent_Varying_Recomb_Map_AAMap_correction <-'Fig_3_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Variyng_Time_of_Recent_sampling_GF_l_fixed_Recomn_Map_Hap_Map_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-AAMap_correction.txt'
Result.Table.path_Recent_Varying_Recomb_Map_HapMap_Recomb_HapMap_correction <-'Fig_3_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Variyng_Time_of_Recent_sampling_GF_l_fixed_Recomn_Map_Hap_Map_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-HapMap_correction.txt'


Plot.data_50<-rbind(
  Recent_50_constant<- Result.Table.fn(Result.Table.path_Recent_50,50,'Recent_50_constant'),
  Recent_50_HapMap_no_correction <- Result.Table.fn(Result.Table.path_Recent_50_Recomb_Map_no_correction,50,'Recent_50_HapMap_no_correction'),
  Recent_50_HapMap_AAMap_correction <- Result.Table.fn(Result.Table.path_Recent_50_Recomb_Map_AAMap_correction,50,'Recent_50_HapMap_AAMap_correction'),
  Recent_50_HapMap_HapMap_correction <- Result.Table.fn(Result.Table.path_Recent_50_Recomb_Map_HapMap_Recomb_HapMap_correction,50,'Recent_50_HapMap_HapMap_correction')
)

ggdata_t.GF_50_mean_GF_exp <- melt(Plot.data_50,measure.vars =  c('mean_GF_exp'),id.vars = c('True_mean_GF','True_GF_length','Name'))
ggdata_t.GF_50_mean_GF_lomax <- melt(Plot.data_50,measure.vars =  c('mean_GF_lomax_s'),id.vars = c('True_mean_GF','True_GF_length','Name'))
ggdata_l.GF_50 <- melt(Plot.data_50,measure.vars =  c('length_GF'),id.vars = c('True_mean_GF','True_GF_length','Name'))



Plot.data_varying<-rbind(
  Recent_varying_constant<- Result.Table.fn(Result.Table.path_Recent_Varying,c(rep(50,100),rep(100,100),rep(200,100),rep(400,100),rep(800,100),rep(1000,100)),'Recent_50_constant'),
  Recent_varying_HapMap_no_correction <- Result.Table.fn(Result.Table.path_Recent_Varying_Recomb_Map_no_correction,c(rep(50,100),rep(100,100),rep(200,100),rep(400,100),rep(800,100),rep(1000,100)),'Recent_50_HapMap_no_correction'),
  Recent_varying_HapMap_AAMap_correction <- Result.Table.fn(Result.Table.path_Recent_Varying_Recomb_Map_AAMap_correction,c(rep(50,100),rep(100,100),rep(200,100),rep(400,100),rep(800,100),rep(1000,100)),'Recent_50_HapMap_AAMap_correction'),
  Recent_varying_HapMap_HapMap_correction <- Result.Table.fn(Result.Table.path_Recent_Varying_Recomb_Map_HapMap_Recomb_HapMap_correction,c(rep(50,100),rep(100,100),rep(200,100),rep(400,100),rep(800,100),rep(1000,100)),'Recent_50_HapMap_HapMap_correction')
)

ggdata_t.GF_varying_mean_GF_exp <- melt(Plot.data_varying,measure.vars =  c('mean_GF_exp'),id.vars = c('True_mean_GF','True_GF_length','Name','Sample_Time'))
ggdata_t.GF_varying_mean_GF_lomax <- melt(Plot.data_varying,measure.vars =  c('mean_GF_lomax_s'),id.vars = c('True_mean_GF','True_GF_length','Name','Sample_Time'))
ggdata_l.GF_varying <- melt(Plot.data_varying,measure.vars =  c('length_GF'),id.vars = c('True_mean_GF','True_GF_length','Name','Sample_Time'))




New.P1_mean_GF_exp <- Plot_sampling_50_gen_t_GF(ggdata_t.GF_50_mean_GF_exp,cbPalette_viridis, "Sampled 50 Gen. From End Of Admixture")
New.P1_mean_GF_lomax <- Plot_sampling_50_gen_t_GF(ggdata_t.GF_50_mean_GF_lomax,cbPalette_viridis,"Sampled 50 Gen. From End Of Admixture")
New.P2 <- Plot_sampling_50_gen_GF_Length(ggdata_l.GF_50,cbPalette_viridis,"Sampled 50 Gen. From End Of Admixture")
New.P3_mean_GF_exp <- Plot_sampling_varying_gen_t_GF(ggdata_t.GF_varying_mean_GF_exp,cbPalette_viridis,"Admixture Duration = 800 Gen.")
New.P3_mean_GF_lomax <- Plot_sampling_varying_gen_t_GF(ggdata_t.GF_varying_mean_GF_lomax,cbPalette_viridis,"Admixture Duration = 800 Gen.")
New.P4 <- Plot_sampling_varying_gen_GF_Length(ggdata_l.GF_varying,cbPalette_viridis,"Admixture Duration = 800 Gen.")

```

Building on the previous
result we wanted to find out the conditions to retrieve the Lomax
parameters i.e.~the duration of the admixture. We simulated an admixture
scenario under a simple demography with varying durations of continuous
admixture and sampled the population at different time points since the
end of the gene flow. Doing so allows us to examine how close one has to
sample form the end of a continuous admixture to still accurately
estimate its duration. Since the recombination map was shown to be highly
influential, we tested the duration estimates under a constant and variable
recombination using the HapMap genetic map. Here, we correct the
genetic distance by: assuming a constant rate, using the AAMap (uncertainty in the recombination map) or the
HapMap itself (knowing the population recombination map). We used the LES ascertainment scheme in combination with
a minimal distance of 0.05 cM. To fit the Lomax we can take advantage of
the fact that the bias of the mean time estimates using the simplified
one generation pulse model is relatively accurate. We can thus estimate
the mean time first by fitting an exponential and in a second step estimating k
using a Lomax distribution with a starting parameter for the mean time received
from the exponential fit, to archive better convergent. Figure \ref{fig:fig4} A and C show the mean
time estimates received from the Exponential fit. For simulations under a
constant recombination the mean time received from the exponantial fit can be estimated confidently for different durations and different sampling times after the end of the admixture event. Estimates for simulation under a recombination map only
assuming a constant rate when calculating the LD results in severely
underestimation of the mean time estimates. Using the AAMap yields
results closer to the true value and less downwards biased, however only
using the exact same genetic map gives unbiased results. The mean time estimates received from the Lomax distribution show an overestimation on average and a higher variation (Supp. Fig.  \ref{fig:figS2}).  Figure
\ref{fig:fig4} B and D shows the corresponding admixture duration estimates by the
Lomax fit. Accurate estimates can be obtained throughout the different
admixture durations under a constant recombination rate, when sampled
recent from the end of the continuous admixture. Sampling further away from the end of the admixture results in less accurate estimates.  All simulations using a recombination map show a much higher
variance in the estimates. Especially for admixture durations longer then
800 generations or sampled later then 50 generations away from the end
of the admixture, the estimates are not reliably. If no precise genetic map
is used to inferred the genetic distance between SNPs, no accurate
duration estimates can be obtained. The mean duration over all
replicates for the simulation corrected by the exact same map seems
relatively unbiased for a recent gene flow with a duration shorter 1000
generations. 

Under a realistic scenario with a varying recombination
rate, the duration can only be accurately estimated with a highly
precise map for recent continuous admixture events not longer then 400
generations. With regard to scenarios of Neandertal admixture,
accurately estimating the duration of possible continuous admixture from
present day human genomes even under a constant rate is
under powered. 
Figure \ref{fig:fig5} shows multiple gene flow duration scenarios ranging from a one generation pulse to 2500 generations of continuous admixture. All scenarios are compatible with the ALD data from 1000 Genome's CEU computed using YRI and the Altai, Vindija and Chagyrskaya high coverage as reference populations and a CEU specific fine-scale genetic map \cite{spence_inference_2019}.

We repeated the analysis on directly inferred Neandertal segments found in 27,566 high coverage genomes from Iceland \cite{skov_nature_2020} using the deCODE map \cite{kong_fine-scale_2010} as a population specific map for Icelanders (Supplement Figure \ref{fig:figS5}). However, the mean time estimates of Neandertal admixture obtained are way younger then expected both from previous genetic and archaeological studies, making long continuous admixture (longer then 200 generations ) less compatible with the data.

``` {r fig4, message=FALSE, echo=FALSE,warning=FALSE,fig4.pos="H",fig.width=9,fig.height=6,fig.cap="\\label{fig:fig4} Parameter estimate for different sampling and admixture duration times using different methods for assigning genetic length A) Mean time estimates from the continuous model fit of different gene flow length all sampled 50 generations after the gene flow enden. B) Lomax duration estimat of the scenario C) Mean time estimates from the continuous model fit of different sampling times after the end of 800 generations of gene flow. D) Lomax duration estimat of the scenario"}


Lomax.Fig_mean_lomax <- ggarrange(New.P1_mean_GF_lomax,New.P2,New.P3_mean_GF_lomax,New.P4,
                   labels = c("A","B","C","D"),
                   ncol = 2, nrow = 2,common.legend = T,legend = 'bottom')


Lomax.Fig_mean_lomax

```

```{r message=FALSE, echo=FALSE,warning=FALSE}
input_pol_corrected <- "Real_Data_Analysis/Raw_ALDER_output-ALL_chr_hcNea_YRI_CEU_1k_G_polarized_LES_ascertained_corrected_rr_CEU_specific_map.txt"
#input_corrected <- "Real_Data_Analysis/Raw_ALDER_output_ALL_chr_hcNea_YRI_CEU_1k_G_LES_ascertained_corrected_rr_CEU_specific_map.txt"
#input <- "Real_Data_Analysis/Raw_ALDER_output-ALL_chr_hcNea_YRI_CEU_1k_G_LES_ascertained_corrected_constant_rr.txt"
lval <- 0.05	# lower value of dist to use
hval <- 3		# higher value of dist to use 
log <- F
affine <- T


Fit_Exp_fn <- function(Data,affine){
  xx=Data
  
  dist=xx$dist
  wcorr=xx$wcorr
  #Fitting an Exponential
  
  if(affine){
    fm1_exp <- function(x) x[1]*exp(-(dist/100)/x[2])+x[3]
    fm2_exp <- function(x) sum((wcorr-fm1_exp(x))^2)
    fm3_exp <- DEoptim(fm2_exp, lower=c(1e-6,0,-1), upper=c(1, 1,1), control=list(trace=FALSE))
    
    par1_exp <- fm3_exp$optim$bestmem
    # parameters for y ~ Ae-mt
    names(par1_exp) <- c("A", "s","c")
    A_exp_est <- as.numeric((par1_exp[1]))
    Lambda_est <-as.numeric((par1_exp[2]))  	# rate of decay of exponential
    C_exp_est <- as.numeric((par1_exp[3]))
    
    fit1_exp <- nls(wcorr ~ (A*exp(-(dist/100)/s)+c), start=par1_exp, control=list(maxiter=10000, warnOnly=TRUE)) 
  }
  return(fit1_exp)
}



Fit_Lomax_fn <- function(Data,fixed_w){
  xx=Data
  
  dist=xx$dist
  wcorr=xx$wcorr

  fm1_lomax <- function(x) x[4] + x[3]* (1/(1 + (x[1]*(dist/100) /  x[2])))^(1/x[1])
  fm2_lomax_k <- function(x) sum((wcorr-fm1_lomax(x))^2)
  fm3_DEoptim <- DEoptim(fm2_lomax_k, lower=c(fixed_w,0,0,0), upper=c(fixed_w,1,1,1), control=list(trace=FALSE))
  
  par1_lomax <- fm3_DEoptim$optim$bestmem
  par1_lomax <- c(par1_lomax[2],par1_lomax[3],par1_lomax[4])
  names(par1_lomax) <- c("s","A","c")
  fit1_lomax <- nls(wcorr ~ c+A*(1/(1  + ((fixed_w*(dist/100)) / s)))^(1/fixed_w), start=par1_lomax, control=list(maxiter=10000, warnOnly=TRUE,minFactor=0.0004))

  return(fit1_lomax)
}

xdata=Get_points(input_pol_corrected,lval,hval,log)
#xdata2=Get_points(input_corrected,lval,hval,log)
#xdata3=Get_points(input,lval,hval,log)
Expo_fit_result <- Fit_Exp_fn(Data = xdata,affine = affine)
t_expo_est=1/coef(Expo_fit_result)[[2]]


t_d=c(1,100,200,400,800,1000,1500,2000,2500)

all_t_lomax_est <- list()
for(t in 1:length(t_d)){
  fixed_w= 1/(t_expo_est*(t_expo_est/((t_d[t]/4)^2)))
  
  Lomax_fit_result <- Fit_Lomax_fn(Data = xdata,fixed_w = fixed_w)
  coef(Lomax_fit_result)
  t_lomax_est=1/coef(Lomax_fit_result)[[1]]
  all_t_lomax_est[[t]] <- Lomax_fit_result
  
}


EXP_norm_fn <- function(dist,A,s,c) A*exp(-(dist/100)/s)+c
LOMAX_norm_fn <- function(dist,A,s,w,c) c+A*(1/(1  + ((w*(dist/100)) / s)))^(1/w)
EXP_Log_fn <- function(dist,A,s) log(A)  -((dist/100)/s)
LOMAX_Log_fn <- function(dist,A,s,w) log(A) + (1/w) * -log(1+ ((w*(dist/100))/s))


AIC_result <- AIC(Expo_fit_result,all_t_lomax_est[[1]],all_t_lomax_est[[2]],all_t_lomax_est[[3]],all_t_lomax_est[[4]],
    all_t_lomax_est[[5]],all_t_lomax_est[[6]],all_t_lomax_est[[7]],all_t_lomax_est[[8]],all_t_lomax_est[[9]])

xx=t(data.frame(c(c(coef(Expo_fit_result)[1],confint(Expo_fit_result)[1,1],confint(Expo_fit_result)[1,2]),
                 c(coef(Expo_fit_result)[2],confint(Expo_fit_result)[2,1],confint(Expo_fit_result)[2,2]),
                 c(coef(Expo_fit_result)[3],confint(Expo_fit_result)[3,1],confint(Expo_fit_result)[3,2]))))
colnames(xx) <- c("A","A 2.5 %", "A 97.5 %","s","s 2.5 %", "s 97.5 %","c","c 2.5 %", "c 97.5 %")

Model_RSS <- c()
for(i in list(Expo_fit_result,all_t_lomax_est[[1]],all_t_lomax_est[[2]],all_t_lomax_est[[3]],all_t_lomax_est[[4]],
           all_t_lomax_est[[5]],all_t_lomax_est[[6]],all_t_lomax_est[[7]],all_t_lomax_est[[8]],all_t_lomax_est[[9]])){
  RSS <- sum(residuals(i)^2) 
  Model_RSS <- c(Model_RSS,RSS)
}

```

```{r message=FALSE, echo=FALSE,warning=FALSE}

Get_CI_s_approx_fn <- function(fit,i,n_data){
  org <- coef(fit)[[i]]
  lwr_approx <- coef(fit)[[i]]*(1-(1.96/sqrt(length(n_data[,1]))))
  upr_approx <- coef(fit)[[i]]*(1+(1.96/sqrt(length(n_data[,1]))))
  param_CI <- c(1/org,1/upr_approx,1/lwr_approx)
  return(param_CI)
}

Get_CI_other_approx_fn <- function(fit,i,n_data,sigma){
  org <- coef(fit)[[i]]
  lwr_approx <- coef(fit)[[i]]-1.96*(sigma/sqrt(length(n_data[,1])))
  upr_approx <- coef(fit)[[i]]+1.96*(sigma/sqrt(length(n_data[,1])))
  param_CI <- c(org,lwr_approx,upr_approx)
  return(param_CI)
}

A_param=Get_CI_other_approx_fn(Expo_fit_result,1,xdata,summary(Expo_fit_result)$sigma)
t_m=Get_CI_s_approx_fn(Expo_fit_result,2,xdata)
c_param=Get_CI_other_approx_fn(Expo_fit_result,3,xdata,summary(Expo_fit_result)$sigma)
Expo_fit_tabel <- rbind(A_param,t_m,c_param)

Lomax_fit_tabel <- c()
for(model in all_t_lomax_est){
  A_parm=Get_CI_other_approx_fn(model,2,xdata,summary(model)$sigma)
  t_m=Get_CI_s_approx_fn(model,1,xdata)
  c_param=Get_CI_other_approx_fn(model,3,xdata,summary(Expo_fit_result)$sigma)
  Lomax_fit_tabel_x <- rbind(A_param,t_m,c_param)
  Lomax_fit_tabel <- rbind(Lomax_fit_tabel,Lomax_fit_tabel_x)
}



```

```{r eval=FALSE,message=FALSE, echo=FALSE,warning=FALSE}
# Try to get proper CI for the log exp and lomax
Fit_Exp_log_fn <- function(Data){
   xx=Data
  
  dist=xx$dist
  wcorr=xx$wcorr
  #Fitting an Exponential
  
    fm1_exp <- function(x) log(x[1])-((dist/100)/x[2])
    #fm2_exp <- function(x) sum(complete.cases((wcorr-fm1_exp(x))^2))
    fm2_exp <- function(x) sum((wcorr-fm1_exp(x))^2)
    fm3_exp <- DEoptim(fm2_exp, lower=c(1e-6,1e-8), upper=c(0.5, 0.5), control=list(trace=FALSE))
    
    par1_exp <- fm3_exp$optim$bestmem
    # parameters for y ~ Ae-mt
    names(par1_exp) <- c("A", "s")
    A_exp_est <- as.numeric((par1_exp[1]))
    Lambda_est <-as.numeric((par1_exp[2]))  	# rate of decay of exponential
    
    fit1_exp <- nls(wcorr ~ log(A) -((dist/100)/s), start=par1_exp, control=list(maxiter=10000, warnOnly=TRUE)) 
  return(fit1_exp)
}
Expo_fit_result_log <- Fit_Exp_log_fn(Data = Get_points(input_pol_corrected,lval,hval=0.4,log = T))

## confidenc intervals are bs for the log

x=Expo_fit_result
summary(x)

# Manual CI for the mean time of admixture by a normal approximation to the exact solution using the chisq
S_lwr_approx <- coef(x)[[2]]*(1-(1.96/sqrt(length(xdata[,1]))))
S_upr_approx <- coef(x)[[2]]*(1+(1.96/sqrt(length(xdata[,1]))))
1/coef(x)[[2]]
1/S_lwr_approx
1/S_upr_approx
confint(x)

pred_exp <- data.frame(xdata$dist,predict(Expo_fit_result))
ci_expo_lwr = as.data.frame(predict(Expo_fit_result) *(1-(1.96/sqrt(length(xdata[,1])))))
ci_expo_upr = as.data.frame(predict(Expo_fit_result) *(1+(1.96/sqrt(length(xdata[,1])))))
plot(xdata$dist,xdata$wcorr,xlim=c(0,0.5))
lines(xdata$dist,pred_exp$predict.Expo_fit_result.,lwd=2,lty=2,col="red")
lines(xdata$dist,ci_expo_lwr$`predict(Expo_fit_result) * (1 - (1.96/sqrt(length(xdata[, 1]))))`,lwd=2,lty=1,col="red")
lines(xdata$dist,ci_expo_upr$`predict(Expo_fit_result) * (1 + (1.96/sqrt(length(xdata[, 1]))))`,lwd=2,lty=1,col="red")

pred_exp <- EXP_Log_fn(xdata$dist,coef(Expo_fit_result)[[1]],coef(Expo_fit_result)[[2]])
ci_expo_lwr = as.data.frame(pred_exp *(1-(1.96/sqrt(length(xdata[,1])))))
ci_expo_upr = as.data.frame(pred_exp *(1+(1.96/sqrt(length(xdata[,1])))))
plot(xdata$dist,log(xdata$wcorr),xlim=c(0,0.5))
lines(xdata$dist,pred_exp,lwd=2,lty=2,col="red")
lines(xdata$dist,ci_expo_lwr$`predict(Expo_fit_result) * (1 - (1.96/sqrt(length(xdata[, 1]))))`,lwd=2,lty=1,col="red")
lines(xdata$dist,ci_expo_upr$`predict(Expo_fit_result) * (1 + (1.96/sqrt(length(xdata[, 1]))))`,lwd=2,lty=1,col="red")

df <- c()
df$pred <- EXP_Log_fn(xdata$dist,coef(Expo_fit_result)[[1]],coef(Expo_fit_result)[[2]])
se = summary(Expo_fit_result_log)$sigma
ci = as.data.frame(outer(df$pred, c(outer(se, c(-1,1), '*'))*1.96, '+'))

plot(xdata$dist,log(xdata$wcorr),xlim=c(0,0.5))
lines(xdata$dist,df$pred,lwd=2,lty=2,col="red")
lines(xdata$dist,ci$V1,lwd=2,lty=1,col="red")
lines(xdata$dist,ci$V2,lwd=2,lty=1,col="red")

yy=as.data.frame(investr::predFit(Expo_fit_result_log,newdata=list(dist=xdata$dist),interval="prediction"))
plot(xdata$dist,log(xdata$wcorr),xlim=c(0,1))
lines(xdata$dist,yy$fit,lwd=2,lty=2,col="red")
lines(xdata$dist,yy$lwr,lwd=2,lty=1,col="red")
lines(xdata$dist,yy$upr,lwd=2,lty=1,col="red")
```

```{r fig5, message=FALSE, echo=FALSE,warning=FALSE,fig5.pos="H",fig.width=9,fig.height=6,fig.cap="\\label{fig:fig5} Different admixure duration models ranging from a one generation pulse tu 2500 generations for Neandertal admixture duration using all 1k Genome CEU individuals as the admixed population with all YRI and 3 high coverage Neandertals as reference populations."}

cbPalette_viridis <- viridis(length(t_d),option = "D")


ggplot_fit_data_transf_fn <- function(Expo_fit_result,all_t_lomax_est,log){
    if(log==T){
      fit.ggplot_exp=data.frame(y=EXP_Log_fn(xdata$dist,coef(Expo_fit_result)[[1]],coef(Expo_fit_result)[[2]]),x=xdata$dist)
      fit.ggplot_exp$lowCI <- EXP_Log_fn(xdata$dist,confint(Expo_fit_result)[[1,1]],confint(Expo_fit_result)[[2,1]])
      fit.ggplot_exp$highCI <- EXP_Log_fn(xdata$dist,confint(Expo_fit_result)[[1,2]],confint(Expo_fit_result)[[2,2]])
      fit.ggplot_exp$Duration <- 1e5
  } else {
      fit.ggplot_exp=data.frame(y=EXP_norm_fn(xdata$dist,coef(Expo_fit_result)[[1]],coef(Expo_fit_result)[[2]],
                                            coef(Expo_fit_result)[[3]]),x=xdata$dist)
      fit.ggplot_exp$lowCI <- EXP_norm_fn(xdata$dist,confint(Expo_fit_result)[[1,1]],confint(Expo_fit_result)[[2,1]],
                                        confint(Expo_fit_result)[[3,1]])
      fit.ggplot_exp$highCI <- EXP_norm_fn(xdata$dist,confint(Expo_fit_result)[[1,2]],confint(Expo_fit_result)[[2,2]],
                                         confint(Expo_fit_result)[[3,2]])
      fit.ggplot_exp$Duration <- 1e5
  }
  Real_Lomax_fit_Result <- c()
  if(log==T){
    for(i in 1:length(t_d)){
      fit.ggplot_lomax_x=data.frame(y=LOMAX_Log_fn(xdata$dist,coef(all_t_lomax_est[[i]])[[2]],coef(all_t_lomax_est[[i]])[[1]],
                                               1/(t_expo_est*(t_expo_est/((t_d[i]/4)^2)))),x=xdata$dist)
      fit.ggplot_lomax_x$lowCI <- LOMAX_Log_fn(xdata$dist,confint(all_t_lomax_est[[i]])[[2,1]],confint(all_t_lomax_est[[i]])[[1,1]],
                                             1/(t_expo_est*(t_expo_est/((t_d[i]/4)^2))))
      fit.ggplot_lomax_x$highCI <- LOMAX_Log_fn(xdata$dist,confint(all_t_lomax_est[[i]])[[2,2]],confint(all_t_lomax_est[[i]])[[1,2]],
                                            1/(t_expo_est*(t_expo_est/((t_d[i]/4)^2))))
      fit.ggplot_lomax_x$Duration <- t_d[i]
      Real_Lomax_fit_Result <- rbind(Real_Lomax_fit_Result,fit.ggplot_lomax_x)
      Real_Lomax_fit_Result <- as.data.frame(Real_Lomax_fit_Result)
    }
    } 
  else {
    for(i in 1:length(t_d)){
      fit.ggplot_lomax_x=data.frame(y=LOMAX_norm_fn(xdata$dist,coef(all_t_lomax_est[[i]])[[2]],coef(all_t_lomax_est[[i]])[[1]],
                                            1/(t_expo_est*(t_expo_est/((t_d[i]/4)^2))),coef(all_t_lomax_est[[i]])[[3]]),x=xdata$dist)
      fit.ggplot_lomax_x$lowCI <- LOMAX_norm_fn(xdata$dist,confint(all_t_lomax_est[[i]])[[2,1]],confint(all_t_lomax_est[[i]])[[1,1]],
                                          1/(t_expo_est*(t_expo_est/((t_d[i]/4)^2))),confint(all_t_lomax_est[[i]])[[3,1]])
      fit.ggplot_lomax_x$highCI <- LOMAX_norm_fn(xdata$dist,confint(all_t_lomax_est[[i]])[[2,2]],confint(all_t_lomax_est[[i]])[[1,2]],
                                         1/(t_expo_est*(t_expo_est/((t_d[i]/4)^2))),confint(all_t_lomax_est[[i]])[[3,2]])
      fit.ggplot_lomax_x$Duration <- t_d[i]
      Real_Lomax_fit_Result <- rbind(Real_Lomax_fit_Result,fit.ggplot_lomax_x)
      Real_Lomax_fit_Result <- as.data.frame(Real_Lomax_fit_Result)
  }
    
}

  Real_fit_Result <- rbind(Real_Lomax_fit_Result,fit.ggplot_exp)
  Real_fit_Result <- as.data.frame(Real_fit_Result)
  Real_fit_Result$Duration <- as.factor(Real_fit_Result$Duration)
  return(Real_fit_Result)
  
}

ggplot_fit_data_transf_fn_2 <- function(Expo_fit_result,all_t_lomax_est,log){
    if(log==T){
      fit.ggplot_exp=data.frame(y=EXP_Log_fn(xdata$dist,coef(Expo_fit_result)[[1]],coef(Expo_fit_result)[[2]]),x=xdata$dist)
      fit.ggplot_exp$lowCI <- EXP_Log_fn(xdata$dist,confint(Expo_fit_result)[[1,1]],confint(Expo_fit_result)[[2,1]])
      fit.ggplot_exp$highCI <- EXP_Log_fn(xdata$dist,confint(Expo_fit_result)[[1,2]],confint(Expo_fit_result)[[2,2]])
      fit.ggplot_exp$Duration <- 1e5
  } else {
      fit.ggplot_exp=data.frame(as.data.frame(investr::predFit(Expo_fit_result,newdata=list(dist=xdata$dist),interval="prediction")),x=xdata$dist)
      fit.ggplot_exp$Duration <- 1e5
  }
  Real_Lomax_fit_Result <- c()
  if(log==T){
    for(i in 1:length(t_d)){
      fit.ggplot_lomax_x=data.frame(y=LOMAX_Log_fn(xdata$dist,coef(all_t_lomax_est[[i]])[[2]],coef(all_t_lomax_est[[i]])[[1]],
                                               1/(t_expo_est*(t_expo_est/((t_d[i]/4)^2)))),x=xdata$dist)
      fit.ggplot_lomax_x$lowCI <- LOMAX_Log_fn(xdata$dist,confint(all_t_lomax_est[[i]])[[2,1]],confint(all_t_lomax_est[[i]])[[1,1]],
                                             1/(t_expo_est*(t_expo_est/((t_d[i]/4)^2))))
      fit.ggplot_lomax_x$highCI <- LOMAX_Log_fn(xdata$dist,confint(all_t_lomax_est[[i]])[[2,2]],confint(all_t_lomax_est[[i]])[[1,2]],
                                            1/(t_expo_est*(t_expo_est/((t_d[i]/4)^2))))
      fit.ggplot_lomax_x$Duration <- t_d[i]
      Real_Lomax_fit_Result <- rbind(Real_Lomax_fit_Result,fit.ggplot_lomax_x)
      Real_Lomax_fit_Result <- as.data.frame(Real_Lomax_fit_Result)
    }
    } 
  else {
    for(i in 1:length(t_d)){
      fit.ggplot_lomax_x=data.frame(as.data.frame(investr::predFit(all_t_lomax_est[[i]],newdata=list(dist=xdata$dist),interval="prediction")),x=xdata$dist)
      fit.ggplot_lomax_x$Duration <- t_d[i]
      Real_Lomax_fit_Result <- rbind(Real_Lomax_fit_Result,fit.ggplot_lomax_x)
      Real_Lomax_fit_Result <- as.data.frame(Real_Lomax_fit_Result)
  }
    
}

  Real_fit_Result <- rbind(Real_Lomax_fit_Result,fit.ggplot_exp)
  Real_fit_Result <- as.data.frame(Real_fit_Result)
  Real_fit_Result$Duration <- as.factor(Real_fit_Result$Duration)
  return(Real_fit_Result)
  
}
Real_fit_Result_norm <- ggplot_fit_data_transf_fn(Expo_fit_result, all_t_lomax_est, log=F)
Real_fit_Result_norm_2<- ggplot_fit_data_transf_fn_2(Expo_fit_result, all_t_lomax_est, log=F)

Real_data_Plot_normal_2 <- ggplot(data=Real_fit_Result_norm_2,aes(x = x, y = fit,color=Duration,fill=Duration))+
  geom_point(data=xdata,aes(x=dist,y=wcorr,color=NULL,fill=NULL),show.legend = F)+
  xlim(0,0.5)+
  #ylim(-15,-5)+
  #geom_ribbon(aes(ymin=lwr,ymax=upr, fill = Duration,color=NULL), alpha = 0.3,show.legend = F)+
  geom_line(data=Real_fit_Result_norm_2,aes(x = x, y = fit,color=Duration))+
  scale_color_manual("Admixture Duration",
                     values = c(c(cbPalette_viridis,cbPalette_viridis[1])),
                     labels = c(c(t_d,"Pulse")))+
  scale_fill_manual( values = c(c(cbPalette_viridis,cbPalette_viridis[1])))+
  labs(x = "Genetic distance (cM)")+
  labs(y = "weighted LD") 

Real_data_Plot_normal <- ggplot(data=Real_fit_Result_norm,aes(x = x, y = y,color=Duration,fill=Duration))+
  geom_point(data=xdata,aes(x=dist,y=wcorr,color=NULL,fill=NULL),show.legend = F)+
  xlim(0,0.5)+
  #ylim(-15,-5)+
  #geom_ribbon(aes(ymin=lowCI,ymax=highCI, fill = Duration,color=NULL), alpha = 0.5,show.legend = F)+
  geom_line(data=Real_fit_Result_norm,aes(x = x, y = y,color=Duration))+
  scale_color_manual("Admixture Duration",
                     values = c(c(cbPalette_viridis,"red")),
                     labels = c(c(t_d,"Pulse")))+
  scale_fill_manual( values = c(c(cbPalette_viridis,"red")))+
  labs(x = "Genetic distance (cM)")+
  labs(y = "weighted LD") 

Real_fit_Result_log <- ggplot_fit_data_transf_fn(Expo_fit_result, all_t_lomax_est, log=T)
Real_data_Plot_log <- ggplot(data=Real_fit_Result_log,aes(x = x, y = y,color=Duration,fill=Duration))+
  geom_point(data=xdata,aes(x=dist,y=log(wcorr),color=NULL,fill=NULL),show.legend = F)+
  xlim(0,0.5)+
  ylim(-13,-5)+
  geom_line(data=Real_fit_Result_log,aes(x = x, y = y,color=Duration))+
  #geom_ribbon(aes(ymin=lowCI,ymax=highCI, fill = Duration,color=NULL), alpha = 0.5,show.legend = F)+
  scale_color_manual("Admixture Duration",
                     values = c(c(cbPalette_viridis,cbPalette_viridis[1])),
                     labels = c(c(t_d,"Pulse")))+
  scale_fill_manual( values = c(c(cbPalette_viridis,cbPalette_viridis[1])))+
  labs(x = "Genetic distance (cM)")+
  labs(y = "log weighted LD")


ggarrange(Real_data_Plot_normal_2,Real_data_Plot_log,ncol = 2,nrow = 1,
          labels = c("A","B")
          ,common.legend = T,legend = 'bottom')

```




\section{Discussion}\label{discussion}

How, where and when Neandertals and early modern humans interacted remains contentious.  
Archaeological evidence bounds the timing of interactions to times when their range overlapped; from the first out-of-Africa migrations of modern humans around 188 k years ago (\cite{stringer_when_2018,hershkovitz_earliest_2018}) to the extinction of Neandertals around 37 - 39 kya \cite{higham_timing_2014,zilhao_precise_2017}), leaving a time-span of roughly 140ky.

Genetic data has revealed that gene flow between Neandertals and modern humans did occur \cite{green_draft_2010}; and it's mean age is estimated to 47,000â€“65,000 ya \citep{sankararaman_date_2012}, assuming the interaction occurred at an instantaneous pulse.

Here, we contrasted this pulse model with scenarios involving more long-standing gene flow.  Our model, assumes that migration rates  follow a Gamma distribution, which results in an simple closed-form expressions for the introgressed segment lengths or ALD  distributions. 

In our analyses using the extended model, we find that most methods focus on the mean time of gene flow, and are mostly accurate in its inference. However, we also show that even gene flow lasting thousands of generations may yield data that are practically indistinguishable from a pulse, and that other modelling and method assumptions have an impact on estimates that are of a similar magnitude or much higher. Particularly the assumption of a constant recombination rate will lead to sever underestimations of admixture times, therefore reliable mean time estimates can only be obtained using population specific recombination maps.

The major implication of our result is that one has to be extremely cautious when interpreting results of genetic dating; the data are entirely consistent with gene flow occurring both earlier and later than the confidence intervals of the mean gene flow timing might indicate. This is of great practical importance as it might be tempting to link the genetic admixture date estimates with biogeographical events \cite{sankararaman_date_2012,lazaridis_genomic_2016,jacobs_multiple_2019,vyas_analyses_2019,douka_age_2019}. For example, the lower bounds on admixture time estimates might be used as dates of Neandertal extinction, and likewise use the earliest dates of gene flow as evidence when the out-of-Africa migration happened \citep{sankararaman_date_2012}. Our results show that both of these analyses might be misleading.


While our results show that drawing concrete conclusions from introgression time estimates, other avenues for differentiating different gene flow events remain fruitful.
In particular, measures based on population differentiation (e.g \cite{browning_analysis_2018,wall_higher_2013,villanea_multiple_2019,jacobs_multiple_2019}) are very promising to understand the different events that contributed to archaic ancestry in present-day humans. 

The other major avenue are ancient DNA samples from early modern humans that lived around or immediately after gene flow between archaic and modern humans occurred. The \textit{Oase 1} genome is a prime example, as it directly demonstrates that some gene flow must have occurred in Europe, around 40,000 years ago, concurrently with when \textit{Oase 1} lived. More generally, detailed analyses of ancient genomes from the initial upper paleolithic should provide more accurate mean dates, as they are much closer to the gene flow, and may give better evidence about the duration of the gene flow. The drawback is that some of the gene flow these individuals experience may be private to their population, as has e.g. been suggested for \textit{Oase 1}(\cite{fu_genome_2014}). Larger numbers of early modern human genomes, as well as methods to accurately infer admixture tracts or ALD in low-coverage data will likely enable this line of research. 



\section{References}\label{References}


\pagebreak
\setcounter{figure}{0}
\renewcommand{\figurename}{Fig. S}
\renewcommand{\tablename}{Tab. S}


\section{Supplement}\label{supplement}
```{r eval=FALSE, message=FALSE, echo=FALSE,warning=FALSE,}

Demography_graphic <- readPNG(source = "Paper_Graphics_demography_only.png",native = F,info = T)
im_B <- ggplot() + 
    background_image(Demography_graphic) +
    theme_bw()+
    # This ensures that the image leaves some space at the edges
    theme(plot.margin = margin(t=1, l=1, r=1, b=1, unit = "cm"))
im_B
```

```{r figS1, message=FALSE, echo=FALSE,warning=FALSE,fig.width=12,fig.height=6,fig.cap="\\label{fig:figS1} Demographic models of Neandertal admixture with non-Africans used for the simulations. A) Simple demographic model used for ALD simulations with constant population sizes. B) Complex demographic model with substructure in Africa, where after an initial earlier split and isolation the structured population exchange migrants till the final split and additional gene flow between Africans and non-Africans after the Neandertal admixture. The  population sizes after the (final) split are taken fome MSMC/PSMC estimates for the respective populations. C) Demographic model for the direct inference of Neandertal segments in non-Africans taken and modified from Skov et al. 2018."}



Simple_Demo <- readPNG(source = "Simple_Demographic_model.png",native = F)
Complex_Demo <- readPNG(source = "Complex_Demographic_model.png",native = F)
Skov_Demo <- readPNG(source = "Direct_Inference_Demographic_model.png",native = F)
#im_AA <- rasterGrob(Intro_graphic)

Simple_Demo <- ggplot() + 
    background_image(Simple_Demo) +
    theme_bw()+
    #theme(plot.margin = margin(t=0, l=0, r=0, b=0, unit = "cm")
    #,panel.border = element_blank()
    theme(plot.margin = margin(t=0, l=1, r=1, b=1, unit = "cm"))
ggsave(file="Simple_Demo.png", width=10, height=8, dpi=300)

Complex_Demo <- ggplot() + 
    background_image(Complex_Demo) +
    theme_bw()+
    #theme(plot.margin = margin(t=0, l=0, r=0, b=0, unit = "cm")
    #,panel.border = element_blank()
    theme(plot.margin = margin(t=0, l=1, r=1, b=1, unit = "cm"))
ggsave(file="Complex_Demo.png", width=10, height=8, dpi=300)

Skov_Demo <- ggplot() + 
    background_image(Skov_Demo) +
    theme_bw()+
    #theme(plot.margin = margin(t=0, l=0, r=0, b=0, unit = "cm")
    #,panel.border = element_blank()
    theme(plot.margin = margin(t=0, l=1, r=1, b=1, unit = "cm"))
ggsave(file="Skov_Demo.png", width=10, height=8, dpi=300)


Im_Simple_Demo <- cowplot::ggdraw() +
  cowplot::draw_image("Simple_Demo.png")

Im_Complex_Demo <- cowplot::ggdraw() +
  cowplot::draw_image("Complex_Demo.png")

Im_Skov_Demo <- cowplot::ggdraw() +
  cowplot::draw_image("Skov_Demo.png")

ggarrange(Im_Simple_Demo,Im_Complex_Demo,Im_Skov_Demo,
          labels = c("A","B", "C"),
          ncol = 3, nrow = 1)
```

```{r figS2, message=FALSE, echo=FALSE,warning=FALSE,fig.width=12,fig.height=6,fig.cap="\\label{fig:figS2} Comparison of the standardized difference between true and estimated admixture time for all combinations of parameters: ascertainment scheme = LES/HES,  $d_{0}$ = 0.02/0.05 cM, demography = simple/complex, recombination = constant/variable and the gene flow model = pulse/continuous, with 100 relicates respectively. Dotted line represents the model prediction with the 5.5 % and 94.5 % compatibility intervals solid lines. Dotted horizontal line indicates no difference between ture and estimated time. "}

Plot_model <- data.frame(table(Diff_s=round(xdata.M.3_no_error$Diff_s,digits = 2),GF=xdata.M.3_no_error$GF,Asc=xdata.M.3_no_error$Ascertainment,d0=xdata.M.3_no_error$min_dist,True_GF=xdata.M.3_no_error$mean.t.GF,Demo=xdata.M.3_no_error$Demography,Recomb=xdata.M.3_no_error$Recomb.rate,Combination=xdata.M.3_no_error$TID))
Plot_model <- subset(Plot_model,Freq>0)

Plot_model$Col <- ifelse(Plot_model$GF=='0_Pulse','#56B4E9','#D55E00')



### Supplement Figures ? Tables

Plot_Fig_2_A <- function(Data,x.axes.lables){
  Px <-  ggplot(Data,aes(x=as.character(Combination),y=as.numeric(as.character(Diff_s)),colour=Col))+
    geom_point(aes(size = Freq),show.legend = F)+
    geom_boxplot(show.legend = F)+
    geom_abline(intercept = 0,slope = 0,linetype=2,aes(colour='grey'))+
    coord_cartesian(ylim = c(-3,2),expand = 0)+
    labs(x = "Predictor combination")+
    labs(y = "Standardized difference between true and estimated time")+
    theme(axis.text.x = element_text(angle = 0))+
    scale_x_discrete(labels= x.axes.lables)+
    scale_color_manual("Gene Flow Model",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[6]),
                       labels = c("Pulse","Continuous"))
  return(Px)
  
}


x.axes.lables=c("HES\n0.02\nInf\nCon","HES\n0.02\nInf\nCon","HES\n0.05\nInf\nCon","HES\n0.05\nInf\nCon"
                ,"LES\n0.02\nInf\nCon","LES\n0.02\nInf\nCon","LES\n0.05\nInf\nCon","LES\n0.05\nInf\nCon"
                ,"HES\n0.02\nSim\nVar","HES\n0.02\nSim\nVar","HES\n0.05\nSim\nVar","HES\n0.05\nSim\nVar"
                ,"LES\n0.02\nSim\nVar","LES\n0.02\nSim\nVar","LES\n0.05\nSim\nVar","LES\n0.05\nSim\nVar"
                ,"HES\n0.02\nCom\nVar","HES\n0.02\nCom\nVar","HES\n0.05\nCom\nVar","HES\n0.05\nCom\nVar"
                ,"LES\n0.02\nCom\nVar","LES\n0.02\nCom\nVar","LES\n0.05\nCom\nVar","LES\n0.05\nCom\nVar"
                ,"HES\n0.02\nSim\nCon","HES\n0.02\nSim\nCon","HES\n0.05\nSim\nCon","HES\n0.05\nSim\nCon"
                ,"LES\n0.02\nSim\nCon","LES\n0.02\nSim\nCon","LES\n0.05\nSim\nCon","LES\n0.05\nSim\nCon")

Plot_Fig_2_A(Plot_model,x.axes.lables)
```


```{r tableS1, echo=FALSE,results='asis' }

print_B_model_result <- data.frame(B_model_result)
kable(print_B_model_result , "latex",col.names = c("mean" , "sd"   , "5.5%"  ,"94.5%", "n_eff", "Rhat" ),digits = 2,
      caption = "\\label{tab:tableS1} Mean, standart deviation, 5.5/94.5 compatibility interval of the posterior distribution for every parameter effect on the standardized difference between true and estimated admixture time.") %>%
  collapse_rows(columns = 1, latex_hline = "major", valign = "middle")%>%
  kable_styling(latex_options = "HOLD_position")
```

```{r figS3, message=FALSE, echo=FALSE,warning=FALSE,fig.width=12,fig.height=6,fig.cap="\\label{fig:figS3} Exponential estimates for the mean time."}

Lomax.Fig_mean_exp <- ggarrange(New.P1_mean_GF_exp,New.P3_mean_GF_exp,
                   labels = c("A","B"),
                   ncol = 2, nrow = 1,common.legend = T,legend = 'bottom')

Lomax.Fig_mean_exp
```


```{r tableS2, echo=FALSE,results='asis' }

Param_Est_Tabel <- rbind(Expo_fit_tabel,Lomax_fit_tabel)
Models <- c("Exponential","Exponential","Exponential","Lomax (td=1)","Lomax (td=1)","Lomax (td=1)" 
           ,"Lomax (td=100)","Lomax (td=100)","Lomax (td=100)","Lomax (td=200)","Lomax (td=200)","Lomax (td=200)"
            ,"Lomax (td=400)","Lomax (td=400)","Lomax (td=400)","Lomax (td=800)","Lomax (td=800)","Lomax (td=800)"
            ,"Lomax (td=1000)","Lomax (td=1000)","Lomax (td=1000)","Lomax (td=1500)","Lomax (td=1500)","Lomax (td=1500)"
            ,"Lomax (td=2000)","Lomax (td=2000)","Lomax (td=2000)","Lomax (td=2500)","Lomax (td=2500)","Lomax (td=2500)")
Params_name <- rep(c("A","mean time","c"),10)
Param_Est_Tabel <- cbind(Models,Params_name,Param_Est_Tabel)


kable(Param_Est_Tabel , "latex",col.names = c("Model","Parameter","Estimate","2.5 %", "97.5 %"),row.names = FALSE,
      caption = "\\label{tab:tableS2} Mean and 2.5/97.5 compatibility interval for every parameter estimated in the model fit") %>%
  #collapse_rows(columns = 1, latex_hline = "major", valign = "middle")%>%
  kable_styling(latex_options = "HOLD_position")
```

```{r message=FALSE, echo=FALSE,warning=FALSE}
### Functions
Get_Filtered_Simulated_Fragments_fn <- function(Path_to_Fragment_File,header,recomb_rate,n_Haploid){
  Segments <- read.table(Path_to_Fragment_File,stringsAsFactors = F,header=header)
  if(header==F){
    colnames(Segments) = c('Ind','chrom', 'start','end')
  }
  
  Segments$length_bp <- as.numeric(Segments$end) - as.numeric(Segments$start)
  m=sum(Segments$length_bp)/(length(unique(Segments$chrom))*n_Haploid*150e6)
  Segments$length_cM <- Segments$length_bp*(recomb_rate)*100
  
  Segments_filtered <- c()
  for(chr in 1:22){
    Segments_filtered_chr <- Segments[Segments$chrom==paste("chr",chr,sep = "") & !duplicated(Segments$start) & !duplicated(Segments$end),]
    Segments_filtered <- rbind(Segments_filtered,Segments_filtered_chr)
    rm(Segments_filtered_chr)
  }
  return(list(Segments_filtered=Segments_filtered,m=m))
  
}

Assign_Genetic_distance_Simulation_interpolate_fn <- function(Path_to_Fragment_File,header,Path_to_Recomb_Map,n_Haploid){
  Fragments <- read.table(Path_to_Fragment_File,stringsAsFactors = F,header=header,fill = T)
  if(header==F){
    colnames(Fragments) = c('Ind','chrom', 'start','end')
  }
  Fragment_bp=Fragments$end - Fragments$start
  m=sum(Fragment_bp)/(length(unique(Fragments$chrom))*n_Haploid*150e6)
  Recomb_Map <- read.table(Path_to_Recomb_Map, header = T)
  Fragments_cM <- c()
  for(chr in 1:length(unique(Fragments$chrom))){
    Recomb_Map_chr <- Recomb_Map
    Fragments_chr <- Fragments[Fragments$chrom==paste("chr",chr,sep=""),]
    #Start_Arch_Freg <- approx(x=Recomb_Map_chr[,2]  , y=Recomb_Map_chr[,4], xout=Fragments_chr$start,method = "linear")
    #Stop_Arch_Freg <- approx(x=Recomb_Map_chr[,2], y=Recomb_Map_chr[,4], xout=Fragments_chr$end,method = "linear")
    Start_Arch_Freg <- approx(x=Recomb_Map_chr[,2]  , y=Recomb_Map_chr[,4], xout=Fragments_chr$start,method = "constant")
    Stop_Arch_Freg <- approx(x=Recomb_Map_chr[,2], y=Recomb_Map_chr[,4], xout=Fragments_chr$end,method = "constant")
    Chr_x <- data.frame(chrom=paste("chr",chr,sep = ""),Start_cM=Start_Arch_Freg$y,End_cM=Stop_Arch_Freg$y,length_bp=Fragments_chr$end - Fragments_chr$start)
    Fragments_cM <- rbind(Fragments_cM,Chr_x)
  }
  Fragments_cM_clean <- Fragments_cM[complete.cases(Fragments_cM$Start_cM),]
  Fragments_cM_clean <- Fragments_cM_clean[complete.cases(Fragments_cM_clean$End_cM),]
  Fragments_cM_clean$length_cM <- Fragments_cM_clean$End_cM - Fragments_cM_clean$Start_cM
  Fragments_cM_clean_filtered <- c()
  for(chr in 1:22){
    Fragments_cM_clean_filtered_chr <- Fragments_cM_clean[Fragments_cM_clean$chrom==paste("chr",chr,sep = "") & !duplicated(Fragments_cM_clean$Start_cM) & !duplicated(Fragments_cM_clean$End_cM),]
    Fragments_cM_clean_filtered <- rbind(Fragments_cM_clean_filtered,Fragments_cM_clean_filtered_chr)
    rm(Fragments_cM_clean_filtered_chr)
  }
  return(list(Fragments_cM_clean_filtered=Fragments_cM_clean_filtered,m=m))
  
}

Assign_Genetic_distance_interpolate_fn <- function(Recomb_Map,Fragments){
  Fragments_cM <- c()
  for(chr in 1:23){
    if(chr==23){
      chr="X"
    }
    else{
      chr=chr
    }
    Recomb_Map_chr <- Recomb_Map[Recomb_Map$Chr==paste("chr",chr,sep=""),]
    Fragments_chr <- Fragments[Fragments$chrom==chr,]
    Start_Arch_Freg <- approx(x=Recomb_Map_chr$Begin, y=Recomb_Map_chr$cM, xout=Fragments_chr$start,method = "constant")
    Stop_Arch_Freg <- approx(x=Recomb_Map_chr$Begin, y=Recomb_Map_chr$cM, xout=Fragments_chr$end,method = "constant")
    Chr_x <- data.frame(chr=chr,Start_cM=Start_Arch_Freg$y,End_cM=Stop_Arch_Freg$y,length_bp=Fragments_chr$length,called=Fragments_chr$called)
    Fragments_cM <- rbind(Fragments_cM,Chr_x)
  }
  Fragments_cM_clean <- Fragments_cM[complete.cases(Fragments_cM$Start_cM),]
  Fragments_cM_clean <- Fragments_cM_clean[complete.cases(Fragments_cM_clean$End_cM),]
  Fragments_cM_clean$length_cM <- Fragments_cM_clean$End_cM - Fragments_cM_clean$Start_cM
  return(Fragments_cM_clean)
  
}
#truncated expo density
dtexp <- function(x, rate=1, lower_trunc, upper_trunc){
  dexp(x, rate, log=T) - logspace.sub(pexp(lower_trunc, rate, lower=F, log=T),pexp(upper_trunc, rate, lower=F, log=T))
}

#truncated lomax density
dtlomax <- function(x, scale, shape, lower_trunc, upper_trunc){
  VGAM::dlomax(x, scale=scale, shape=shape, log=T) - 
    logspace.sub(VGAM::plomax(lower_trunc, scale=scale, shape=shape, lower=F, log=T),VGAM::plomax(upper_trunc, scale=scale, shape=shape, lower=F, log=T))
}

fit_exp_optim_rep=function(Fragments,lower_trunc,upper_trunc){
  l=Fragments[Fragments>=lower_trunc & Fragments<=upper_trunc]
  n = rep(1, length(l))
  
  try({
    f = function(par) -sum(n * dtexp(l, exp(par[1]), lower_trunc=lower_trunc,upper_trunc = upper_trunc))
    #f2 = function(par) -sum(n * dtexp(l, (par[1])))
    res = optim(c(0), f, method="L-BFGS-B")
    par =exp(res$par)
    return(data.frame(rate=par, ll_exp = -res$value))
  }, silent=F)
  return(data.frame(rate=NA, ll_exp=NA))
}

fit_lomax_optim_fixed_shape_rep=function(Fragments,fixed_shape,lower_trunc,upper_trunc){
  l=Fragments[Fragments>=lower_trunc & Fragments<=upper_trunc]
  n = rep(1, length(l))
  
  try({
    f = function(par)-sum(n * dtlomax(l, scale=exp(par[1]), shape=fixed_shape, lower_trunc=lower_trunc,upper_trunc=upper_trunc))
    res = optim(c(-1), f, method="L-BFGS-B")
    pars = exp(res$par)
    return(data.frame(scale=pars,fixed_shape=fixed_shape,t_m_est=fixed_shape/pars,tm=(fixed_shape/pars)*100, ll_lomax = -res$value,lower_trunc=lower_trunc,upper_trunc=upper_trunc))
  }, silent=F)
  return(data.frame(scale=NA, t_m=NA,tm_exp=NA,ll_lomax=NA))
}

fit_lomax_optim_rep=function(Fragments,lower_trunc,upper_trunc){
  l=Fragments[Fragments>=lower_trunc & Fragments<=upper_trunc]
  n = rep(1, length(l))

  try({
    f = function(par)-sum(n * dtlomax(l, scale=par[1], shape=par[2],lower_trunc=lower_trunc,upper_trunc=upper_trunc))
    res = optim(c(1, 1), f, method="L-BFGS-B", lower=c(1e-5, 1))
    pars = res$par
    return(data.frame(scale=pars[1], shape=pars[2],t_m_est=pars[2]/pars[1],t_m=(pars[2]/pars[1])*100, ll_lomax=-res$value,lower_trunc=lower_trunc,upper_trunc=upper_trunc))
  }, silent=F)
  return(data.frame(scale=NA, shape=NA,t_m=NA,tm_exp=NA,ll_lomax=NA))
}

Get_Expo_est_fn <- function(Fragments,lower_truncs,upper_trunc,m){
  Expo_Res <- c()
  for(i in lower_truncs){
    expo_fit_res=fit_exp_optim_rep(Fragments$length_cM,i,upper_trunc)
    #expo_fit_res$t_m <- (expo_fit_res$rate*100)/(1-m)
    expo_fit_res$t_m <- (expo_fit_res$rate*100)
    Expo_Res <- rbind(Expo_Res,expo_fit_res)
  }
 
  Expo_Res$lower_trunc <- lower_truncs
  Expo_Res$upper_trunc <- upper_trunc
  return(Expo_Res)
  
}


Get_Lomax_fixed_shape_est_fn <- function(t_d,Fragments,Expo_Res,Expo_Res_col_tm,Expo_Res_col_lower_trunc,Expo_Res_col_upper_trunc){
  Res_lomax <- c()
  for(trunc in 1:length(Expo_Res[,1])){
    t_d=t_d
    t_expo_est=Expo_Res[trunc,Expo_Res_col_tm]
    all_t_lomax_est <- c()
    for(t in 1:length(t_d)){
      fixed_shape= (t_expo_est^2)/((t_d[t]/4)^2)
      Res_Segments_optim_lomax=fit_lomax_optim_fixed_shape_rep(Fragments$length_cM,fixed_shape,Expo_Res[trunc,Expo_Res_col_lower_trunc],Expo_Res[trunc,Expo_Res_col_upper_trunc])
      all_t_lomax_est <- rbind(all_t_lomax_est,Res_Segments_optim_lomax)
    }
    Res_lomax <- rbind(Res_lomax,all_t_lomax_est)
    
  }
  Res_lomax$length_GF <- rep(t_d,length(Expo_Res[,1]))
  Res_lomax$t_expo_est <- rep(Expo_Res$rate,each=length(t_d))
  Res_lomax$t_m_expo_est <- rep((Expo_Res$t_m),each=length(t_d))
  return(Res_lomax)
  
}

Get_Lomax_est_fn <- function(Fragments,Expo_Res,Expo_Res_col_lower_trunc,Expo_Res_col_upper_trunc){
  Res_lomax <- c()
  for(trunc in 1:length(Expo_Res[,1])){
      Res_Segments_optim_lomax=fit_lomax_optim_rep(Fragments$length_cM,Expo_Res[trunc,Expo_Res_col_lower_trunc],Expo_Res[trunc,Expo_Res_col_upper_trunc])
      Res_lomax <- rbind(Res_lomax,Res_Segments_optim_lomax)
  }
  Res_lomax$length_GF_est <- 1/sqrt(Res_lomax$shape/Res_lomax$t_m_est)*4

  return(Res_lomax)
}


LRT_fn= function(ll) {2*(ll[1]-ll[2])}

LRT_Lomax_fn <- function(Lomax_Fragments_fit_results,t_d){
  LRT_res <- c()
  for(i in seq(0,length(Lomax_Fragments_fit_results$scale)-length(t_d),length(t_d))){
    i=i+1
    GF_length_model <- t(combn(Lomax_Fragments_fit_results$length_GF[i:(i+(length(t_d)-1))],2))
    ll <- t(combn(Lomax_Fragments_fit_results$ll_lomax[i:(i+(length(t_d)-1))],2))
    l_t <- rep(Lomax_Fragments_fit_results$lower_trunc[i],length(ll[1]))
    u_t <- rep(Lomax_Fragments_fit_results$upper_trunc[i],length(ll[1]))
    
    LRT <- apply(ll, 1, LRT_fn)
    
    LRT_res_x <- cbind(l_t,u_t,GF_length_model,ll,LRT)
    colnames(LRT_res_x) <- c("lower_cutoff","upper_cutoff","GF_Length_Model_1","GF_Length_Model_2","Likelihood_M_1","Likelihood_M_2","LRT")
    LRT_res <- rbind(LRT_res,LRT_res_x)
  }
  
  LRT_res <- as.data.frame(LRT_res)
  return(LRT_res)
  
}

Results_fit_Simulation <- function(Path_to_Fragment_File,header,Path_to_Recomb_Map=NA,recomb_rate,upper_trunc,n_Haploid){
  if(is.na(Path_to_Recomb_Map)==T){
    Segments_filtered <- Get_Filtered_Simulated_Fragments_fn(Path_to_Fragment_File,header = header,recomb_rate = recomb_rate,n_Haploid=n_Haploid)
    m <- Segments_filtered$m
    Segments_filtered <- Segments_filtered$Segments_filtered
  }
  else{
    Segments_filtered <- Assign_Genetic_distance_Simulation_interpolate_fn(Path_to_Fragment_File,Path_to_Recomb_Map,header = header,n_Haploid=n_Haploid)
    m <- Segments_filtered$m
    Segments_filtered <- Segments_filtered$Fragments_cM_clean_filtered
  }

  Expo_res <- Get_Expo_est_fn(Fragments = Segments_filtered,lower_truncs = c(0.001,0.002,0.005,0.01,0.05,0.1,0.15,0.2,0.5),upper_trunc = upper_trunc,m=m)
  
  Lomax_res <- Get_Lomax_est_fn(Segments_filtered,Expo_res,4,5)
  
  Lomax_fixed_shape_res <- Get_Lomax_fixed_shape_est_fn(t_d = c(1,100,200,400,800,1000,1500,2000,2500),Fragments = Segments_filtered,Expo_Res = Expo_res,
                                                        Expo_Res_col_tm = 3,Expo_Res_col_lower_trunc = 4,Expo_Res_col_upper_trunc = 5)
  Lomax_res_LRT <- LRT_Lomax_fn(Lomax_fixed_shape_res,t_d = c(1,100,200,400,800,1000,1500,2000,2500))
  
  Pulse_vs_Continuous <- Lomax_res_LRT[Lomax_res_LRT$GF_Length_Model_1==1 & abs(Lomax_res_LRT$LRT)<=2,]
  
  # LME GF_length
  LME_gf_length <- c()
  for(i in  c(0.001,0.002,0.005,0.01,0.05,0.1,0.15,0.2,0.5)){
    LME_gf_length_x=Lomax_res[Lomax_res$ll_lomax==max(Lomax_res$ll_lomax[Lomax_res$lower_trunc==i]),]
    LME_gf_length <- rbind(LME_gf_length,LME_gf_length_x)
    rm(LME_gf_length_x)
  }
  
  LME_gf_length_fixed_shape <- c()
  for(i in  c(0.001,0.002,0.005,0.01,0.05,0.1,0.15,0.2,0.5)){
    LME_gf_length_fixed_shape_x=Lomax_fixed_shape_res[Lomax_fixed_shape_res$ll_lomax==max(Lomax_fixed_shape_res$ll_lomax[Lomax_fixed_shape_res$lower_trunc==i]),]
    LME_gf_length_fixed_shape <- rbind(LME_gf_length_fixed_shape,LME_gf_length_fixed_shape_x)
    rm(LME_gf_length_fixed_shape_x)
  }

  return(list(
    Filtered_Fragments= Segments_filtered,
    m=m,
    Expo_res= Expo_res,
    Lomax_res=Lomax_res,
    Lomax_fixed_shape_res=Lomax_fixed_shape_res,
    Lomax_res_LRT=Lomax_res_LRT,
    Pulse_vs_Continuous=Pulse_vs_Continuous,
    LME_gf_length=LME_gf_length,
    LME_gf_length_fixed_shape=LME_gf_length_fixed_shape
  ))
  
}



##### Simulation Results #####
## No Recombination
# True Pulse no recombination
True_Pulse_no_Recomb <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Simulation-merged-_Scenario_1__Archaic_Segments_run_0.bed",header = F,
                                    recomb_rate = 1.2e-8,upper_trunc = 1.2,n_Haploid=100)

# Inferred Pulse no recombination
Inferred_Pulse_no_Recomb <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Inferred_Archaic_Tracts-_Scenario_1_-run0_decoded_cutoff_0.9.txt",header=T,
                                        recomb_rate = 1.2e-8,upper_trunc = 1.2,n_Haploid=100)

# True Continuous no recombination
True_Continuous_no_Recomb <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Simulation-merged-_Scenario_2__Archaic_Segments_run_0.bed",header = F,
                                    recomb_rate = 1.2e-8,upper_trunc = 1.2,n_Haploid=100)

# Inferred Continuous no recombination
Inferred_Continuous_no_Recomb <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Inferred_Archaic_Tracts-_Scenario_2_-run0_decoded_cutoff_0.9.txt",header=T,
                                        recomb_rate = 1.2e-8,upper_trunc = 1.2,n_Haploid=100)

## With Recombination
correction_Map="Scaled_Decode_Map"
# True Pulse no recombination
True_Pulse_with_Recomb <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Simulation-merged-_Scenario_1_Recomb__Archaic_Segments_run_0.bed",header = F,
                                      Path_to_Recomb_Map=paste("Recombination_Maps/",correction_Map,".txt",sep = ""),upper_trunc = 1.2,n_Haploid=100)

# Inferred Pulse no recombination
Inferred_Pulse_with_Recomb <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Inferred_Archaic_Tracts-_Scenario_1_Recomb_-run0_decoded_cutoff_0.9.txt",header=T,
                                          Path_to_Recomb_Map=paste("Recombination_Maps/",correction_Map,".txt",sep = ""),upper_trunc = 1.2,n_Haploid=100)

# True Continuous no recombination
True_Continuous_with_Recomb <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Simulation-merged-_Scenario_2_Recomb__Archaic_Segments_run_0.bed",header = F,
                                           Path_to_Recomb_Map=paste("Recombination_Maps/",correction_Map,".txt",sep = ""),upper_trunc = 1.2,n_Haploid=100)

# Inferred Continuous no recombination
Inferred_Continuous_with_Recomb <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Inferred_Archaic_Tracts-_Scenario_2_Recomb_-run0_decoded_cutoff_0.9.txt",header=T,
                                               Path_to_Recomb_Map=paste("Recombination_Maps/",correction_Map,".txt",sep = ""),upper_trunc = 1.2,n_Haploid=100)

## No population specific map
correction_Map="Scaled_Genetic_AAMap"
True_Pulse_with_Recomb_AAMap_corrected <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Simulation-merged-_Scenario_1_Recomb__Archaic_Segments_run_0.bed",header = F,
                                      Path_to_Recomb_Map=paste("Recombination_Maps/",correction_Map,".txt",sep = ""),upper_trunc = 1.2,n_Haploid=100)

# Inferred Pulse no recombination
Inferred_Pulse_with_Recomb_AAMap_corrected <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Inferred_Archaic_Tracts-_Scenario_1_Recomb_-run0_decoded_cutoff_0.9.txt",header=T,
                                          Path_to_Recomb_Map=paste("Recombination_Maps/",correction_Map,".txt",sep = ""),upper_trunc = 1.2,n_Haploid=100)

# True Continuous no recombination
True_Continuous_with_Recomb_AAMap_corrected <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Simulation-merged-_Scenario_2_Recomb__Archaic_Segments_run_0.bed",header = F,
                                           Path_to_Recomb_Map=paste("Recombination_Maps/",correction_Map,".txt",sep = ""),upper_trunc = 1.2,n_Haploid=100)

# Inferred Continuous no recombination
Inferred_Continuous_with_Recomb_AAMap_corrected <- Results_fit_Simulation(Path_to_Fragment_File = "Icelandic_Segments_Paper_Simulation/ALL_Inferred_Archaic_Tracts-_Scenario_2_Recomb_-run0_decoded_cutoff_0.9.txt",header=T,
                                               Path_to_Recomb_Map=paste("Recombination_Maps/",correction_Map,".txt",sep = ""),upper_trunc = 1.2,n_Haploid=100)

All_Simulations_Pulse_expo_fit <- data.frame(t_m=c(True_Pulse_no_Recomb$Expo_res$t_m,True_Pulse_no_Recomb$Expo_res$t_m,True_Continuous_with_Recomb_AAMap_corrected$Expo_res$t_m,Inferred_Pulse_no_Recomb$Expo_res$t_m,Inferred_Pulse_with_Recomb$Expo_res$t_m,Inferred_Pulse_with_Recomb_AAMap_corrected$Expo_res$t_m),Name=rep(c("0_True_P_n_R","1_True_P_w_R","2_True_P_w_R_AAMap_cor","3_Inf_P_n_R","4_Inf_P_w_R","5_Inf_P_w_R_AAMap_cor"),each=9),lower_trunc=True_Pulse_no_Recomb$Expo_res$lower_trunc,upper_trunc=True_Pulse_no_Recomb$Expo_res$upper_trunc,variable="mean GF expo")

All_Simulations_Pulse_lomax_fit <- data.frame(t_m=c(True_Pulse_no_Recomb$Lomax_res$t_m,True_Pulse_no_Recomb$Lomax_res$t_m,True_Continuous_with_Recomb_AAMap_corrected$Lomax_res$t_m,Inferred_Pulse_no_Recomb$Lomax_res$t_m,Inferred_Pulse_with_Recomb$Lomax_res$t_m,Inferred_Pulse_with_Recomb_AAMap_corrected$Lomax_res$t_m),Name=rep(c("0_True_P_n_R","1_True_P_w_R","2_True_P_w_R_AAMap_cor","3_Inf_P_n_R","4_Inf_P_w_R","5_Inf_P_w_R_AAMap_cor"),each=9),lower_trunc=True_Pulse_no_Recomb$Lomax_res$lower_trunc,upper_trunc=True_Pulse_no_Recomb$Lomax_res$upper_trunc,variable="mean GF lomax")


```

```{r figS4, message=FALSE, echo=FALSE,warning=FALSE,fig.width=12,fig.height=6,fig.cap="\\label{fig:figS3} Icelandic fragments simulated"}

P_Sim_Frag_Expo <- ggplot(All_Simulations_Pulse_expo_fit,aes(x=Name,y=as.numeric(as.character(t_m)),colour=factor(Name)))+
                      geom_boxplot()+
                      facet_grid(~as.factor(lower_trunc),switch = "x")+
                      ggtitle("Exponential PDF fit") +
                      geom_hline( aes(yintercept = 1500 ))+
                      labs(x = "lower cutoff in cM")+
                      labs(y = "Estimated Admixture Time")+
                      theme(
                        axis.text.x=element_blank(),
                        axis.ticks.x=element_blank())+
                      coord_cartesian(ylim = c(0,2200), expand = 0)+
                      scale_color_manual("Simulations",
                                         values = c(cbPalette_viridis[1],cbPalette_viridis[2],cbPalette_viridis[3],cbPalette_viridis[4],cbPalette_viridis[5],cbPalette_viridis[6]),
                                        labels = c("True Fragments","True Fragments Recombination","True Fragments Recombination AAMap corrected","Inferred Fragments","Inferred Fragments Recombination","Inferred Fragments Recombination AAMap corrected"))
 
P_Sim_Frag_Lomax <- ggplot(All_Simulations_Pulse_lomax_fit,aes(x=Name,y=as.numeric(as.character(t_m)),colour=factor(Name)))+
                      geom_boxplot()+
                      facet_grid(~as.factor(lower_trunc),switch = "x")+
                      ggtitle("Lomax PDF fit") +
                      geom_hline( aes(yintercept = 1500 ))+
                      labs(x = "lower cutoff in cM")+
                      labs(y = "Estimated Admixture Time")+
                      theme(
                        axis.text.x=element_blank(),
                        axis.ticks.x=element_blank())+
                      coord_cartesian(ylim = c(0,2200), expand = 0)+
                      scale_color_manual("Simulations",
                                         values = c(cbPalette_viridis[1],cbPalette_viridis[2],cbPalette_viridis[3],cbPalette_viridis[4],cbPalette_viridis[5],cbPalette_viridis[6]),
                                         labels = c("True Fragments","True Fragments Recombination","True Fragments Recombination AAMap corrected","Inferred Fragments","Inferred Fragments Recombination","Inferred Fragments Recombination AAMap corrected"))
 
Segment_simulation_result <- ggarrange(P_Sim_Frag_Expo,P_Sim_Frag_Lomax,
                   labels = c("A","B"),
                   ncol = 2, nrow = 1,common.legend = T,legend = 'bottom')

Segment_simulation_result
```

```{r figS5, message=FALSE, echo=FALSE,warning=FALSE,fig6.pos="H",fig.width=9,fig.height=6,fig.cap="\\label{fig:fig5} Different admixure duration models ranging from a one generation pulse tu 2500 generations for Neandertal admixture using directly infered introgressed segments from Skov & Coll Macia et al. 2020"}
### For the paper plot cutoff 0.05 - 1.2 cM
#### Real Data Results
lower_trunc=0.05
upper_trunc=1.2

Icelandic_Fragments <- read.table("Real_Data_Analysis/Archaicfragments_Iceland.txt",header = T)

Icelandic_Recomb_Map <- read.table("Real_Data_Analysis/RecombmapIceland.txt", header = T)

Icelandic_Fragments_Filtered <- Icelandic_Fragments[Icelandic_Fragments$archaic=="Vindija" | Icelandic_Fragments$archaic=="Altai",]

Icelandic_Fragments_cM=Assign_Genetic_distance_interpolate_fn(Icelandic_Recomb_Map,Icelandic_Fragments_Filtered)

Icelandic_Expo_est=Get_Expo_est_fn(Icelandic_Fragments_cM,lower_trunc,upper_trunc)

Icelandic_Expo_lomax=Get_Lomax_est_fn(Icelandic_Fragments_cM,Icelandic_Expo_est,4,5)

Icelandic_Expo_lomax_fixed=Get_Lomax_fixed_shape_est_fn(t_d,Icelandic_Fragments_cM,Icelandic_Expo_est,3,4,5)

Icelandic_LRT_lomax_fixed=LRT_Lomax_fn(Icelandic_Expo_lomax_fixed,t_d )

Icelandic_max_gf_duration_compatible=max(Icelandic_LRT_lomax_fixed$GF_Length_Model_2[Icelandic_LRT_lomax_fixed$GF_Length_Model_1==1 & Icelandic_LRT_lomax_fixed$LRT<=4])

Plot_Icelandic_Fragments=hist(Icelandic_Fragments_cM$length_cM[Icelandic_Fragments_cM$length_cM>=lower_trunc &
                                                              Icelandic_Fragments_cM$length_cM<=upper_trunc   ],breaks = 300,plot=F)
Plot_Icelandic_Fragments <- data.frame(mids=Plot_Icelandic_Fragments$mids,density=Plot_Icelandic_Fragments$density)
Icelandic_Fit_Results=data.frame(rep(Plot_Icelandic_Fragments$mids,10),c(
                                 dtexp(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$t_expo_est[1], Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc),
                                 dtlomax(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$scale[1], Icelandic_Expo_lomax_fixed$fixed_shape[1],Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc),
                                 dtlomax(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$scale[2], Icelandic_Expo_lomax_fixed$fixed_shape[2],Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc),
                                 dtlomax(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$scale[3], Icelandic_Expo_lomax_fixed$fixed_shape[3],Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc),
                                 dtlomax(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$scale[4], Icelandic_Expo_lomax_fixed$fixed_shape[4],Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc),
                                 dtlomax(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$scale[5], Icelandic_Expo_lomax_fixed$fixed_shape[5],Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc),
                                 dtlomax(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$scale[6], Icelandic_Expo_lomax_fixed$fixed_shape[6],Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc),
                                 dtlomax(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$scale[7], Icelandic_Expo_lomax_fixed$fixed_shape[7],Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc),
                                 dtlomax(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$scale[8], Icelandic_Expo_lomax_fixed$fixed_shape[8],Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc),
                                 dtlomax(Plot_Icelandic_Fragments$mids,Icelandic_Expo_lomax_fixed$scale[9], Icelandic_Expo_lomax_fixed$fixed_shape[9],Icelandic_Expo_lomax_fixed$lower_trunc,Icelandic_Expo_lomax_fixed$upper_trunc)),rep(c(0,t_d),each=length(Plot_Icelandic_Fragments$mids)))
colnames(Icelandic_Fit_Results) <- c("x","y","GF_length")


ggplot(data=Icelandic_Fit_Results,aes(x = x, y = y,color=as.factor(GF_length),fill=as.factor(GF_length)))+
  geom_point(data=Plot_Icelandic_Fragments,aes(x=mids,y=log(density),color=NULL,fill=NULL),show.legend = F)+
  geom_line(data=Icelandic_Fit_Results,aes(x = x, y = y,color=as.factor(GF_length)))+
  scale_color_manual("Admixture Duration",
                     values = c(c(cbPalette_viridis[1],cbPalette_viridis)),
                     labels = c(c("Pulse",c(0,t_d))))+
  scale_fill_manual( values = c(c(cbPalette_viridis[1],cbPalette_viridis)))+
  labs(x = "Genetic distance (cM)")+
  labs(y = "density") 
```
