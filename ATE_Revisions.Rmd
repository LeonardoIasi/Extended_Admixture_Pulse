---
title: "Revisions"

author: Leonardo Nicola Martin Iasi (Max Planck Institute for Evolutionary Anthropology,
  MPI EVA), Dr. Benjamin Marco Peter (MPI EVA, benjamin_peter@eva.mpg.de)
date: "`r Sys.Date()`"
output:
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
    fig_caption: yes
    citation_package: natbib
#    template: ATE_modified.tex
#  html_document:
#    code_folding: hide
#    toc: yes
#    toc_depth: 4
#    toc_float:
#      collapsed: no
#    citation_package: natbib
#  md_document:
#    toc: yes
#    variant: markdown_github
#    citation_package: natbib
#  bookdown::word_document2:
#    fig_caption: yes
#    toc: yes
#    toc_depth: '4'
#  github_document:
#    toc: yes
#    citation_package: natbib
header-includes:
- \usepackage{setspace}
- \doublespacing
- \usepackage[none]{hyphenat}
- \usepackage{amsfonts}
- \usepackage{amssymb}
- \usepackage{graphicx}
- \usepackage{float}
- \usepackage{xcolor}
- \floatplacement{figure}{H}

#csl: References/chicago-author-date.csl
bibliography: References/MyLibraryATE.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
#Make code wrap text so it doesn't go off the page when Knitting to PDF
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

<style>
body {
text-align: justify}
</style>

\maketitle
\section{Titles}
\begin{enumerate}
    \item An extended admixture pulse model reveals the limitation to the dating of Human-Neandertal introgression Revisions
\end{enumerate}


```{r message=FALSE, echo=F,warning=FALSE}
suppressPackageStartupMessages({
  library(VGAM)
  library(tidyverse)
  library(ggplot2)
  library(reshape)
  library(viridis)
  library(ggpubr)
  library(dplyr)
  library(rethinking)
  library(kableExtra)
  library(DEoptim)
  library("MASS")
  library(bbmle)
  library(flextable)
  library(officer)
})

Results_Table <- function(Table_Path) {
  header_for_Result=c("A","m","c","RSS_Expo","error","Scenario","GF_Start","GF_Stop","Ascertained","min_dist","Gene_Flow_Model")
  Raw_results <-  read.table(Table_Path, header = F,col.names = header_for_Result)
  Raw_results$mean.t.GF <- rowMeans(Raw_results[c('GF_Start', 'GF_Stop')], na.rm=TRUE)
  Raw_results$length.t.GF <- Raw_results$GF_Stop - Raw_results$GF_Start
  Raw_results$GF[Raw_results$length.t.GF== 1]="0_Pulse"
  Raw_results$GF[Raw_results$length.t.GF > 1]="Continous"
  Raw_results$Ascertainment[Raw_results$Ascertained== 0]="0_LES"
  Raw_results$Ascertainment[Raw_results$Ascertained == 1]="HES"
  Raw_results$min_dist <- as.factor(Raw_results$min_dist)
  Raw_results$GF[Raw_results$Gene_Flow_Model== "GF_Model_I"]="0_Pulse"
  return(Raw_results)
}


Get_Data_Table <- function(Data,mean_Gamma=F){
  xx=as.data.frame(table(round(Data$m,digits = 0), paste(Data$GF,Data$mean.t.GF, sep="_"),Data$mean.t.GF,Data$GF,Data$mean.t.GF,Data$length.t.GF))
  xx=subset(xx,Freq>0)
  xx=xx[order(xx$Var3),]
  return(xx)
}

Get_points <- function(input,lval,hval,log){
  # Read input file
  data <- read.table(input, header = F)
  
  
  # set dist and wcorr
  col=2
  dist <- data[,1]
  wcorr <- data[,col]
  ndist <- length(dist)  ## number of rows in dataset
  lval=lval
  hval=hval
  
  # check x lower value and y lower value
  data.sub <- data
  if ((lval > dist[1]) || (hval < dist[ndist])) {
    data.sub <- subset(data, ((dist <= hval) & (dist >= lval)))
  } 
  dist <- data.sub[,1]		# updated x values
  wcorr <- data.sub[,col]		# updated y values
  if(log==T){
    xx <- cbind(dist,log(wcorr))
    xx <- xx[complete.cases(xx),]
    wcorr <- xx[,2]
    wcorr <-c(wcorr,rep(NA,length(data.sub[,1])-length(wcorr)))
    dist <- xx[,1]
    dist <-c(dist,rep(NA,length(data.sub[,1])-length(dist)))
  }
  result_table <- data.frame(dist,wcorr)
  return(result_table)
}

Figure_1_C_1 <- function(input,log,Colour_P){
  
  Pulse <- Get_points(input[1],lval=0.05,hval=0.6,log)
  Continous <- Get_points(input[2],lval=0.05,hval=0.6,log)
  P_C_Data <- data.frame(Pulse,Continous)
  P_C_Data <- P_C_Data[P_C_Data$wcorr > -13,]
  
  Px <-  ggplot(data=P_C_Data,aes(y=wcorr,x=dist))+
    geom_point(aes(x=dist,y=wcorr),color=Colour_P[1],pch=4)+
    geom_point(aes(x=dist.1,y=wcorr.1),color=Colour_P[6],pch=18)+
    labs(y = "log weighted LD")+
    labs(x = "Genetic Distance in cM")
  #coord_cartesian(ylim = c(-13,-8),xlim=c(0,0.4),expand = 0)
  
  return(Px)
  
}

Figure_All_Real_Data <- function(input,log,GF_length,Colour_P){
  
  Real_Data <- c()
  for(i in input){
    xx <-Get_points(i,lval=0.05,hval=0.5,log)
    Real_Data <- c(Real_Data,xx)
  }
  Real_Data <- as.data.frame(Real_Data)
  Real_Data_names <- c()
  for(i in GF_length){
    Real_Data_names <- c(Real_Data_names,c('Genetic_Distance',i))
  }
  colnames(Real_Data) <- Real_Data_names
  Real_Data.melted <- melt(Real_Data, id = c("Genetic_Distance"))
  
  Px <-  ggplot(data =Real_Data.melted, aes(x = Genetic_Distance, y = value,color=variable)) +
    geom_point(pch=18)+
    coord_cartesian(ylim = c(-8,-14),expand = 0,xlim = c(0,0.5))+
    #geom_vline(xintercept=Split_time,linetype=3,color='black')+
    scale_color_manual(values = Colour_P)+
    labs(x = "Genetic distance")+
    labs(y = "log weighted LD")+
    labs(color="Admixture Duration")
  return(Px)
  
}

Figure_1_C_2 <- function(Timespan_GF_Models,time_l,Split_time,Mean_Time,Colour_P,max_y,max_x){
  
  n_GF_Models=length(Timespan_GF_Models)
  time=seq(1,time_l,1)
  
  Gamma_fun <- function(GF_Length,time_l,Split_time,Mean_Time){
    time=seq(1,time_l,1)
    EX= Mean_Time
    VarX= (GF_Length/4)**2
    b= EX/VarX
    a=EX*b
    
    GF_gamma <- dgamma(x=time,shape = a,scale = 1/b)
    GF_gamma[GF_gamma < 1e-6] = 0
    GF_gamma <- GF_gamma[1:time_l]
    m2 <- c()
    for (i in GF_gamma){
      x <- i*(0.03/sum(GF_gamma))
      m2 <- c(m2,x)
    }
    #m2 <- c(m2,rep(0,time_l-Split_time))
    #m2 <- c(m2,rep(0,time_l))
    #cutoff_in_Percent=(sum(m2[2550:5001])/0.03)*100
    
    GF <- c(m2)
    return(GF)
  }
  GF <- c(seq(1,time_l,1))
  for(i in 1:n_GF_Models){
    Timespan <- Timespan_GF_Models[i]
    GF_x <- Gamma_fun(Timespan,time_l,Split_time,Mean_Time)
    GF <- cbind(GF,GF_x)
  }
  GF <- as.data.frame(GF)
  colnames(GF) <- c('Time',Timespan_GF_Models)
  GF.melted <- melt(GF, id = "Time")
  Px <-  ggplot(data =GF.melted, mapping=aes(x = Time, y = value,color=variable,fill=variable)) +
    # outcomented part colors the area of t_d
    #geom_area(position = 'identity',mapping = aes(x = ifelse(Time>Mean_Time-(as.numeric(as.character(variable))/2) & Time< Mean_Time+(as.numeric(as.character(variable))/2) , Time, NA),fill=variable),show.legend = F,alpha = 0.33)+
    geom_area(position = 'identity',mapping = aes(x = ifelse(Time<Mean_Time-(as.numeric(as.character(variable))/2) 
     , Time, NA),fill=variable),show.legend = F,alpha = 0.33)+
    geom_area(position = 'identity',mapping = aes(x = ifelse(Time>Mean_Time+(as.numeric(as.character(variable))/2) 
       , Time, NA),fill=variable),show.legend = F,alpha = 0.33)+
    geom_line(show.legend = F)+
    coord_cartesian(ylim = c(0,1e-04),xlim = c(0,3050),expand = 0)+
    geom_vline(xintercept=Split_time,linetype=3,color='black')+
    scale_color_manual(values = Colour_P)+
    scale_fill_manual(values = Colour_P)+
    labs(x = "Time in Generations")+
    labs(y = "Migration Rate")+
    labs(color="Admixture Duration")
  return(Px)
}


Theoratical_Lomax <- function(Timespan_GF_Models,max_Genetic_distance,Split_time,Mean_Time,Intercept,Colour_P){
  n_GF_Models=length(Timespan_GF_Models)
  
  Lomax_fun <- function(GF_Length,max_Genetic_distance,Split_time,Mean_Time,Intercept,log=T){
    Genetic_length=seq(0.01,max_Genetic_distance,0.01)
    EX= Mean_Time
    VarX= (GF_Length/4)**2
    b= EX/VarX
    a=EX*b
    Theta=b
    k=a+1
    Lomax_normal <- function(dist,k,theta,A) A*(1 + ((dist/100) /  theta))^-(k)
    Lomax_log <- function(dist,k,theta,A) -k* log(1 + ((dist/100) /  theta)) + log(A)
    if(log==T){
      ALD <-  Lomax_log(dist=Genetic_length,k = k ,theta = Theta, A=Intercept)
    }
    else{
      ALD <-  Lomax_normal(dist=Genetic_length,k = k ,theta = Theta, A=Intercept)
    }
    Lomax_Result <- cbind(Genetic_length,ALD,k,Theta)
    return(Lomax_Result)
  }
  Lomax_Result <- c()
  for(i in Timespan_GF_Models){
    xx=Lomax_fun(i,max_Genetic_distance,Split_time,Mean_Time,Intercept,log=T)
    Lomax_Result <- cbind(Lomax_Result,xx)
  }
  Lomax_Result <- as.data.frame(Lomax_Result)
  colnames_Lomax_Result <- c()
  for(time in Timespan_GF_Models){
    colnames_Lomax_Result <- c(colnames_Lomax_Result,c('Genetic_Distance',time,'k','Theta'))
  }
  colnames(Lomax_Result) <- colnames_Lomax_Result
  Lomax_Result.melted <- melt(Lomax_Result, id = c("Genetic_Distance",'k','Theta'))
  Px <-  ggplot(data =Lomax_Result.melted, aes(x = Genetic_Distance, y = value,color=variable)) +
    geom_line()+
    #coord_cartesian(ylim = c(0,max(ALD$'2')),expand = 0)+
    coord_cartesian(ylim = c(-14,-8),expand = 0,xlim = c(0,0.5))+
    #geom_vline(xintercept=Split_time,linetype=3,color='black')+
    scale_color_manual(values = Colour_P)+
    labs(x = "Genetic distance (cM)")+
    labs(y = "log weighted LD")+
    labs(color="Admixture Duration")
  return(Px)
}

t_d=c(1,20,40,60,80,100,200,400,800,1000,1500,2000,2500)
cbPalette_viridis <- viridis(length(t_d),option = "D")

```

# Power Analysis to differentiat an extended from a simple pulse

Here we want to know for which duration and time since admixture we can differentiate an extended from a simple admixture pulse. We take a best case scenario were admixture segments are perfectly known. First, we compare the likelihood of the data simulated from a lomax distribution using different admixture durations, under the extended and simple pulse and perform a likelihood ratio test to find the parameter region where we can confidently distinguish these models.

## Perfectly known data

We fix the mean time of admixture to 1500 generation with different durations and calculate the likelihood of the data given the two models. We perform a likelihood ratio test with a significance cutoff of + 2. We perform each simulation 100 times with different amount of data. Our maximum amount is 100000 unique segments which is half the number observed in Skov et al. 2020. Here around 200000 unique segments were identified in Icelandic genomes using a posterior probability cutoff of 0.8 to identify the segment using an HMM (Skov et al. 2018).

```{r eval=F,message=FALSE, echo=FALSE,warning=FALSE}
# check the LRT
n_segments=1000
tm=2000
td=1000
k = 1/((td/(4*tm))^2)
seg = VGAM::rlomax(n=n_segments,shape3.q = k,scale = k/tm)

f_SP=  function(par) -sum(dexp(seg,par,log = T))
LME_SP = optim(par = c(100), lower = c(1),fn = f_SP, method="L-BFGS-B")
f_EP= function(par) -sum(dlomax(x=seg,shape3.q = par[2],scale = par[2]/par[1],log=T))
LME_ep = optim(par = c(100,10),lower = c(1,1) ,fn = f_EP, method="L-BFGS-B")
LRT = -2*(LME_ep$value - LME_SP$value)

print(LME_SP$par)
print(LME_SP$value)

print(LME_ep$par)
print(LME_ep$value)

mean(seg)

(k/(k-1))*(1/tm)
```

```{r eval=F,message=FALSE, echo=FALSE,warning=FALSE}
LME_fn <- function(seg){
  f_SP=  function(par) -sum(dexp(seg,par,log = T))
  LME_SP = optim(par = c(100), lower = c(1),fn = f_SP, method="L-BFGS-B")
  f_EP= function(par) -sum(dlomax(x=seg,shape3.q = par[2],scale = par[2]/par[1],log=T))
  LME_ep = optim(par = c(100,10),lower = c(1,1) ,fn = f_EP, method="L-BFGS-B")
  LRT = -2*(LME_ep$value - LME_SP$value)
  return(LRT)
}  

# not used for the simulations !!!
simulate_pulse=function(n_segments,tm,td){
  k = 1/((td/(4*tm))^2)
  sim_r = VGAM::rlomax(n=n_segments,shape3.q = k,scale = k/tm)
  LRT = LME_fn(sim_r)
  return(LRT)
}

frag_through_time_fn <- function(t,t_closer){
  s_t0=rexp(1,t)
  s_t_closer=rexp(1,t-t_closer)
  seg_t <- c(s_t0,s_t_closer)
  return(seg_t)
}

simulate_closer=function(n_ti,tm,td,t_since_admixture){
  t_closer=tm - td/2 - t_since_admixture
  k=1/((td/(4*tm))^2)
  sim_r=rgamma(n_ti,shape = k,scale = tm/k)
  if(length(which(sim_r<=t_closer))==0){
      sim_r=sim_r
  }else{
    sim_r=sim_r[-which(sim_r<=t_closer)]    
  }
  while(length(sim_r)!=n_ti){
    sim_r=c(sim_r,rgamma(n_ti-length(sim_r),shape = k,scale = tm/k))
    if(length(which(sim_r<=t_closer))==0){
        sim_r=sim_r
    }else{
      sim_r=sim_r[-which(sim_r<=t_closer)]    
    }
  
  }
  seg.res <-  t(sapply(sim_r,function(x) frag_through_time_fn(x,t_closer = t_closer)))
  LRT_0 = LME_fn(seg = seg.res[,1])
  LRT_closer = LME_fn(seg = seg.res[,2])
  return(c(LRT_0,LRT_closer))
}

n_seg=c(100,1000,10000,100000)
Sim_2_fn <- function(n_seg,rep=rep){
  LRT = list(
  P_td_1=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 1,t_since_admixture=50))),
  P_td_20=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 20,t_since_admixture=50))),
  P_td_40=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 40,t_since_admixture=50))),
  P_td_60=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 60,t_since_admixture=50))),
  P_td_80=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 80,t_since_admixture=50))),
  P_td_100=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 100,t_since_admixture=50))),
  P_td_200=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 200,t_since_admixture=50))),
  P_td_400=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 400,t_since_admixture=50))),
  P_td_800=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 800,t_since_admixture=50))),
  P_td_1000=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 1000,t_since_admixture=50))),
  P_td_1500=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 1500,t_since_admixture=50))),
  P_td_2000=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 2000,t_since_admixture=50))),
  P_td_2500=t(sapply(1:rep, function(x) simulate_closer(n_ti = n_seg,tm = 1500,td = 2500,t_since_admixture=50)))
  )
  return(LRT)
} 

Sim_2=lapply(n_seg, function(x) Sim_2_fn(x,rep=100))
#save(Sim_2,n_seg,file = "Paper_Revision_Poweranalysis_2.RData")


```



```{r figR1,message=FALSE, echo=FALSE,warning=FALSE,fig1.pos="H",fig.width=9,fig.height=9,fig.cap="\\label{fig:figR1} Liklihood ratios between the simple pulse and extended pulse model for different durations of admixture for 100, 1000, 10000 and 100000 segments sampled at time 0 and 50 generations after the end of admixture. Boxplots from 100 replications."}
load("Paper_Revision_Poweranalysis_2.RData")

Sim_2_ggplot_100 <- data.frame(l_LRT=melt(Sim_2[[1]])[3],t_sample=melt(Sim_2[[1]])[2],n_seg=as.factor(100),td=as.factor(rep(t_d,each=200)))
Sim_2_ggplot_1000 <- data.frame(l_LRT=melt(Sim_2[[2]])[3],t_sample=melt(Sim_2[[2]])[2],n_seg=as.factor(1000),td=as.factor(rep(t_d,each=200)))
Sim_2_ggplot_10000 <- data.frame(l_LRT=melt(Sim_2[[3]])[3],t_sample=melt(Sim_2[[3]])[2],n_seg=as.factor(10000),td=as.factor(rep(t_d,each=200)))
Sim_2_ggplot_100000 <- data.frame(l_LRT=melt(Sim_2[[4]])[3],t_sample=melt(Sim_2[[4]])[2],n_seg=as.factor(100000),td=as.factor(rep(t_d,each=200)))

Sim_2_ggplot_all <- rbind(Sim_2_ggplot_100,Sim_2_ggplot_1000,Sim_2_ggplot_10000,Sim_2_ggplot_100000)
Sim_2_ggplot_all$value <- ifelse(Sim_2_ggplot_all$value>=10,10,Sim_2_ggplot_all$value)
Sim_2_ggplot_all_sig_cutoff <- data.frame(n_seg = c(100,1000,10000,100000), Z = c(2.03136,2.44156,2.61434,2.70554))


Plot_power_analysis_2 <- function(Data,Colour_P,n_seg){
  Px <-  ggplot(Data,aes(x=as.factor(X2),y=value,color=as.factor(X2)))+
    geom_boxplot()+
    facet_grid(~td,switch = "x")+
    geom_hline( aes(yintercept = 2 ))+
    ggtitle(paste("n segments = ",n_seg,sep = ""))+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    ylim(c(-0.5,10))+
    labs(x = "Admixture Duration")+
    labs(y = "log Likelihood Ratio")+
    scale_color_manual("Gene Flow Model",
                       values = c(Colour_P[1],Colour_P[6]),
                       labels = c("Sampled at 0","Sampled 50 gen from GF"))
  return(Px)
  
}

#PA_2_A <- Plot_power_analysis_2(Sim_2_ggplot_100,cbPalette_viridis,100)
#PA_2_B <- Plot_power_analysis_2(Sim_2_ggplot_1000,cbPalette_viridis,1000)
#PA_2_C <- Plot_power_analysis_2(Sim_2_ggplot_10000,cbPalette_viridis,10000)
#PA_2_D <- Plot_power_analysis_2(Sim_2_ggplot_100000,cbPalette_viridis,100000)

#ggarrange(PA_2_A,PA_2_B,PA_2_C,PA_2_D,
#          labels = c("A","B","C", "D"),
#          ncol = 2, nrow = 2,common.legend = T,legend = 'bottom',heights = c(1,1))

Plot_power_analysis <- function(Data,Sim_2_ggplot_all_sig_cutoff,Colour_P){
  Px <-  ggplot(Data,aes(x=as.factor(X2),y=value,color=as.factor(X2)))+
    geom_boxplot()+
    facet_grid(n_seg~td,switch = "x",labeller=labeller(.rows=c("100"="# fragments: 100","1000"="# fragments: 1000", "10000"="# fragments: 10000", "1e+05"="# fragments: 100000")))+
    geom_hline(data = Sim_2_ggplot_all_sig_cutoff, aes(yintercept = Z))+
    theme(legend.position="bottom",
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    ylim(c(-0.5,10))+
    labs(x = "Admixture Duration")+
    labs(y = "log Likelihood Ratio")+
    #scale_y_continuous("log Likelihood Ratio", sec.axis = sec_axis(n_seg,name = "n unique segments"))+
    scale_color_manual("Gene Flow Model",
                       values = c(Colour_P[1],Colour_P[6]),
                       labels = c("Sampled at present","Sampled 50 after end of gene flow"))
  return(Px)
  
}



Plot_power_analysis(Sim_2_ggplot_all,Sim_2_ggplot_all_sig_cutoff,cbPalette_viridis)

```

## On msprime simulated ALD data

Here, we us msprime simulations to simulate the above scenarios. All samples are sampled at time 0, i.e. using present-day genomes to estimate $t_m$ and $t_d$. The ALDER inferred ALD is used to fit the simple and extended pulse. We compare the fit to data between the simple and extended pulse model using Akaike information criterion and a F-test (comparing significant differences between the residual sum of squares).

```{r eval=T,message=FALSE, echo=FALSE,warning=FALSE}
#### New Figure for Paper using recent sampling (50 gen): constant RR, RM no correction, RM diff RM correction, RM correction same RM ####


Filter_Result_Table <- function(Result.Table){
  Result.Table=read.table(Result.Table,header=F,sep = " ")
  Result.names <- c('A.sp', 'tm_sp', 'c.sp', 'RSS_SP','AIC_SP', 'A.ep', 'tm.ep', 'k.ep','c.ep', 'RSS_EP','AIC_EP', 'F_Test','Scenario.name','GF.Start','GF.End','AS','minDist','GF.Model')
  colnames(Result.Table) <- Result.names
  #Result.Table <- Result.Table[(1/Result.Table$s.exp)>0,]
  #Result.Table <- Result.Table[(1/Result.Table$s.exp)<5000,]
  #Result.Table <- Result.Table[Result.Table$RSS_Lomax<1e-2,]
  return(Result.Table)
}

#### True values
True_params_paper_parametrization <- function(Result.Table){
  True_params_Calc <- function(True_GF_length,True_mean_GF){
    EX= True_mean_GF
    GF_Len <-True_GF_length
    VarX= ((GF_Len)/4)**2
    b= EX/VarX
    a=EX*b
    a=a
    True_k=a
    True_tm=EX
    xx=c(True_k,True_tm)
    return(xx)
  }
  True.params <- c()
  for (i in 1:length(Result.Table$F_Test)) {
    xx=True_params_Calc(Result.Table$True_GF_length[i],Result.Table$True_mean_GF[i])
    True.params <- rbind(True.params,xx)
  }
  True.params <- as.data.frame(True.params)
  return(True.params)
}

Result.Table.paper.parametrization.fn <- function(Result.Table.path,Sampling.time.from.GF.End,name){
  Result.Table <- Filter_Result_Table(Result.Table.path)
  Result.Table$Name <- name
  Result.Table$Sample_Time <- Sampling.time.from.GF.End
  Result.Table$True_GF_length <- Result.Table$GF.End-Result.Table$GF.Start
  #Result.Table$True_mean_GF <- ((Result.Table$GF.End+Result.Table$GF.Start)/2)-(Result.Table$GF.Start-Result.Table$Sample_Time)
  Result.Table$True_mean_GF <- ((Result.Table$GF.End+Result.Table$GF.Start)/2)
  Result.Table$mean_GF_SP <- Result.Table$tm.sp
  Result.Table$mean_GF_EP_tm <- Result.Table$tm.ep
  Result.Table.comparison <- True_params_paper_parametrization(Result.Table)
  Result.Table$True_k <- Result.Table.comparison$V1
  Result.Table$True_tm <- Result.Table.comparison$V2
  #Result.Table.comparison$length_GF <- (sqrt(Result.Table$mean_GF_lomax_s/(((1/Result.Table$w.lomax))*Result.Table$s.lomax)))*4
  Result.Table.comparison$length_GF <- 4*Result.Table$tm.ep*Result.Table$k.ep^(-(1/2))
  Result.Table$length_GF <- Result.Table.comparison$length_GF
  
  return(Result.Table)
}

Plot_all_together_samples_50_gen_flipped <- function(ggdata,cbPalette_viridis){
  ggdata$Model <- factor(ggdata$Model,
                          levels = c("Simple Pulse","Extended Pulse"),ordered = TRUE)
  ggdata$Name <- factor(ggdata$Name,
                        levels = c("HapMap_HapMap_correction","HapMap_AAMap_correction","HapMap_no_correction",
                                   "Constant"),ordered = TRUE)
  ggplot(data = ggdata, aes(y=factor(Name),x=as.numeric(as.character(value)),colour=factor(Name))) +
    geom_boxplot(show.legend = T)+ 
    facet_grid(as.factor(Sample_Time)+as.factor(True_GF_length)+as.factor(True_mean_GF) ~Model, switch = "y")+
    geom_vline( aes(xintercept = True_mean_GF ))+
    labs(x = "Estimated Admixture Mean Time")+
    labs(y = "Sampling Time \n Simulated Admixture Duration \n Simulated Admixture Mean")+
    theme(
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank())+
    coord_cartesian(xlim = c(500,2000), expand = 0)+
    scale_x_continuous(breaks = seq(0, 1000, by = 500))+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[2],cbPalette_viridis[3],cbPalette_viridis[4]),
                       labels = c("HapMap HapMap corrected","HapMap AAMap corrected","HapMap not corrected","Constant Recombination"),
                       guide = guide_legend(reverse=TRUE))
  
}


Plot_sampling_50_gen_GF_Length_flipped <- function(ggdata,cbPalette_viridis){
  ggdata$Name <- factor(ggdata$Name,
                        levels = c("HapMap_HapMap_correction","HapMap_AAMap_correction","HapMap_no_correction",
                                   "Constant"),ordered = TRUE)
  ggplot(ggdata,aes(y=variable,x=as.numeric(as.character(value)),colour=factor(Name)))+
    geom_boxplot(show.legend = F)+
    facet_grid(as.factor(Sample_Time)+as.factor(True_GF_length)+as.factor(True_mean_GF) ~Model, switch = "y")+
    geom_vline( aes(xintercept = True_GF_length ))+
    labs(y = "")+
    labs(x = "Estimated Admixture Duration")+
    theme(
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank())+
    coord_cartesian(xlim = c(0,2500), expand = 0)+
    scale_x_continuous(breaks = seq(0, 2500, by = 500))+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[2],cbPalette_viridis[3],cbPalette_viridis[4]),
                       labels = c("HapMap HapMap corrected","HapMap AAMap corrected","HapMap not corrected","Constant Recombination"),
                       guide = guide_legend(reverse=TRUE))
}



Result.Table.path_ALD_constant <-'/mnt/diversity/leonardo_iasi/Adm_Time_Dating_Sim/Paper_Revisions/Segment_ALD_comparison_ALD/Result_Simple_Extended_Pulse/Result_file_SIM_Raw_ALDER-Fit-Segment_ALD_comparison_ALD-GF_Model_IV-min_dist_Fit-0.05-ascertainmentI-downsampled100-ReccNo_correction.txt'
Result.Table.path_ALD_no_correction <-'/mnt/diversity/leonardo_iasi/Adm_Time_Dating_Sim/Paper_Revisions/Segment_ALD_comparison_recombination_map_ALD/Result_Simple_Extended_Pulse/Result_file_SIM_Raw_ALDER-Fit-Segment_ALD_comparison_recombination_map_ALD-GF_Model_IV-min_dist_Fit-0.05-ascertainmentI-downsampled100-ReccNo_correction.txt'
Result.Table.path_ALD_AAMap_correction <-'/mnt/diversity/leonardo_iasi/Adm_Time_Dating_Sim/Paper_Revisions/Segment_ALD_comparison_recombination_map_ALD/Result_Simple_Extended_Pulse/Result_file_SIM_Raw_ALDER-Fit-Segment_ALD_comparison_recombination_map_ALD-GF_Model_IV-min_dist_Fit-0.05-ascertainmentI-downsampled100-ReccAAMap_correction.txt'
Result.Table.path_ALD_HapMap_correction <-'/mnt/diversity/leonardo_iasi/Adm_Time_Dating_Sim/Paper_Revisions/Segment_ALD_comparison_recombination_map_ALD/Result_Simple_Extended_Pulse/Result_file_SIM_Raw_ALDER-Fit-Segment_ALD_comparison_recombination_map_ALD-GF_Model_IV-min_dist_Fit-0.05-ascertainmentI-downsampled100-ReccHapMap_correction.txt'

Plot.data_ALD_constant <- Result.Table.paper.parametrization.fn(Result.Table.path = Result.Table.path_ALD_constant,Sampling.time.from.GF.End = 0,name = 'Constant')
Plot.data_ALD_no_correction <- Result.Table.paper.parametrization.fn(Result.Table.path = Result.Table.path_ALD_no_correction,Sampling.time.from.GF.End = 0,name = 'HapMap_no_correction')
Plot.data_ALD_AAMap_correction<- Result.Table.paper.parametrization.fn(Result.Table.path = Result.Table.path_ALD_AAMap_correction,Sampling.time.from.GF.End = 0,name = 'HapMap_AAMap_correction')
Plot.data_ALD_HapMap_correction <- Result.Table.paper.parametrization.fn(Result.Table.path = Result.Table.path_ALD_HapMap_correction,Sampling.time.from.GF.End = 0,name = 'HapMap_HapMap_correction')
Plot.data_ALD <- rbind(Plot.data_ALD_constant,Plot.data_ALD_no_correction,Plot.data_ALD_AAMap_correction,Plot.data_ALD_HapMap_correction)

Plot.data_ALD$True_mean_GF <- 1500
ggdata_t.ALD_tm_mean_GF_exp <- melt(Plot.data_ALD,measure.vars =  c('tm_sp'),id.vars = c('True_mean_GF','True_GF_length','Name'))
ggdata_t.ALD_tm_mean_GF_lomax <- melt(Plot.data_ALD,measure.vars =  c('mean_GF_EP_tm'),id.vars = c('True_mean_GF','True_GF_length','Name'))
ggdata_l.ALD_tm <- melt(Plot.data_ALD,measure.vars =  c('length_GF'),id.vars = c('True_mean_GF','True_GF_length','Name'))

```



``` {r eval=T,figR2_3_1, message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=9,fig.height=10,fig.cap="\\label{fig:figR2_3_1} Comparison between the Hudson only and hybrid Wright-Fischer/Hudson simulations for parameter inference under the simple and extended pulse model  A) Mean time estimates $t_m$ for different gene flow durations $t_d$ all sampled 50 generations after the gene flow ended. B) Duration estimate $t_d$ of the same scenario"}

# Plot 50 gen from Admixture
ggdata_t.ALD_tm_mean_GF_exp$Model <- "Simple Pulse"
ggdata_t.ALD_tm_mean_GF_lomax$Model <- "Extended Pulse"

ggdata_all_together_samples_ALD_tm <- rbind(ggdata_t.ALD_tm_mean_GF_exp,ggdata_t.ALD_tm_mean_GF_lomax)
ggdata_all_together_samples_ALD_tm$Sample_Time <- 0

ggdata_sampling_ALD_tm_gen_GF_Length <- ggdata_l.ALD_tm
ggdata_sampling_ALD_tm_gen_GF_Length$Model <- "Extended Pulse"
ggdata_sampling_ALD_tm_gen_GF_Length$Sample_Time <- 0

Mean_GF_ALD_tm <- Plot_all_together_samples_50_gen_flipped(ggdata = ggdata_all_together_samples_ALD_tm,cbPalette_viridis)
Duration_GF_ALD_tm <- Plot_sampling_50_gen_GF_Length_flipped(ggdata = ggdata_sampling_ALD_tm_gen_GF_Length,cbPalette_viridis)
Constant_sampling_time <- ggarrange(Mean_GF_ALD_tm,Duration_GF_ALD_tm,labels = c("A","B"),
          ncol = 2, nrow = 1,widths = c(0.6,0.4),common.legend = T,legend = 'bottom')

Constant_sampling_time
```



``` {r eval=T,figR2_3_2, message=FALSE, echo=FALSE,warning=FALSE,figR3_3.pos="H",fig.width=9,fig.height=10,fig.cap="\\label{fig:figR2_3_2} Neandertal duration simple and extended pulse AIC and F test comparison"}


AIC_comp=data.frame(AIC_SP=Plot.data_ALD$AIC_SP,AIC_EP=Plot.data_ALD$AIC_EP,
                      GF_duration=Plot.data_ALD$True_GF_length,Name=Plot.data_ALD$Name)
AIC_comp$Name <- factor(AIC_comp$Name,
                    levels = c("Constant","HapMap_no_correction","HapMap_AAMap_correction","HapMap_HapMap_correction"),ordered = TRUE)
P_AIC <- ggplot(AIC_comp, aes(x=as.factor(GF_duration), y=AIC_SP,color=as.factor(GF_duration))) + 
                geom_boxplot()+
                facet_grid(~Name,switch = "x")+
                labs(y = "AIC")+
                labs(x = "")+
                theme(
                  axis.ticks.y=element_blank(),
                  axis.ticks.x=element_blank(),
                  axis.text.x=element_blank())+
                coord_cartesian(expand = 0)+
                scale_color_manual("Admixture duration",
                                   values = cbPalette_viridis[1:7],
                                   labels = c(1,200,400,800,1000,1500,2000))



F_Test_comp=data.frame(F_Test_p=Plot.data_ALD$F_Test,
                      GF_duration=Plot.data_ALD$True_GF_length,Name=Plot.data_ALD$Name)
F_Test_comp$Name <- factor(F_Test_comp$Name,
                    levels = c("Constant","HapMap_no_correction","HapMap_AAMap_correction","HapMap_HapMap_correction"),ordered = TRUE)
P_F_Test <- ggplot(F_Test_comp, aes(x=as.factor(GF_duration), y=log(F_Test_p),color=as.factor(GF_duration))) + 
                geom_boxplot()+
                facet_grid(~Name,switch = "x")+
                labs(y = "log p-value")+
                labs(x = "")+
                theme(
                  axis.ticks.y=element_blank(),
                  axis.ticks.x=element_blank(),
                  axis.text.x=element_blank())+
                coord_cartesian(expand = 0)+
                scale_color_manual("Admixture duration",
                                   values = cbPalette_viridis[1:7],
                                   labels = c(1,200,400,800,1000,1500,2000))



SP_EP_stats_comparison <- ggarrange(P_AIC,P_F_Test,labels = c("A","B"),
          ncol = 2, nrow = 2,common.legend = T,legend = 'top')

SP_EP_stats_comparison
```
## Using segments directly

Here, we use msprime simulations and use the segments directly. The simulations were modeled after Skov. et al. 2018 with minor changes (only non-Africans were modeled). We used the true segments from 100 haploid non-Africans obtained from msprime and also inferred the segments using the HMM from Skov et al. 2018. We used a posterior cutoff for calling introgressed segments of 0.9. We only considered segments between 0.05 and 1.2 cM. We used the deCODE MAp to simulate a variyng recombination rate. 

```{r eval=F,message=FALSE, echo=FALSE,warning=FALSE}
source("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Fit_models.R")

Fit_all_true_segments <- function(file_pattern_constant,file_pattern_varying,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,td,n_rep,apply_cutoff=F){
  Path_to_Fragment_Files_True_Constant=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Segment_ALD_comparison/",pattern = file_pattern_constant,full.names = T)
  True_segments_constant_l <- lapply(Path_to_Fragment_Files_True_Constant, Fit_to_segments,header=F,recomb_rate=1.2e-8,n_Haploid=100,truncation=F)
  
  Path_to_Fragment_Files_True_varying=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Segment_ALD_comparison_recombination_map/",pattern = file_pattern_varying,full.names = T)
  if(apply_cutoff==T){
    print("Cutoff is applied")
    #no correction
    True_segments_varying_no_correction_l <- lapply(Path_to_Fragment_Files_True_varying, Fit_to_segments,header=F,recomb_rate=mean_HapMap_rr,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
    #AAMap correction
    True_segments_varying_AAMap_correction_l <- lapply(Path_to_Fragment_Files_True_varying, Fit_to_segments,header=F,Path_to_Recomb_Map=AAMap_Map_path,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
  } else{
        #no correction
    True_segments_varying_no_correction_l <- lapply(Path_to_Fragment_Files_True_varying, Fit_to_segments,header=F,recomb_rate=mean_HapMap_rr,n_Haploid=100,truncation=F)
    #AAMap correction
    True_segments_varying_AAMap_correction_l <- lapply(Path_to_Fragment_Files_True_varying, Fit_to_segments,header=F,Path_to_Recomb_Map=AAMap_Map_path,n_Haploid=100,truncation=F)
    
  }

  #HapMap correction
  True_segments_varying_HapMap_correction_l <- lapply(Path_to_Fragment_Files_True_varying, Fit_to_segments,header=F,Path_to_Recomb_Map=HapMap_Map_path,n_Haploid=100,truncation=F)
  
  True_segments_constant=get_seg_result_table(True_segments_constant_l,td,"constant",n_rep)
  True_segments_varying_no_correction=get_seg_result_table(True_segments_varying_no_correction_l,td,"varying no correction",n_rep)
  True_segments_varying_AAMap_correction=get_seg_result_table(True_segments_varying_AAMap_correction_l,td,"varying AAMap correction",n_rep)
  True_segments_varying_HapMap_correction=get_seg_result_table(True_segments_varying_HapMap_correction_l,td,"varying HapMap correction",n_rep)
  True_segs=rbind(True_segments_constant,True_segments_varying_no_correction,True_segments_varying_AAMap_correction,True_segments_varying_HapMap_correction)
  return(True_segs)
}

Fit_all_inferred_segments <- function(file_pattern_constant,file_pattern_varying,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,td,n_rep){
  Path_to_Fragment_Files_Inferred_Constant=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Segment_ALD_comparison/",pattern = file_pattern_constant,full.names = T)
  Inferred_segments_constant_l <- lapply(Path_to_Fragment_Files_Inferred_Constant, Fit_to_segments,header=T,recomb_rate=1.2e-8,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
  
  Path_to_Fragment_Files_Inferred_varying=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Segment_ALD_comparison_recombination_map/",pattern = file_pattern_varying,full.names = T)
  #no correction
  Inferred_segments_varying_no_correction_l <- lapply(Path_to_Fragment_Files_Inferred_varying, Fit_to_segments,header=T,recomb_rate=mean_HapMap_rr,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
  #AAMap correction
  Inferred_segments_varying_AAMap_correction_l <- lapply(Path_to_Fragment_Files_Inferred_varying, Fit_to_segments,header=T,Path_to_Recomb_Map=AAMap_Map_path,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
  #HapMap correction
  Inferred_segments_varying_HapMap_correction_l <- lapply(Path_to_Fragment_Files_Inferred_varying, Fit_to_segments,header=T,Path_to_Recomb_Map=HapMap_Map_path,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
  
  Inferred_segments_constant=get_seg_result_table(Inferred_segments_constant_l,td,"constant",n_rep)
  Inferred_segments_varying_no_correction=get_seg_result_table(Inferred_segments_varying_no_correction_l,td,"varying no correction",n_rep)
  Inferred_segments_varying_AAMap_correction=get_seg_result_table(Inferred_segments_varying_AAMap_correction_l,td,"varying AAMap correction",n_rep)
  Inferred_segments_varying_HapMap_correction=get_seg_result_table(Inferred_segments_varying_HapMap_correction_l,td,"varying HapMap correction",n_rep)
  Inferred_segs=rbind(Inferred_segments_constant,Inferred_segments_varying_no_correction,Inferred_segments_varying_AAMap_correction,Inferred_segments_varying_HapMap_correction)
  return(Inferred_segs)
}

get_seg_result_table <- function(res.list,GF_length,descrip,n_rep){
  Seg_result.table <- c()
  for(i in 1:n_rep){
      xx <- c(res.list[[i]][[1]][[2]]$t_m,
                       res.list[[i]][[2]][[2]]$tm,
                       res.list[[i]][[2]][[2]]$k,
                       res.list[[i]][[2]][[2]]$lower_trunc,
                       res.list[[i]][[2]][[2]]$upper_trunc,
                       res.list[[i]][[3]])
      Seg_result.table=rbind(Seg_result.table,xx)
  }
  Seg_result.table <- as.data.frame(Seg_result.table)
  Seg_result.table$GF_length <- GF_length
  Seg_result.table$descr <- descrip
  return(Seg_result.table)
}



## Variation in recombinations (HapMap) ##
AAMap_Map_path="/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Paper_Scripts/Simulations/Recombination_Maps/Scaled_Genetic_AAMap.txt"
HapMap_Map_path="/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Paper_Scripts/Simulations/Recombination_Maps/Scaled_HapMap.txt"
AAMap_Map=read.table(AAMap_Map_path,stringsAsFactors = F,header=T,fill = T)
HapMap_Map=read.table(HapMap_Map_path,stringsAsFactors = F,header=T,fill = T)
mean_AAMap_rr=(tail(AAMap_Map$Map.cM.,n=1)/tail(AAMap_Map$Position.bp.,n=1))/100
mean_HapMap_rr=(tail(HapMap_Map$Genetic_Map.cM.,n=1)/tail(HapMap_Map$position,n=1))/100

## Fitting True segments w/o cutoff for AAMap and constant 

True_seg_td_1 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_1_", "ALL_Simulation-merged-_Scenario_1_Recomb_",mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,1,25)
True_seg_td_200 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_2_","ALL_Simulation-merged-_Scenario_2_Recomb_"
                                         ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,200,25)
True_seg_td_400 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_3_","ALL_Simulation-merged-_Scenario_3_Recomb_"
                                         ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,400,25)
True_seg_td_800 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_4_","ALL_Simulation-merged-_Scenario_4_Recomb_"
                                         ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,800,25)
True_seg_td_1000 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_5_","ALL_Simulation-merged-_Scenario_5_Recomb_"
                                          ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,1000,25)
True_seg_td_1500 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_6_","ALL_Simulation-merged-_Scenario_6_Recomb_"
                                          ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,1500,25)
True_seg_td_2000 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_7_","ALL_Simulation-merged-_Scenario_7_Recomb_"
                                          ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,2000,25)

#save(True_seg_td_1,True_seg_td_200,True_seg_td_400,True_seg_td_800,True_seg_td_1000,True_seg_td_1500,True_seg_td_2000,file = "True_Segment_fit.RData")
save(True_seg_td_1,True_seg_td_200,True_seg_td_400,True_seg_td_800,True_seg_td_1000,True_seg_td_1500,True_seg_td_2000,file = "True_Segment_fit_linear.RData")

## Fitting True segments with cutoff for AAMap and constant 

True_seg_td_1 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_1_", "ALL_Simulation-merged-_Scenario_1_Recomb_",mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,1,25,apply_cutoff=T)
True_seg_td_200 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_2_","ALL_Simulation-merged-_Scenario_2_Recomb_"
                                         ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,200,25,apply_cutoff=T)
True_seg_td_400 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_3_","ALL_Simulation-merged-_Scenario_3_Recomb_"
                                         ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,400,25,apply_cutoff = T)
True_seg_td_800 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_4_","ALL_Simulation-merged-_Scenario_4_Recomb_"
                                         ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,800,25,apply_cutoff = T)
True_seg_td_1000 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_5_","ALL_Simulation-merged-_Scenario_5_Recomb_"
                                          ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,1000,25,apply_cutoff = T)
True_seg_td_1500 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_6_","ALL_Simulation-merged-_Scenario_6_Recomb_"
                                          ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,1500,25,apply_cutoff = T)
True_seg_td_2000 <- Fit_all_true_segments("ALL_Simulation-merged-_Scenario_7_","ALL_Simulation-merged-_Scenario_7_Recomb_"
                                          ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,2000,25,apply_cutoff = T)

save(True_seg_td_1,True_seg_td_200,True_seg_td_400,True_seg_td_800,True_seg_td_1000,True_seg_td_1500,True_seg_td_2000,file = "True_Segment_fit_linear_with_AAMap_constant_cutoff.RData")


Inferred_seg_td_1 <- Fit_all_inferred_segments("ALL_Inferred_Archaic_Tracts-_Scenario_1_","ALL_Inferred_Archaic_Tracts-_Scenario_1_Recomb_"
                                                ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,1,25)
Inferred_seg_td_200 <- Fit_all_inferred_segments("ALL_Inferred_Archaic_Tracts-_Scenario_2_","ALL_Inferred_Archaic_Tracts-_Scenario_2_Recomb_"
                                                 ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,200,25)
Inferred_seg_td_400 <- Fit_all_inferred_segments("ALL_Inferred_Archaic_Tracts-_Scenario_3_","ALL_Inferred_Archaic_Tracts-_Scenario_3_Recomb_"
                                                 ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,400,25)
Inferred_seg_td_800 <- Fit_all_inferred_segments("ALL_Inferred_Archaic_Tracts-_Scenario_4_","ALL_Inferred_Archaic_Tracts-_Scenario_4_Recomb_"
                                                 ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,800,25)
Inferred_seg_td_1000 <- Fit_all_inferred_segments("ALL_Inferred_Archaic_Tracts-_Scenario_5_","ALL_Inferred_Archaic_Tracts-_Scenario_5_Recomb_"
                                                  ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,1000,25)
Inferred_seg_td_1500 <- Fit_all_inferred_segments("ALL_Inferred_Archaic_Tracts-_Scenario_6_","ALL_Inferred_Archaic_Tracts-_Scenario_6_Recomb_"
                                                  ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,1500,25)
Inferred_seg_td_2000 <- Fit_all_inferred_segments("ALL_Inferred_Archaic_Tracts-_Scenario_7_","ALL_Inferred_Archaic_Tracts-_Scenario_7_Recomb_"
                                                 ,mean_HapMap_rr,AAMap_Map_path,HapMap_Map_path,2000,25)

#save(Inferred_seg_td_1,Inferred_seg_td_200,Inferred_seg_td_400,Inferred_seg_td_800,Inferred_seg_td_1000,Inferred_seg_td_1500,Inferred_seg_td_2000,file = "Inferred_Segment_fit.RData")

save(Inferred_seg_td_1,Inferred_seg_td_200,Inferred_seg_td_400,Inferred_seg_td_800,Inferred_seg_td_1000,Inferred_seg_td_1500,Inferred_seg_td_2000,file = "Inferred_Segment_fit_linear.RData")
```

```{r eval=F,message=FALSE, echo=FALSE,warning=FALSE}
source("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Fit_models.R")

## Perfectly known recombinations ##
# True Seg 1 gen GF constant recomb
Path_to_Fragment_Files_True_1=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Simulated_Icelandic_Fragments/",pattern = "ALL_Simulation-merged-_Scenario_1__Archaic_Segments_run_",full.names = T)
True_segments_1_gen_GF_recomb_constant <- lapply(Path_to_Fragment_Files_True_1, Fit_to_segments,header=F,recomb_rate=1e-8,n_Haploid=100,truncation=F)

# True Seg 1000 gen GF constant recomb
Path_to_Fragment_Files_True_2=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Simulated_Icelandic_Fragments/", pattern = "ALL_Simulation-merged-_Scenario_2__Archaic_Segments_run_",full.names = T)
True_segments_1000_gen_GF_recomb_constant <- lapply(Path_to_Fragment_Files_True_2, Fit_to_segments,header=F,recomb_rate=1e-8,n_Haploid=100,truncation=F)

# Inferred Seg 1 gen GF constant recomb
Path_to_Fragment_Files_Inferred_1=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Simulated_Icelandic_Fragments/",pattern = "ALL_Inferred_Archaic_Tracts-_Scenario_1_-run",full.names = T)
Inferred_segments_1_gen_GF_recomb_constant <- lapply(Path_to_Fragment_Files_Inferred_1, Fit_to_segments,header=T,recomb_rate=1e-8,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)

# Inferred Seg 1000 gen GF constant recomb
Path_to_Fragment_Files_Inferred_2=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Simulated_Icelandic_Fragments/",pattern = "ALL_Inferred_Archaic_Tracts-_Scenario_2_-run",full.names = T)
Inferred_segments_1000_gen_GF_recomb_constant <- lapply(Path_to_Fragment_Files_Inferred_2, Fit_to_segments,header=T,recomb_rate=1e-8,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)

## Variation in recombinations (deCODE MAP) ##
deCODE_Map_path="/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Paper_Scripts/Simulations/Recombination_Maps/Scaled_Decode_Map.txt"
AAMap_Map_path="/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Paper_Scripts/Simulations/Recombination_Maps/Scaled_Genetic_AAMap.txt"
HapMap_Map_path="/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Paper_Scripts/Simulations/Recombination_Maps/Scaled_HapMap.txt"
deCODE_Map_x=read.table(deCODE_Map_path,stringsAsFactors = F,header=T,fill = T)
AAMap_Map=read.table(AAMap_Map_path,stringsAsFactors = F,header=T,fill = T)
HapMap_Map=read.table(HapMap_Map_path,stringsAsFactors = F,header=T,fill = T)
mean_deCODE_rr=(tail(deCODE_Map_x$Genetic_Map.cM.,n=1)/tail(deCODE_Map_x$position,n=1))/100
mean_AAMap_rr=(tail(AAMap_Map$Map.cM.,n=1)/tail(AAMap_Map$Position.bp.,n=1))/100
mean_HapMap_rr=(tail(HapMap_Map$Genetic_Map.cM.,n=1)/tail(HapMap_Map$position,n=1))/100

# True Seg 1 gen GF varying recomb 
Path_to_Fragment_Files_True_3=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Simulated_Icelandic_Fragments_Recomb/",pattern = "ALL_Simulation-merged-_Scenario_1_Recomb__Archaic_Segments_run_",full.names = T)
#no correction
True_segments_1_gen_GF_recomb_varying_no_correction <- lapply(Path_to_Fragment_Files_True_3, Fit_to_segments,header=F,recomb_rate=mean_deCODE_rr,n_Haploid=100,truncation=F)
#AAMap correction
True_segments_1_gen_GF_recomb_varying_AAMap_correction <- lapply(Path_to_Fragment_Files_True_3, Fit_to_segments,header=F,Path_to_Recomb_Map=AAMap_Map_path,n_Haploid=100,truncation=F)
#deCODE correction
True_segments_1_gen_GF_recomb_varying_deCODE_correction <- lapply(Path_to_Fragment_Files_True_3, Fit_to_segments,header=F,Path_to_Recomb_Map=deCODE_Map_path,n_Haploid=100,truncation=F)

# True Seg 1000 gen GF varying recomb no correction
Path_to_Fragment_Files_True_4=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Simulated_Icelandic_Fragments_Recomb/",pattern = "ALL_Simulation-merged-_Scenario_2_Recomb__Archaic_Segments_run_",full.names = T)
#no correction
True_segments_1000_gen_GF_recomb_varying_no_correction <- lapply(Path_to_Fragment_Files_True_4, Fit_to_segments,header=F,recomb_rate=mean_deCODE_rr,n_Haploid=100,truncation=F)
#AAMap correction
True_segments_1000_gen_GF_recomb_varying_AAMap_correction <- lapply(Path_to_Fragment_Files_True_4, Fit_to_segments,header=F,Path_to_Recomb_Map=AAMap_Map,n_Haploid=100,truncation=F)
#deCODE correction
True_segments_1000_gen_GF_recomb_varying_deCODE_correction <- lapply(Path_to_Fragment_Files_True_4, Fit_to_segments,header=F,Path_to_Recomb_Map=deCODE_Map,n_Haploid=100,truncation=F)

# Inferred Seg 1 gen GF varying recomb 
Path_to_Fragment_Files_Inferred_3=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Simulated_Icelandic_Fragments_Recomb/",pattern = "ALL_Inferred_Archaic_Tracts-_Scenario_1_Recomb_-run",full.names = T)
#no correction
Inferred_segments_1_gen_GF_recomb_varying_no_correction <- lapply(Path_to_Fragment_Files_Inferred_3, Fit_to_segments,header=T,recomb_rate=mean_deCODE_rr,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
#AAMap correction
Inferred_segments_1_gen_GF_recomb_varying_AAMap_correction <- lapply(Path_to_Fragment_Files_Inferred_3, Fit_to_segments,header=T,Path_to_Recomb_Map=AAMap_Map,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
#deCODE correction
Inferred_segments_1_gen_GF_recomb_varying_deCODE_correction <- lapply(Path_to_Fragment_Files_Inferred_3, Fit_to_segments,header=T,Path_to_Recomb_Map=deCODE_Map,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)

# Inferred Seg 1000 gen GF varying recomb 
Path_to_Fragment_Files_Inferred_4=list.files("/home/leonardo_iasi/Desktop/Neandertal_Human_Introgression_Project/Paper/Direct_Trat_length_estimation/Simulated_Icelandic_Fragments_Recomb/",pattern = "ALL_Inferred_Archaic_Tracts-_Scenario_2_Recomb_-run",full.names = T)
#no correction
Inferred_segments_1000_gen_GF_recomb_varying_no_correction <- lapply(Path_to_Fragment_Files_Inferred_4, Fit_to_segments,header=T,recomb_rate=mean_deCODE_rr,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
#AAMap correction
Inferred_segments_1000_gen_GF_recomb_varying_AAMap_correction <- lapply(Path_to_Fragment_Files_Inferred_4, Fit_to_segments,header=T,Path_to_Recomb_Map=AAMap_Map,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)
#deCODE correction
Inferred_segments_1000_gen_GF_recomb_varying_deCODE_correction <- lapply(Path_to_Fragment_Files_Inferred_4, Fit_to_segments,header=T,Path_to_Recomb_Map=deCODE_Map,n_Haploid=100,truncation=T,lower_trunc=0.05,upper_trunc=1.2)

save(True_segments_1_gen_GF_recomb_constant,True_segments_1_gen_GF_recomb_varying_no_correction,
     True_segments_1_gen_GF_recomb_varying_AAMap_correction,True_segments_1_gen_GF_recomb_varying_deCODE_correction,
     True_segments_1000_gen_GF_recomb_constant,True_segments_1000_gen_GF_recomb_varying_no_correction,
     True_segments_1000_gen_GF_recomb_varying_AAMap_correction,True_segments_1000_gen_GF_recomb_varying_deCODE_correction,
     Inferred_segments_1_gen_GF_recomb_constant,Inferred_segments_1_gen_GF_recomb_varying_no_correction,
     Inferred_segments_1_gen_GF_recomb_varying_AAMap_correction,Inferred_segments_1_gen_GF_recomb_varying_deCODE_correction,
     Inferred_segments_1000_gen_GF_recomb_constant,Inferred_segments_1000_gen_GF_recomb_varying_no_correction,
     Inferred_segments_1000_gen_GF_recomb_varying_AAMap_correction,Inferred_segments_1000_gen_GF_recomb_varying_deCODE_correction
     , mean_deCODE_rr,file = "Segment_fit_2.RData")

load("Segment_fit_2.RData")



True_segments=rbind(get_seg_result_table(True_segments_1_gen_GF_recomb_constant,1,"constant",10),
     get_seg_result_table(True_segments_1_gen_GF_recomb_varying_no_correction,1,"varying no correction",10),
     get_seg_result_table(True_segments_1_gen_GF_recomb_varying_AAMap_correction,1,"varying AAMap correction",10),
     get_seg_result_table(True_segments_1_gen_GF_recomb_varying_deCODE_correction,1,"varying deCODE correction",10)
     #get_seg_result_table(True_segments_1000_gen_GF_recomb_constant,1000,"constant"),
     #get_seg_result_table(True_segments_1000_gen_GF_recomb_varying_no_correction,1000,"varying no correction"),
     #get_seg_result_table(True_segments_1000_gen_GF_recomb_varying_AAMap_correction,1000,"varying AAMap correction"),
     #get_seg_result_table(True_segments_1000_gen_GF_recomb_varying_deCODE_correction,1000,"varying deCODE correction")
     )
colnames(True_segments) <- c("tm_sp","tm_ep","k","upper","lower","LRT","td","recomb")
True_segments$True_tm <- 1500
True_segments$td_est <-  4*True_segments$tm_ep*(1/True_segments$k)^(-(1/2))

True_segments_ggdata_tm <- data.frame(tm_est=c(True_segments$tm_sp,True_segments$tm_ep),gf_l=c(True_segments$td,True_segments$td),rr=c(True_segments$recomb,True_segments$recomb))
True_segments_ggdata_tm$Model <- rep(c("Simple Pulse","Extended Pulse"),each=80)
True_segments_ggdata_tm$True_tm <- 1500

True_segments_ggdata_td <- data.frame(td_est=c(True_segments$td_est),gf_l=c(True_segments$td),rr=c(True_segments$recomb))
True_segments_ggdata_td$Model <- "Extended Pulse"
True_segments_ggdata_td$True_tm <- 1500

Inferred_segments=rbind(get_seg_result_table(Inferred_segments_1_gen_GF_recomb_constant,1,"constant"),
     get_seg_result_table(Inferred_segments_1_gen_GF_recomb_varying_no_correction,1,"varying no correction"),
     get_seg_result_table(Inferred_segments_1_gen_GF_recomb_varying_AAMap_correction,1,"varying AAMap correction"),
     get_seg_result_table(Inferred_segments_1_gen_GF_recomb_varying_deCODE_correction,1,"varying deCODE correction"),
     get_seg_result_table(Inferred_segments_1000_gen_GF_recomb_constant,1000,"constant"),
     get_seg_result_table(Inferred_segments_1000_gen_GF_recomb_varying_no_correction,1000,"varying no correction"),
     get_seg_result_table(Inferred_segments_1000_gen_GF_recomb_varying_AAMap_correction,1000,"varying AAMap correction"),
     get_seg_result_table(Inferred_segments_1000_gen_GF_recomb_varying_deCODE_correction,1000,"varying deCODE correction"))
colnames(Inferred_segments) <- c("tm_sp","tm_ep","k","upper","lower","LRT","td","recomb")
Inferred_segments$True_tm <- 1500
Inferred_segments$td_est <-  4*Inferred_segments$tm_ep*Inferred_segments$k^(-(1/2))

Inferred_segments_ggdata_tm <- data.frame(tm_est=c(Inferred_segments$tm_sp,Inferred_segments$tm_ep),gf_l=c(Inferred_segments$td,Inferred_segments$td),rr=c(Inferred_segments$recomb,Inferred_segments$recomb))
Inferred_segments_ggdata_tm$Model <- rep(c("Simple Pulse","Extended Pulse"),each=80)
Inferred_segments_ggdata_tm$True_tm <- 1500

Inferred_segments_ggdata_td <- data.frame(td_est=c(Inferred_segments$td_est),gf_l=c(Inferred_segments$td),rr=c(Inferred_segments$recomb))
Inferred_segments_ggdata_td$Model <- "Extended Pulse"
Inferred_segments_ggdata_td$True_tm <- 1500
```

```{r eval=T,figR2_1, message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=9,fig.height=10,fig.cap="\\label{fig:figR2_1} "}
Plot_tm <- function(ggdata,cbPalette_viridis,main){
  ggdata$Model <- factor(ggdata$Model,
                          levels = c("Simple Pulse","Extended Pulse"),ordered = TRUE)
  ggdata$rr <- factor(ggdata$rr,
                          levels = c("varying HapMap correction","varying AAMap correction","varying no correction","constant"),ordered = TRUE)
  ggplot(data = ggdata, aes(y=(rr),x=as.numeric(as.character(tm_est)),colour=(rr))) +
    geom_boxplot(show.legend = T)+ 
    facet_grid(as.factor(gf_l)+as.factor(True_tm) ~Model, switch = "y")+
    geom_vline( aes(xintercept = True_tm ))+
    geom_vline( aes(xintercept = True_tm*(1-0.03)) ,linetype="dashed", 
                color = "red")+
    ggtitle(main)+
    labs(x = "Estimated Admixture Mean Time")+
    labs(y = "Simulated Admixture Duration \n Simulated Admixture Mean")+
    theme(
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank())+
    coord_cartesian(xlim = c(500,2500), expand = 0)+
    scale_x_continuous(breaks = seq(0, 1000, by = 500))+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[7],cbPalette_viridis[5],cbPalette_viridis[3],cbPalette_viridis[1]),
                       labels = c("varying deCODE correction","varying AAMap correction","varying no correction","constant"),
                       guide = guide_legend(reverse=TRUE))
  
}


Plot_td <- function(ggdata,cbPalette_viridis,main){
    ggdata$rr <- factor(ggdata$rr,
                          levels = c("varying HapMap correction","varying AAMap correction","varying no correction","constant"),ordered = TRUE)
    ggplot(data = ggdata, aes(y=(rr),x=as.numeric(as.character(td_est)),colour=(rr))) +
    geom_boxplot(show.legend = T)+
    facet_grid(as.factor(gf_l)+as.factor(True_tm) ~Model, switch = "y")+
    geom_vline( aes(xintercept = gf_l ))+
    labs(y = "")+
    labs(x = "Estimated Admixture Duration")+
    ggtitle(main)+
    theme(
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank())+
    coord_cartesian(xlim = c(0,2500), expand = 0)+
    scale_x_continuous(breaks = seq(0, 2500, by = 500))+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[7],cbPalette_viridis[5],cbPalette_viridis[3],cbPalette_viridis[1]),
                       labels = c("varying deCODE correction","varying AAMap correction","varying no correction","constant"),
                       guide = guide_legend(reverse=TRUE))
}

Plot_LRT<- function(Data,Colour_P,main){
  Data$LRT <- ifelse(Data$LRT>=10,10,Data$LRT)
  Data$recomb <- factor(Data$recomb,
                      levels = c("constant","varying no correction","varying AAMap correction","varying HapMap correction"),ordered = TRUE)
  ggplot(Data,aes(x=(recomb),y=LRT,color=(recomb)))+
    geom_boxplot()+
    facet_grid(~td,switch = "x")+
    geom_hline( aes(yintercept = 2 ))+
    ggtitle(main)+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    ylim(c(-0.5,10))+
    labs(x = "Admixture Duration")+
    labs(y = "log Likelihood Ratio")+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[3],cbPalette_viridis[5],cbPalette_viridis[7]),
                       labels = c("constant","varying no correction","varying AAMap correction","varying deCODE correction"),
                       drop=FALSE)

}

#load("True_Segment_fit.RData")
load("True_Segment_fit_linear.RData")
True_segments=rbind(True_seg_td_1,True_seg_td_200,True_seg_td_400,True_seg_td_800,
                    True_seg_td_1000,True_seg_td_1500,True_seg_td_2000)
colnames(True_segments) <- c("tm_sp","tm_ep","k","upper","lower","LRT","td","recomb")
True_segments$True_tm <- 1500
True_segments$td_est <-  4*True_segments$tm_ep*(1/True_segments$k)^(-(1/2))
True_segments$scale <- 1/True_segments$k/True_segments$tm_ep

True_segments_ggdata_tm <- data.frame(tm_est=c(True_segments$tm_sp,True_segments$tm_ep),gf_l=c(True_segments$td,True_segments$td),rr=c(True_segments$recomb,True_segments$recomb))
True_segments_ggdata_tm$Model <- rep(c("Simple Pulse","Extended Pulse"),each=700)
True_segments_ggdata_tm$True_tm <- 1500

True_segments_ggdata_td <- data.frame(td_est=c(True_segments$td_est),gf_l=c(True_segments$td),rr=c(True_segments$recomb))
True_segments_ggdata_td$Model <- "Extended Pulse"
True_segments_ggdata_td$True_tm <- 1500

True_tm <- Plot_tm(True_segments_ggdata_tm,cbPalette_viridis,"True segments")
True_td <- Plot_td(True_segments_ggdata_td,cbPalette_viridis ,"True segments")

Direct_segments_true <- ggarrange(True_tm,True_td,labels = c("A","B"),
          ncol = 2, nrow = 1,widths = c(0.6,0.4),common.legend = T,legend = 'bottom')

#pdf("True_segments_fitted_1_over_k_fit.pdf")
Direct_segments_true
#dev.off()
#xx <- True_segments %>% filter(recomb=="constant")
#pdf("True_segments_fitted__1_over_k_fit_k.pdf")
#plot(as.factor(xx$td),xx$k)
#dev.off()



```

``` {r eval=T,figR2_1_2, message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=9,fig.height=10,fig.cap="\\label{fig:figR2_1_2} "}

True_LRT <- Plot_LRT(True_segments,cbPalette_viridis,"True segments")

True_LRT
```


```{r eval=T,figR2_1_cutoff, message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=9,fig.height=10,fig.cap="\\label{fig:figR2_1} "}
#load("True_Segment_fit.RData")
load("True_Segment_fit_linear_with_AAMap_constant_cutoff.RData")
True_segments=rbind(True_seg_td_1,True_seg_td_200,True_seg_td_400,True_seg_td_800,
                    True_seg_td_1000,True_seg_td_1500,True_seg_td_2000)
colnames(True_segments) <- c("tm_sp","tm_ep","k","upper","lower","LRT","td","recomb")
True_segments$True_tm <- 1500
True_segments$td_est <-  4*True_segments$tm_ep*(1/True_segments$k)^(-(1/2))
True_segments$scale <- 1/True_segments$k/True_segments$tm_ep

True_segments_ggdata_tm <- data.frame(tm_est=c(True_segments$tm_sp,True_segments$tm_ep),gf_l=c(True_segments$td,True_segments$td),rr=c(True_segments$recomb,True_segments$recomb))
True_segments_ggdata_tm$Model <- rep(c("Simple Pulse","Extended Pulse"),each=700)
True_segments_ggdata_tm$True_tm <- 1500

True_segments_ggdata_td <- data.frame(td_est=c(True_segments$td_est),gf_l=c(True_segments$td),rr=c(True_segments$recomb))
True_segments_ggdata_td$Model <- "Extended Pulse"
True_segments_ggdata_td$True_tm <- 1500

True_tm <- Plot_tm(True_segments_ggdata_tm,cbPalette_viridis,"True segments")
True_td <- Plot_td(True_segments_ggdata_td,cbPalette_viridis ,"True segments")

Direct_segments_true <- ggarrange(True_tm,True_td,labels = c("A","B"),
          ncol = 2, nrow = 1,widths = c(0.6,0.4),common.legend = T,legend = 'bottom')
```

``` {r eval=T,figR2_1_2_with_cutoff, message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=9,fig.height=10,fig.cap="\\label{fig:figR2_1_2} "}

True_LRT <- Plot_LRT(True_segments,cbPalette_viridis,"True segments")

True_LRT
```

```{r eval=T,figR2_2_1, message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=9,fig.height=10,fig.cap="\\label{fig:figR2_2_1} "}
#load("Inferred_Segment_fit.RData")
load("Inferred_Segment_fit_linear.RData")

Inferred_segments=rbind(Inferred_seg_td_1,Inferred_seg_td_200,Inferred_seg_td_400,
                        Inferred_seg_td_800,Inferred_seg_td_1000,Inferred_seg_td_1500,Inferred_seg_td_2000)

colnames(Inferred_segments) <- c("tm_sp","tm_ep","k","upper","lower","LRT","td","recomb")
Inferred_segments$True_tm <- 1500

Inferred_segments$td_est <-  4*Inferred_segments$tm_ep*(1/Inferred_segments$k)^(-(1/2))
Inferred_segments$scale <- 1/Inferred_segments$k/Inferred_segments$tm_ep

Inferred_segments_ggdata_tm <- data.frame(tm_est=c(Inferred_segments$tm_sp,Inferred_segments$tm_ep),gf_l=c(Inferred_segments$td,Inferred_segments$td),rr=c(Inferred_segments$recomb,Inferred_segments$recomb))
Inferred_segments_ggdata_tm$Model <- rep(c("Simple Pulse","Extended Pulse"),each=700)
Inferred_segments_ggdata_tm$True_tm <- 1500

Inferred_segments_ggdata_td <- data.frame(td_est=c(Inferred_segments$td_est),gf_l=c(Inferred_segments$td),rr=c(Inferred_segments$recomb))
Inferred_segments_ggdata_td$Model <- "Extended Pulse"
Inferred_segments_ggdata_td$True_tm <- 1500



Inferred_tm <- Plot_tm(Inferred_segments_ggdata_tm,cbPalette_viridis ,"Inferred segments")
Inferred_td <- Plot_td(Inferred_segments_ggdata_td,cbPalette_viridis ,"Inferred segments")

Direct_segments_inf <- ggarrange(Inferred_tm,Inferred_td,labels = c("A","B"),
          ncol = 2, nrow = 1,widths = c(0.6,0.4),common.legend = T,legend = 'bottom')

Direct_segments_inf



```

``` {r eval=T,figR2_2_2, message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=9,fig.height=10,fig.cap="\\label{fig:figR2_2_2} "}

Inferred_LRT <- Plot_LRT(Inferred_segments,cbPalette_viridis,"Inferred segments")

Inferred_LRT
```

# Wright-Fisher Model for msprime simulations

As described in Neslon et al. 2020 the algorithm in ms and msprime (the Hudson model), it is known that the coalescent is biased relative to the W-F-model when sample sizes are large or for events in the recent past. The Hudson algorithm results in unrealistic relatedness among samples due to having to many ancestors. This is a consequence of the recombination algorithm being designed to simulate small regions and does not account for multiple simultaneous recombinations during meiosis. This can have the effect of long-range correlations along the simulated genomes in large samples or under migration models. This correlation might then affect the dating of migration events since it influences the recombination clock. In Nelson et al. 2020 the deviation in the variance in ancestry proportion between the expected and msprim simulations under the Hudson model was observed for admixture events younger than 20 generations before sampling with 30% admixture proportion. This effect can be corrected by using a Wright-Fisher-model in the first generations of simulation and switch to the faster Hudson model afterwards. Although our smallest number of generations between end of admixture and sampling with a admixture fraction of 3% is 50  generations, we examined the effect of only using the Hudson model, as we did before, by comparing it to W-F & Hudson hybrid simulations for our scenario with the stalest number of generation between sampling and end of admixture. We run the same simulation used for Figure 4 A and B under a constant recombination rate. The W-F-model is run for 500 generations and switches to the Hudson afterwards. We replicated this 10 times and compared it to the original simulations only using the Hudson algorithm (100 replicates).

```{r eval=F,message=FALSE, echo=FALSE,warning=FALSE}
#### New Figure for Paper using recent sampling (50 gen): constant RR, RM no correction, RM diff RM correction, RM correction same RM ####

Filter_Result_Table <- function(Result.Table){
  Result.Table=read.table(Result.Table,header=F,sep = " ")
  Result.names <- c('A.exp', 's.exp', 'c.exp', 'RSS_Expo','AIC_Expo', 'A.lomax', 's.lomax', 'w.lomax','c.lomax', 'RSS_Lomax','AIC_Lomax', 'F_Test','Scenario.name','GF.Start','GF.End','AS','minDist','GF.Model')
  colnames(Result.Table) <- Result.names
  #Result.Table <- Result.Table[(1/Result.Table$s.exp)>0,]
  #Result.Table <- Result.Table[(1/Result.Table$s.exp)<5000,]
  #Result.Table <- Result.Table[Result.Table$RSS_Lomax<1e-2,]
  return(Result.Table)
}

#### True values
True_params <- function(Result.Table){
  True_params_Calc <- function(True_GF_length,True_mean_GF){
    EX= True_mean_GF
    GF_Len <-True_GF_length
    VarX= ((GF_Len)/4)**2
    b= EX/VarX
    a=EX*b
    a=a
    True_W=1/a
    True_S=b/(1/True_W)
    xx=c(True_W,True_S)
    return(xx)
  }
  True.params <- c()
  for (i in 1:length(Result.Table$F_Test)) {
    xx=True_params_Calc(Result.Table$True_GF_length[i],Result.Table$True_mean_GF[i])
    True.params <- rbind(True.params,xx)
  }
  True.params <- as.data.frame(True.params)
  return(True.params)
}

Result.Table.fn <- function(Result.Table.path,Sampling.time.from.GF.End,name){
  Result.Table <- Filter_Result_Table(Result.Table.path)
  Result.Table$Name <- name
  Result.Table$Sample_Time <- Sampling.time.from.GF.End
  Result.Table$True_GF_length <- Result.Table$GF.End-Result.Table$GF.Start
  Result.Table$True_mean_GF <- ((Result.Table$GF.End+Result.Table$GF.Start)/2)-(Result.Table$GF.Start-Result.Table$Sample_Time)
  Result.Table$mean_GF_exp <- 1/Result.Table$s.exp
  Result.Table$mean_GF_lomax_s <- 1/Result.Table$s.lomax
  Result.Table.comparison <- True_params(Result.Table)
  Result.Table$True_W <- Result.Table.comparison$V1
  Result.Table$True_S <- Result.Table.comparison$V2
  #Result.Table.comparison$length_GF <- (sqrt(Result.Table$mean_GF_lomax_s/(((1/Result.Table$w.lomax))*Result.Table$s.lomax)))*4
  Result.Table.comparison$length_GF <- sqrt((1/Result.Table$s.lomax)^2*Result.Table$w.lomax)*4
  Result.Table$length_GF <- Result.Table.comparison$length_GF
  
  return(Result.Table)
}

Plot_all_together_samples_50_gen_flipped <- function(ggdata,cbPalette_viridis){
  ggdata$Model <- factor(ggdata$Model,
                          levels = c("Simple Pulse","Extended Pulse"),ordered = TRUE)
  ggdata$Name <- factor(ggdata$Name,
                        levels = c("Hudson_only_sim","Hybrid_sim"),ordered = TRUE)
  ggplot(data = ggdata, aes(y=factor(Name),x=as.numeric(as.character(value)),colour=factor(Name))) +
    geom_boxplot(show.legend = T)+ 
    #facet_grid(as.factor(True_GF_length)+as.factor(True_mean_GF) ~Model, switch = "y")+
    facet_grid(as.factor(Sample_Time)+as.factor(True_GF_length)+as.factor(True_mean_GF) ~Model, switch = "y")+
    geom_vline( aes(xintercept = True_mean_GF ))+
    labs(x = "Estimated Admixture Mean Time")+
    #labs(y = "Simulated Admixture Duration \n Simulated Admixture Mean")+
    labs(y = "Sampling Time \n Simulated Admixture Duration \n Simulated Admixture Mean")+
    theme(
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank())+
    coord_cartesian(xlim = c(0,1000), expand = 0)+
    scale_x_continuous(breaks = seq(0, 1000, by = 500))+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[6]),
                       labels = c("Hudson only ","500 gen W-F then Hudson"),
                       guide = guide_legend(reverse=TRUE))
  
}


Plot_sampling_50_gen_GF_Length_flipped <- function(ggdata,cbPalette_viridis){
  ggdata$Name <- factor(ggdata$Name,
                        levels = c("Hudson_only_sim","Hybrid_sim"),ordered = TRUE)
  ggplot(ggdata,aes(y=variable,x=as.numeric(as.character(value)),colour=factor(Name)))+
    geom_boxplot(show.legend = F)+
    #facet_grid(as.factor(True_GF_length)+as.factor(True_mean_GF) ~ Model, switch = "y")+
    facet_grid(as.factor(Sample_Time)+as.factor(True_GF_length)+as.factor(True_mean_GF) ~Model, switch = "y")+
    geom_vline( aes(xintercept = True_GF_length ))+
    #ggtitle(Ptitle) +
    labs(y = "")+
    labs(x = "Estimated Admixture Duration")+
    theme(
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank())+
    coord_cartesian(xlim = c(0,2500), expand = 0)+
    scale_x_continuous(breaks = seq(0, 2500, by = 500))+
    scale_color_manual("Simulations",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[6]),
                       labels = c("Hudson only ","500 gen W-F then Hudson"),
                       guide = guide_legend(reverse=TRUE))
}




Result.Table.path_Recent_50 <-'../Close_to_GF_End_Recent_GF_corrected/Result_both_Fit///Result_file_SIM_Raw_ALDER-Fit-Close_to_GF_End_Recent_GF_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-No_correction.txt'

Result.Table.path_Recent_50_WF <-'../Close_to_GF_End_Recent_GF_corrected_WF/Result_both_Fit_classic_Lomax/Result_file_SIM_Raw_ALDER-Fit-Close_to_GF_End_Recent_GF_corrected_WF-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0-No_correction.txt'


Plot.data_50<-rbind(
  Recent_50_constant<- Result.Table.fn(Result.Table.path_Recent_50,50,'Hudson_only_sim'),
  Recent_50_WF<- Result.Table.fn(Result.Table.path_Recent_50_WF,50,'Hybrid_sim')
)

ggdata_t.GF_50_mean_GF_exp <- melt(Plot.data_50,measure.vars =  c('mean_GF_exp'),id.vars = c('True_mean_GF','True_GF_length','Name'))
ggdata_t.GF_50_mean_GF_lomax <- melt(Plot.data_50,measure.vars =  c('mean_GF_lomax_s'),id.vars = c('True_mean_GF','True_GF_length','Name'))
ggdata_l.GF_50 <- melt(Plot.data_50,measure.vars =  c('length_GF'),id.vars = c('True_mean_GF','True_GF_length','Name'))

ggdata_reodering_fn <- function(ggdata){
  ggdata$Name <- factor(ggdata$Name,
    levels = c("Hudson_only_sim","Hybrid_sim"),ordered = TRUE)
  return(ggdata)
}
```



``` {r eval=F,figR3, message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=9,fig.height=10,fig.cap="\\label{fig:figR3} Comparison between the Hudson only and hybrid Wright-Fischer/Hudson simulations for parameter inference under the simple and extended pulse model  A) Mean time estimates $t_m$ for different gene flow durations $t_d$ all sampled 50 generations after the gene flow ended. B) Duration estimate $t_d$ of the same scenario"}

# Plot 50 gen from Admixture
ggdata_t.GF_50_mean_GF_exp$Model <- "Simple Pulse"
ggdata_t.GF_50_mean_GF_lomax$Model <- "Extended Pulse"
ggdata_all_together_samples_50_t_m <- rbind(ggdata_reodering_fn(ggdata_t.GF_50_mean_GF_exp),ggdata_reodering_fn(ggdata_t.GF_50_mean_GF_lomax))
ggdata_all_together_samples_50_t_m$Sample_Time <- 50
ggdata_sampling_50_gen_GF_Length <- ggdata_reodering_fn(ggdata_l.GF_50)
ggdata_sampling_50_gen_GF_Length$Model <- "Extended Pulse"
ggdata_sampling_50_gen_GF_Length$Sample_Time <- 50

Mean_GF_F_50 <- Plot_all_together_samples_50_gen_flipped(ggdata_all_together_samples_50_t_m,cbPalette_viridis)
Duration_GF_F_50 <- Plot_sampling_50_gen_GF_Length_flipped(ggdata_sampling_50_gen_GF_Length,cbPalette_viridis)
Constant_sampling_time <- ggarrange(Mean_GF_F_50,Duration_GF_F_50,labels = c("A","B"),
          ncol = 2, nrow = 1,widths = c(0.6,0.4),common.legend = T,legend = 'bottom')

Constant_sampling_time

```



# Comparing effect sizes for technical covariates now including downsampling

We included downsampling of the data to test the stability of the ALD estimates. We donwnsampled the data to 5 % of the original amount by randomly deleting SNPs and re-estimating all mean times on downsampled data for all scenarios. We checkd for the total effect of downsampling and the interaction of downsampling and ascertainment scheme.
```{r eval=T, message=FALSE, echo=FALSE,warning=FALSE, cache=T, results='hide'}

##### GLM for the bais on the admixture dates #####

library(rethinking)
library(rstan)
### Read in data ###
Read_GLM_indata <- function(path){
  file_l=list.files(path = path,full.names = T)
  #Result.names <- c('A.exp', 's.exp', 'c.exp', 'RSS_Expo','AIC_Expo', 'A.lomax', 's.lomax', 'w.lomax','c.lomax', 'RSS_Lomax','AIC_Lomax', 'F_Test','Scenario.name','GF.Start','GF.End','AS','minDist','downsampling')
  Result.names <- c('A.exp', 'm.exp', 'c.exp', 'RSS_Expo','status','Scenario.name','GF.Start','GF.End','AS','minDist','downsampling')
  Result.Table=do.call(rbind, lapply(file_l, function(x) read.table(x,header=F,sep = " ",col.names = Result.names)))
  return(Result.Table)
}


Fig_2_1 <- Read_GLM_indata("/mnt/diversity/leonardo_iasi/Adm_Time_Dating_Sim/Paper_Revisions/Fig_2_A_revision/Result_classic_Exp/")
Fig_2_1$Demography <- "0_Simple"
Fig_2_1$Recomb.rate <- "0_constant"
Fig_2_1$GF_model <- ifelse(Fig_2_1$Scenario.name=="_Scenario_16_","EP","SP")

Fig_2_2 <- Read_GLM_indata("/mnt/diversity/leonardo_iasi/Adm_Time_Dating_Sim/Paper_Revisions/Fig_2_B_complex_revision/Result_classic_Exp/")
Fig_2_2$Demography <- "0_Complex"
Fig_2_2$Recomb.rate <- "0_constant"
Fig_2_2$GF_model <- ifelse(Fig_2_2$Scenario.name=="_Complex_Demographies_Scenario_3_","EP","SP")

Fig_2_3 <- Read_GLM_indata("/mnt/diversity/leonardo_iasi/Adm_Time_Dating_Sim/Paper_Revisions/Fig_2_C_corrected_revision_new/Result_Exp/")
Fig_2_3$Demography <- "0_Simple"
Fig_2_3$Recomb.rate <- "0_varying"
Fig_2_3$GF_model <- ifelse(Fig_2_3$Scenario.name=="_Recombination_Map_Scenario_3_","EP","SP")

Fig_2_4 <- Read_GLM_indata(path = "/mnt/diversity/leonardo_iasi/Adm_Time_Dating_Sim/Paper_Revisions/Fig_2_D_Complex_corrected_revision_new/Result_Exp/")
Fig_2_4$Demography <- "0_Complex"
Fig_2_4$Recomb.rate <- "0_varying"
Fig_2_4$GF_model <- ifelse(Fig_2_4$Scenario.name=="_Recombination_Map_and_Complex_Demographies_Scenario_3_","EP","SP")

######## model with response being the difference between the estimated Admixture time and the true one #####
# full model with Ascertainement, min dist, Demographi and recombination rate as predictore but no interactions
xdata.M.3 <- rbind(Fig_2_1,Fig_2_2,Fig_2_3,Fig_2_4)
xdata.M.3$downsampling <- as.factor(xdata.M.3$downsampling)
xdata.M.3.no_error <- xdata.M.3 %>% filter(status=='no_error')

#xdata.M.3.no_error <- xdata.M.3 %>% filter(status=='no_error') %>% 
# filter(downsampling!=10) %>% filter(downsampling!=1)


xdata.M.3.no_error <- xdata.M.3 %>% filter(status=='no_error') %>% 
 filter(downsampling==100 | downsampling==5)

xdata.M.3.all <- xdata.M.3  %>% 
 filter(downsampling==100 | downsampling==5)

xdata.M.3.no_error$True_tm <- (xdata.M.3.no_error$GF.End-xdata.M.3.no_error$GF.Start)/2 + xdata.M.3.no_error$GF.Start
xdata.M.3.no_error$Diff <- xdata.M.3.no_error$m.exp - xdata.M.3.no_error$True_tm
xdata.M.3.no_error$Diff_s <- (xdata.M.3.no_error$m.exp - 1500)/sd(xdata.M.3.no_error$m.exp)
xdata.M.3.no_error$Sim_id_int <- as.integer(rownames(xdata.M.3.no_error))

Bdata_index<- list(
  N = length(xdata.M.3.no_error$Diff_s),
  E = xdata.M.3.no_error$Diff_s,
  A = ifelse(xdata.M.3.no_error$AS=="I",0,1),
  MD = ifelse(xdata.M.3.no_error$minDist==0.05,0,1),
  D = ifelse(xdata.M.3.no_error$Demography=="0_Simple",0,1),
  R = ifelse(xdata.M.3.no_error$Recomb.rate=="0_constant",0,1),
  GF = ifelse(xdata.M.3.no_error$GF_model=="SP",0,1),
  DS = ifelse(xdata.M.3.no_error$downsampling==100,0,1)
  
)


Effect_size_fixed_stan_1 <- ulam(
  alist(
    E ~ dnorm(mu,sigma),
    mu <- a + bA*A + bm*MD + bD*D + bR*R + bG*GF + bd*DS,
    a ~ dnorm( 0 , 2 ),
    c(bA,bm,bD,bR,bG,bd) ~ dnorm( 0 , 2 ),
    sigma ~ dexp(1)), data=Bdata_index,chains = 4,iter = 2000,cores = 4)

Effect_size_fixed_stan_2 <- ulam(
  alist(
    E ~ dnorm(mu,sigma),
    mu <- a + bA*A + bm*MD + bD*D + bR*R + bG*GF + bd*DS + bdA*A*DS,
    a ~ dnorm( 0 , 2 ),
    c(bA,bm,bD,bR,bG,bd,bdA) ~ dnorm( 0 , 2 ),
    sigma ~ dexp(1)), data=Bdata_index,chains = 4,iter = 2000,cores = 4)

```


```{r fig4_1,message=FALSE, echo=FALSE,warning=FALSE,fig3.pos="H",fig.width=4,fig.height=4,fig.cap="\\label{fig:fig4_1} GLM effect size estimates and 95% C.I. for the parameters: admixture model (simple/extended), recombination rate (constant/varying), demography (simple/complex), minimal genetic distance (0.02/0.05 cM) and ascertainment scheme (LES/HES), on the standardized difference between simulated and estimated admixture time. Estimates are calculated across all possible combinations of parameters and are given as the estimate of the standard model plus the respective parameter estimate. Dotted horizontal line indicates unbiased admixture estimates."}
B_model_result1 <- precis(Effect_size_fixed_stan_1,prob = 0.95)

post_effect_size_model <- extract.samples(Effect_size_fixed_stan_1,n = 1e5)
Post_effect_size_est=data.frame(mean=c(
mean(post_effect_size_model$a),
mean(post_effect_size_model$a + post_effect_size_model$bG),
mean(post_effect_size_model$a + post_effect_size_model$bR),
mean(post_effect_size_model$a + post_effect_size_model$bD),
mean(post_effect_size_model$a + post_effect_size_model$bm),
mean(post_effect_size_model$a + post_effect_size_model$bA),
mean(post_effect_size_model$a + post_effect_size_model$bd)),
HPDI_lower=c(
HPDI(post_effect_size_model$a,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bG,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bR,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bD,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bm,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bA,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bd,0.95)[1]),
HPDI_upper=c(
HPDI(post_effect_size_model$a,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bG,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bR,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bD,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bm,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bA,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bd,0.95)[2])
#,row.names = c("Standart Model","Continuous GF","Varying recombination","Complex Demography","d0 = 0.02","HES")
)

Post_effect_size_est_table <- Post_effect_size_est
row.names(Post_effect_size_est_table) <- c("Standart Model","Continuous GF","Varying recombination","Complex Demography","d0 = 0.02","HES","downsampled")

ggplot(Post_effect_size_est,aes(x=row.names(Post_effect_size_est),y=as.numeric(as.character(mean))))+
      geom_point(aes(size=1.5,col=c(cbPalette_viridis[1],cbPalette_viridis[6],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1])),show.legend = F,size=2)+
    geom_errorbar(aes(ymin=HPDI_lower,ymax=HPDI_upper,pos=as.numeric(row.names(Post_effect_size_est))),col="black",width=0.2)+
  geom_hline(yintercept = 0,linetype=2,aes(colour='grey'))+
  labs(x = "")+
  labs(y = "Standardized dif. est./sim. time")+
  theme(plot.title = element_text(hjust = 0.5,size = 12))+
  #scale_x_discrete(labels= c("Int","G","R","D","d0","A"))+
  scale_x_discrete(labels= c("Standard Model","Extended GF","Variying recombination","Complex Demography","d0=0.02 cM","HES","downsampled")
                  ,guide = guide_axis(angle = 90))+
  scale_color_manual("Gene Flow Model",
                     values = c(cbPalette_viridis[6],cbPalette_viridis[1]),
                     label=c("Pulse","Continuous"))

```

```{r fig4_2,message=FALSE, echo=FALSE,warning=FALSE,fig3.1.pos="H",fig.width=4,fig.height=4,fig.cap="\\label{fig:fig4_2} GLM effect size estimates and 95% C.I. for the parameters: admixture model (simple/extended), recombination rate (constant/varying), demography (simple/complex), minimal genetic distance (0.02/0.05 cM) and ascertainment scheme (LES/HES), on the standardized difference between simulated and estimated admixture time. Estimates are calculated across all possible combinations of parameters and are given as the estimate of the standard model plus the respective parameter estimate. Dotted horizontal line indicates unbiased admixture estimates."}
B_model_result2 <- precis(Effect_size_fixed_stan_2,prob = 0.95)

post_effect_size_model <- extract.samples(Effect_size_fixed_stan_2,n = 1e5)
Post_effect_size_est=data.frame(mean=c(
mean(post_effect_size_model$a),
mean(post_effect_size_model$a + post_effect_size_model$bG),
mean(post_effect_size_model$a + post_effect_size_model$bR),
mean(post_effect_size_model$a + post_effect_size_model$bD),
mean(post_effect_size_model$a + post_effect_size_model$bm),
mean(post_effect_size_model$a + post_effect_size_model$bA),
mean(post_effect_size_model$a + post_effect_size_model$bd),
mean(post_effect_size_model$a + post_effect_size_model$bdA)),
HPDI_lower=c(
HPDI(post_effect_size_model$a,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bG,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bR,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bD,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bm,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bA,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bd,0.95)[1],
HPDI(post_effect_size_model$a + post_effect_size_model$bdA,0.95)[1]),
HPDI_upper=c(
HPDI(post_effect_size_model$a,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bG,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bR,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bD,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bm,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bA,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bd,0.95)[2],
HPDI(post_effect_size_model$a + post_effect_size_model$bdA,0.95)[2])
#,row.names = c("Standart Model","Continuous GF","Varying recombination","Complex Demography","d0 = 0.02","HES")
)

Post_effect_size_est_table <- Post_effect_size_est
row.names(Post_effect_size_est_table) <- c("Standart Model","Continuous GF","Varying recombination","Complex Demography","d0 = 0.02","HES","downsampled","interaction ds/HES")

ggplot(Post_effect_size_est,aes(x=row.names(Post_effect_size_est),y=as.numeric(as.character(mean))))+
      geom_point(aes(size=1.5,col=c(cbPalette_viridis[1],cbPalette_viridis[6],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1],cbPalette_viridis[1])),show.legend = F,size=2)+
    geom_errorbar(aes(ymin=HPDI_lower,ymax=HPDI_upper,pos=as.numeric(row.names(Post_effect_size_est))),col="black",width=0.2)+
  geom_hline(yintercept = 0,linetype=2,aes(colour='grey'))+
  labs(x = "")+
  labs(y = "Standardized dif. est./sim. time")+
  theme(plot.title = element_text(hjust = 0.5,size = 12))+
  #scale_x_discrete(labels= c("Int","G","R","D","d0","A"))+
  scale_x_discrete(labels= c("Standard Model","Extended GF","Variying recombination","Complex Demography","d0=0.02 cM","HES","downsampled","interaction ds/HES")
                  ,guide = guide_axis(angle = 90))+
  scale_color_manual("Gene Flow Model",
                     values = c(cbPalette_viridis[6],cbPalette_viridis[1]),
                     label=c("Pulse","Continuous"))

```

# Minor changes

```{r message=FALSE, echo=FALSE,warning=FALSE}

# New Data
Figure_1_A_Data <- Results_Table("Simulations/Fig_1_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_1_A_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0.txt")
Figure_1_A_Data <- Figure_1_A_Data[Figure_1_A_Data$error=="no_error",]
Figure_1_B_Data <- Results_Table("Simulations/Fig_1_Results_corrected/Result_file_SIM_Raw_ALDER-Fit-Fig_1_B_corrected-GF_Model_IV-min_dist_Fit-0.05-ascertainment-0.txt")


Fig_A_1 <- Get_Data_Table(Figure_1_A_Data)
Fig_A_1$Var1 <- as.numeric(as.character(Fig_A_1$Var1))
Fig_A_1$Var3 <- round(as.numeric(as.character(Fig_A_1$Var3)))
Fig_A_1$k = 1/((as.numeric(as.character(Fig_A_1$Var6))/(4*Fig_A_1$Var3))^2)
Fig_A_1$EP_tm <- (Fig_A_1$k-1)/Fig_A_1$k*Fig_A_1$Var3

Fig_A_1_Means <- aggregate(Fig_A_1[,c(1,3)],list(Fig_A_1$Var2), mean)
Fig_A_1_Means_diff <- data.frame(sqrt((Fig_A_1_Means$Var1-Fig_A_1_Means$Var3)^2)/Fig_A_1_Means$Var3)
Fig_A_1_Means_diff_pulse <- round(range(Fig_A_1_Means_diff[1:5,]*100))
Fig_A_1_Means_diff_continuous <- round(range(Fig_A_1_Means_diff[6:10,]*100))

Fig_B_1 <- Get_Data_Table(Figure_1_B_Data)
Fig_B_1$Var7 <- rep('xx',length(Fig_B_1$Var1))
Fig_B_1_Means <- data.frame(est=rep(as.numeric(as.character(Fig_B_1$Var1)),Fig_B_1$Freq),
                               duration=rep(as.numeric(as.character(Fig_B_1$Var6)),Fig_B_1$Freq))
Fig_B_1$k = 1/((as.numeric(as.character(Fig_B_1$Var6))/(4*as.numeric(as.character(Fig_B_1$Var5))))^2)
Fig_B_1$EP_tm <- (Fig_B_1$k-1)/Fig_B_1$k*as.numeric(as.character(Fig_B_1$Var5))
Fig_1_B_Means_per_duration <- Fig_B_1_Means %>%
    group_by(duration) %>% 
    summarise_each(funs(mean))

Fig_1_B_Means_per_duration$relative_dif <- abs(1-(1500/Fig_1_B_Means_per_duration$est))

```

```{r fig2,message=FALSE, echo=FALSE,warning=FALSE,fig2.pos="H",fig.width=9,fig.height=9,fig.cap="\\label{fig:fig2} A) Comparison of mean admixture time estimates between simple and extended pulse gene flow for different admixture times. The duration of continuous gene flow $t_d$ corresponds to 50% of the mean admixture time $t_m$, black line indicates true mean admixture time. B) Comparison of mean admixture time estimates for simulations with a mean time of admixture of 1500 generations ago, at a varying durations of gene flow. Boxplot created from 100 simulation replicates, respectively."}

######################## GG PLotting ###########################
## ggplot Figure 1 A
Plot_Fig_1_A <- function(Data,Colour_P){
  Px <-  ggplot(Data,aes(x=Var4,y=as.numeric(as.character(Var1)),colour=factor(Var4)))+
    geom_point(aes(size = Freq),show.legend = F)+
    geom_boxplot()+
    facet_grid(~as.factor(Var3),switch = "x")+
    geom_hline( aes(yintercept = as.numeric(as.character(Data$Var3)) ))+
    geom_hline( aes(yintercept = Data$EP_tm) ,linetype="dashed", 
                color = "red")+
    labs(x = "True Mean Admixture Time")+
    labs(y = "Estimated Mean Admixture Time")+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    coord_cartesian(ylim = c(0,2500), expand = 0)+
    scale_color_manual("Gene Flow Model",
                       values = c(Colour_P[1],Colour_P[6]),
                       labels = c("Simple Pulse","Extended Pulse"))
  return(Px)
  
}


### Figure 1 ggplot ###
Plot_Fig_1_B <- function(Data,Colour_P){
  Px <-  ggplot(Data,aes(x=Var7,y=as.numeric(as.character(Var1)),colour=factor(Var4)))+
  #Px <-  ggplot(Data,aes(x=Var7,y=as.numeric(as.character(Var1))))+
    geom_point(aes(size = Freq),show.legend = F)+
    geom_boxplot()+
    facet_grid(~as.factor(Var6),switch = "x")+
    geom_hline( aes(yintercept = 1500 ))+
    geom_hline( aes(yintercept = Data$EP_tm) ,linetype="dashed", 
                color = "red")+
    theme(
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank())+
    labs(x = "Admixture Duration")+
    labs(y = "Estimated Mean Admixture Time")+
    scale_color_manual("Gene Flow Model",
                       values = c(Colour_P[1],Colour_P[6],Colour_P[6],Colour_P[6],Colour_P[6],Colour_P[6]),
                       labels = c("Simple Pulse","Extended Pulse","Extended Pulse","Extended Pulse","Extended Pulse","Extended Pulse"))
  return(Px)
  
}

### Plot in one window

P1_1 <- Plot_Fig_1_A(Fig_A_1,Colour_P = cbPalette_viridis)
P1_2 <- Plot_Fig_1_B(Fig_B_1,Colour_P = cbPalette_viridis)

ggarrange(P1_1,P1_2,
          labels = c("A","B"),
          ncol = 2, nrow = 2,common.legend = T,legend = 'top', align = "h")

```

```{r figS2_updated, message=FALSE, echo=FALSE,warning=FALSE,fig.width=12,fig.height=8,fig.cap="\\label{fig:figS2_updated} Comparison of the standardized difference between true and estimated admixture time for all combinations of parameters: ascertainment scheme = LES/HES,  $d_{0}$ = 0.02/0.05 cM, demography = simple/complex, recombination = constant/variable and the gene flow model = pulse/continuous, with 100 replicates respectively. Dotted horizontal line indicates no difference between true and estimated time."}

Plot_model <- data.frame(table(Diff_s=round(xdata.M.3.no_error$Diff_s,digits = 2),GF=xdata.M.3.no_error$GF_model,Asc=ifelse(xdata.M.3.no_error$AS=="I","LES", "HES"),d0=xdata.M.3.no_error$minDist,True_GF=xdata.M.3.no_error$True_tm,Demo=ifelse(xdata.M.3.no_error$Demography=="0_Simple","Sim", "Com"),Recomb=ifelse(xdata.M.3.no_error$Recomb.rate=="0_constant","Con", "Var"),Downsampling=xdata.M.3.no_error$downsampling))
Plot_model <- subset(Plot_model,Freq>0)
Plot_model$Combination_chr <- as.factor(paste(Plot_model$GF,Plot_model$Recomb,Plot_model$Demo,Plot_model$Asc,Plot_model$d0,Plot_model$Downsampling,sep = "\n"))
#Plot_model$Combination_chr <- factor(Plot_model$Combination_chr,
#                        levels = c("Hudson_only_sim","Hybrid_sim"),ordered = TRUE)
Plot_model$Combination <- as.numeric(Plot_model$Combination_chr)


Plot_model$Col <- ifelse(Plot_model$GF=='SP','#56B4E9','#D55E00')

### Supplement Figures ? Tables

Plot_Fig_2_A <- function(Data,x.axes.lables){
  Px <-  ggplot(Data,aes(x=as.character(Combination_chr),y=as.numeric(as.character(Diff_s)),colour=Col))+
    geom_point(aes(size = Freq),show.legend = F)+
    geom_boxplot(show.legend = F)+
    geom_abline(intercept = 0,slope = 0,linetype=2,aes(colour='grey'))+
    coord_cartesian(ylim = c(-2,1),expand = 0)+
    labs(x = "Predictor combination")+
    labs(y = "Standardized difference between true and estimated time")+
    theme(axis.text.x = element_text(angle = 0),text = element_text(size=5))+
    scale_x_discrete(labels= x.axes.lables)+
    scale_color_manual("Gene Flow Model",
                       values = c(cbPalette_viridis[1],cbPalette_viridis[6]),
                       labels = c("Pulse","Continuous"))
  return(Px)
  
}


Plot_Fig_2_A(Plot_model,levels(Plot_model$Combination_chr))


```

```{r tableS1_1, echo=FALSE,results='asis' }

print_B_model_result <- data.frame(B_model_result1)
kable(print_B_model_result , "latex",col.names = c("mean" , "sd"   , "5.5%"  ,"94.5%", "n_eff", "Rhat" ),digits = 2,
      caption = "\\label{tab:tableS1} Mean, standart deviation, 5.5/94.5 compatibility interval of the posterior distribution for every parameter effect on the standardized difference between true and estimated admixture time.") %>%
  collapse_rows(columns = 1, latex_hline = "major", valign = "middle")%>%
  kable_styling(latex_options = "HOLD_position")
```

```{r tableS1_2, echo=FALSE,results='asis' }

print_B_model_result <- data.frame(B_model_result2)
kable(print_B_model_result , "latex",col.names = c("mean" , "sd"   , "5.5%"  ,"94.5%", "n_eff", "Rhat" ),digits = 2,
      caption = "\\label{tab:tableS1} Mean, standart deviation, 5.5/94.5 compatibility interval of the posterior distribution for every parameter effect on the standardized difference between true and estimated admixture time.") %>%
  collapse_rows(columns = 1, latex_hline = "major", valign = "middle")%>%
  kable_styling(latex_options = "HOLD_position")
```